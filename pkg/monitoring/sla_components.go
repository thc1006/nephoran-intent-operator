// Package monitoring provides detailed implementation of SLA monitoring components.
package monitoring

import (
	"context"
	"fmt"
	"math"
	"sort"
	"sync"
	"time"

	"github.com/prometheus/client_golang/prometheus"
	"go.uber.org/zap"
)

// AvailabilityStatus represents current availability metrics.
type AvailabilityStatus struct {
	ComponentAvailability   float64 `json:"component_availability"`
	ServiceAvailability     float64 `json:"service_availability"`
	UserJourneyAvailability float64 `json:"user_journey_availability"`
	CompliancePercentage    float64 `json:"compliance_percentage"`
	ErrorBudgetRemaining    float64 `json:"error_budget_remaining"`
	ErrorBudgetBurnRate     float64 `json:"error_budget_burn_rate"`
}

// LatencyStatus represents current latency metrics.
type LatencyStatus struct {
	P50Latency             time.Duration `json:"p50_latency"`
	P95Latency             time.Duration `json:"p95_latency"`
	P99Latency             time.Duration `json:"p99_latency"`
	CompliancePercentage   float64       `json:"compliance_percentage"`
	ViolationCount         int           `json:"violation_count"`
	SustainedViolationTime time.Duration `json:"sustained_violation_time"`
}

// ThroughputStatus represents current throughput metrics.
type ThroughputStatus struct {
	CurrentThroughput    float64 `json:"current_throughput"`
	PeakThroughput       float64 `json:"peak_throughput"`
	SustainedThroughput  float64 `json:"sustained_throughput"`
	CapacityUtilization  float64 `json:"capacity_utilization"`
	QueueDepth           int     `json:"queue_depth"`
	CompliancePercentage float64 `json:"compliance_percentage"`
}

// ErrorBudgetStatus represents current error budget status.
type ErrorBudgetStatus struct {
	TotalErrorBudget     float64 `json:"total_error_budget"`
	ConsumedErrorBudget  float64 `json:"consumed_error_budget"`
	RemainingErrorBudget float64 `json:"remaining_error_budget"`
	BurnRate             float64 `json:"burn_rate"`
	BusinessImpactScore  float64 `json:"business_impact_score"`
}

// PredictedViolation represents a predicted SLA violation.
type PredictedViolation struct {
	ViolationType   string    `json:"violation_type"`
	PredictedTime   time.Time `json:"predicted_time"`
	Confidence      float64   `json:"confidence"`
	EstimatedImpact float64   `json:"estimated_impact"`
	Recommendations []string  `json:"recommendations"`
}

// SLARecommendation represents automated optimization recommendations.
type SLARecommendation struct {
	Type               string  `json:"type"`
	Priority           string  `json:"priority"`
	Description        string  `json:"description"`
	EstimatedImpact    float64 `json:"estimated_impact"`
	ImplementationCost float64 `json:"implementation_cost"`
	ROI                float64 `json:"roi"`
}

// StreamingMetricsCollector provides ultra-low latency metric collection.
type StreamingMetricsCollector struct {
	metricsBuffer     chan *MetricsSample
	processingRate    prometheus.Gauge
	bufferUtilization prometheus.Gauge
	collectionLatency *prometheus.HistogramVec

	batchSize     int
	flushInterval time.Duration
	maxBufferSize int

	mu     sync.RWMutex
	logger *zap.Logger
}

// MetricsSample represents a single metrics sample.
type MetricsSample struct {
	Timestamp  time.Time
	MetricName string
	Value      float64
	Labels     map[string]string
	SampleType string
}

// NewStreamingMetricsCollector creates a high-performance streaming collector.
func NewStreamingMetricsCollector(bufferSize int, batchSize int, flushInterval time.Duration) *StreamingMetricsCollector {
	return &StreamingMetricsCollector{
		metricsBuffer: make(chan *MetricsSample, bufferSize),
		batchSize:     batchSize,
		flushInterval: flushInterval,
		maxBufferSize: bufferSize,

		processingRate: prometheus.NewGauge(prometheus.GaugeOpts{
			Name: "sla_streaming_collector_processing_rate",
			Help: "Current processing rate of streaming collector",
		}),

		bufferUtilization: prometheus.NewGauge(prometheus.GaugeOpts{
			Name: "sla_streaming_collector_buffer_utilization",
			Help: "Buffer utilization percentage",
		}),

		collectionLatency: prometheus.NewHistogramVec(prometheus.HistogramOpts{
			Name:    "sla_streaming_collector_latency_seconds",
			Help:    "Latency of metrics collection operations",
			Buckets: prometheus.ExponentialBuckets(0.0001, 2, 10), // 0.1ms to ~100ms
		}, []string{"operation"}),
	}
}

// Start begins the streaming collection process.
func (smc *StreamingMetricsCollector) Start(ctx context.Context) error {
	// Start batch processor goroutines.
	for i := 0; i < 4; i++ { // 4 parallel processors for high throughput
		go smc.processBatch(ctx)
	}

	// Start buffer monitoring.
	go smc.monitorBuffer(ctx)

	return nil
}

// CollectMetric adds a metric to the streaming buffer.
func (smc *StreamingMetricsCollector) CollectMetric(sample *MetricsSample) error {
	start := time.Now()
	defer func() {
		smc.collectionLatency.WithLabelValues("collect").Observe(time.Since(start).Seconds())
	}()

	select {
	case smc.metricsBuffer <- sample:
		return nil
	default:
		// Buffer full - drop metric or use overflow handling.
		return ErrBufferFull
	}
}

// processBatch processes metrics in batches for efficiency.
func (smc *StreamingMetricsCollector) processBatch(ctx context.Context) {
	batch := make([]*MetricsSample, 0, smc.batchSize)
	ticker := time.NewTicker(smc.flushInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case sample := <-smc.metricsBuffer:
			batch = append(batch, sample)

			if len(batch) >= smc.batchSize {
				smc.processBatchData(batch)
				batch = batch[:0] // Clear batch
			}

		case <-ticker.C:
			if len(batch) > 0 {
				smc.processBatchData(batch)
				batch = batch[:0]
			}
		}
	}
}

// processBatchData processes a batch of metrics.
func (smc *StreamingMetricsCollector) processBatchData(batch []*MetricsSample) {
	start := time.Now()
	defer func() {
		smc.collectionLatency.WithLabelValues("batch_process").Observe(time.Since(start).Seconds())
		smc.processingRate.Set(float64(len(batch)) / time.Since(start).Seconds())
	}()

	// Process batch with parallel workers for high throughput.
	// This would integrate with Prometheus, time series DB, etc.
}

// monitorBuffer monitors buffer utilization.
func (smc *StreamingMetricsCollector) monitorBuffer(ctx context.Context) {
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			utilization := float64(len(smc.metricsBuffer)) / float64(smc.maxBufferSize) * 100
			smc.bufferUtilization.Set(utilization)
		}
	}
}

// CardinalityManager optimizes metric cardinality for high-volume scenarios.
type CardinalityManager struct {
	maxCardinality     int
	currentCardinality map[string]int
	cardinalityLimits  map[string]int

	cardinalityMetric *prometheus.GaugeVec
	droppedMetrics    *prometheus.CounterVec

	mu sync.RWMutex
}

// NewCardinalityManager creates a new cardinality manager.
func NewCardinalityManager(maxCardinality int) *CardinalityManager {
	return &CardinalityManager{
		maxCardinality:     maxCardinality,
		currentCardinality: make(map[string]int),
		cardinalityLimits:  make(map[string]int),

		cardinalityMetric: prometheus.NewGaugeVec(prometheus.GaugeOpts{
			Name: "sla_metrics_cardinality",
			Help: "Current cardinality by metric family",
		}, []string{"metric_family"}),

		droppedMetrics: prometheus.NewCounterVec(prometheus.CounterOpts{
			Name: "sla_dropped_metrics_total",
			Help: "Total number of dropped metrics due to cardinality limits",
		}, []string{"metric_family", "reason"}),
	}
}

// ShouldAcceptMetric determines if a metric should be accepted based on cardinality.
func (cm *CardinalityManager) ShouldAcceptMetric(metricName string, labels map[string]string) bool {
	cm.mu.RLock()
	defer cm.mu.RUnlock()

	// Calculate metric key for cardinality tracking.
	metricKey := cm.generateMetricKey(metricName, labels)

	// Check if metric already exists.
	if _, exists := cm.currentCardinality[metricKey]; exists {
		return true
	}

	// Check total cardinality limit.
	totalCardinality := cm.getTotalCardinality()
	if totalCardinality >= cm.maxCardinality {
		cm.droppedMetrics.WithLabelValues(metricName, "total_limit").Inc()
		return false
	}

	// Check per-metric family limit.
	if limit, exists := cm.cardinalityLimits[metricName]; exists {
		familyCardinality := cm.getFamilyCardinality(metricName)
		if familyCardinality >= limit {
			cm.droppedMetrics.WithLabelValues(metricName, "family_limit").Inc()
			return false
		}
	}

	return true
}

// generateMetricKey generates a unique key for metric cardinality tracking.
func (cm *CardinalityManager) generateMetricKey(metricName string, labels map[string]string) string {
	// Implementation would generate a unique key based on metric name and label values.
	return metricName + ":" + cm.hashLabels(labels)
}

// hashLabels creates a hash of label values for cardinality calculation.
func (cm *CardinalityManager) hashLabels(labels map[string]string) string {
	// Simplified implementation - in production would use proper hashing.
	result := ""
	for k, v := range labels {
		result += k + "=" + v + ","
	}
	return result
}

// getTotalCardinality returns the current total cardinality.
func (cm *CardinalityManager) getTotalCardinality() int {
	total := 0
	for _, count := range cm.currentCardinality {
		total += count
	}
	return total
}

// getFamilyCardinality returns cardinality for a specific metric family.
func (cm *CardinalityManager) getFamilyCardinality(metricName string) int {
	count := 0
	for key := range cm.currentCardinality {
		if len(key) > len(metricName) && key[:len(metricName)] == metricName {
			count++
		}
	}
	return count
}

// RealTimeSLICalculator computes SLIs in real-time.
type RealTimeSLICalculator struct {
	// Availability calculation.
	availabilityCalculator *AvailabilityCalculator

	// Latency calculation.
	latencyCalculator *LatencyCalculator

	// Throughput calculation.
	throughputCalculator *ThroughputCalculator

	// Error rate calculation.
	errorRateCalculator *ErrorRateCalculator

	// Real-time state.
	currentState *SLIState
	stateHistory *CircularBuffer

	// Performance metrics.
	calculationLatency *prometheus.HistogramVec
	calculationRate    prometheus.Gauge

	mu sync.RWMutex
}

// SLIState represents the current state of all SLIs.
type SLIState struct {
	Timestamp       time.Time
	Availability    float64
	P95Latency      time.Duration
	P99Latency      time.Duration
	Throughput      float64
	ErrorRate       float64
	ErrorBudgetBurn float64
}

// AvailabilityCalculator computes multi-dimensional availability.
type AvailabilityCalculator struct {
	// Component availability tracking.
	componentStates  map[string]bool
	componentWeights map[string]float64

	// Dependency tracking.
	dependencyStates  map[string]bool
	dependencyWeights map[string]float64

	// User journey tracking.
	journeySuccessRates map[string]float64
	journeyWeights      map[string]float64

	// Historical data for trend analysis.
	availabilityHistory *TimeSeries
}

// CalculateAvailability computes the current multi-dimensional availability.
func (ac *AvailabilityCalculator) CalculateAvailability(timestamp time.Time) float64 {
	// Component availability weighted calculation.
	componentAvailability := ac.calculateComponentAvailability()

	// Dependency availability weighted calculation.
	dependencyAvailability := ac.calculateDependencyAvailability()

	// User journey success rate weighted calculation.
	journeyAvailability := ac.calculateJourneyAvailability()

	// Composite availability calculation with weights.
	compositeAvailability := (componentAvailability * 0.4) +
		(dependencyAvailability * 0.3) +
		(journeyAvailability * 0.3)

	// Store in history for trend analysis.
	ac.availabilityHistory.Add(timestamp, compositeAvailability)

	return compositeAvailability
}

// calculateComponentAvailability calculates weighted component availability.
func (ac *AvailabilityCalculator) calculateComponentAvailability() float64 {
	totalWeight := 0.0
	weightedSum := 0.0

	for component, available := range ac.componentStates {
		weight := ac.componentWeights[component]
		totalWeight += weight

		if available {
			weightedSum += weight
		}
	}

	if totalWeight == 0 {
		return 1.0 // Default to available if no components tracked
	}

	return weightedSum / totalWeight
}

// calculateDependencyAvailability calculates weighted dependency availability.
func (ac *AvailabilityCalculator) calculateDependencyAvailability() float64 {
	totalWeight := 0.0
	weightedSum := 0.0

	for dependency, available := range ac.dependencyStates {
		weight := ac.dependencyWeights[dependency]
		totalWeight += weight

		if available {
			weightedSum += weight
		}
	}

	if totalWeight == 0 {
		return 1.0
	}

	return weightedSum / totalWeight
}

// calculateJourneyAvailability calculates weighted user journey availability.
func (ac *AvailabilityCalculator) calculateJourneyAvailability() float64 {
	totalWeight := 0.0
	weightedSum := 0.0

	for journey, successRate := range ac.journeySuccessRates {
		weight := ac.journeyWeights[journey]
		totalWeight += weight
		weightedSum += weight * successRate
	}

	if totalWeight == 0 {
		return 1.0
	}

	return weightedSum / totalWeight
}

// LatencyCalculator computes real-time latency percentiles.
type LatencyCalculator struct {
	// Latency tracking by component.
	endToEndLatencies   *LatencyTracker
	llmLatencies        *LatencyTracker
	ragLatencies        *LatencyTracker
	gitopsLatencies     *LatencyTracker
	deploymentLatencies *LatencyTracker

	// Percentile calculation.
	percentileCalculator *PercentileCalculator

	// SLA compliance tracking.
	slaComplianceTracker *SLAComplianceTracker
}

// LatencyTracker tracks latency measurements for a specific component.
type LatencyTracker struct {
	measurements *CircularBuffer
	histogram    *prometheus.HistogramVec

	// Real-time percentiles (using quantile estimator).
	quantileEstimator *QuantileEstimator
}

// QuantileEstimator provides efficient real-time quantile estimation.
type QuantileEstimator struct {
	// P2 algorithm or similar for real-time quantile estimation.
	p50Estimator *P2Estimator
	p95Estimator *P2Estimator
	p99Estimator *P2Estimator
}

// P2Estimator implements the P² algorithm for quantile estimation.
type P2Estimator struct {
	quantile   float64
	markers    [5]float64
	positions  [5]int
	increments [5]float64
	count      int
}

// NewP2Estimator creates a new P² quantile estimator.
func NewP2Estimator(quantile float64) *P2Estimator {
	p2 := &P2Estimator{
		quantile: quantile,
	}

	// Initialize positions.
	for i := 0; i < 5; i++ {
		p2.positions[i] = i
	}

	// Initialize increments.
	p2.increments[0] = 0
	p2.increments[1] = quantile / 2
	p2.increments[2] = quantile
	p2.increments[3] = (1 + quantile) / 2
	p2.increments[4] = 1

	return p2
}

// Add adds a new observation to the quantile estimator.
func (p2 *P2Estimator) Add(value float64) {
	if p2.count < 5 {
		// Initialization phase.
		p2.markers[p2.count] = value
		p2.count++

		if p2.count == 5 {
			// Sort markers.
			for i := 0; i < 4; i++ {
				for j := i + 1; j < 5; j++ {
					if p2.markers[i] > p2.markers[j] {
						p2.markers[i], p2.markers[j] = p2.markers[j], p2.markers[i]
					}
				}
			}
		}
		return
	}

	// Find cell k such that markers[k] <= value < markers[k+1].
	k := 0
	if value < p2.markers[0] {
		p2.markers[0] = value
		k = 0
	} else if value >= p2.markers[4] {
		p2.markers[4] = value
		k = 3
	} else {
		for i := 1; i < 4; i++ {
			if value < p2.markers[i] {
				k = i - 1
				break
			}
		}
	}

	// Increment positions.
	for i := k + 1; i < 5; i++ {
		p2.positions[i]++
	}
	p2.count++

	// Update desired positions.
	for i := 0; i < 5; i++ {
		p2.increments[i] = float64(p2.count-1) * p2.getDesiredPosition(i)
	}

	// Adjust heights of markers if necessary.
	for i := 1; i < 4; i++ {
		diff := p2.increments[i] - float64(p2.positions[i])

		if (diff >= 1 && p2.positions[i+1]-p2.positions[i] > 1) ||
			(diff <= -1 && p2.positions[i-1]-p2.positions[i] < -1) {

			d := 1.0
			if diff < 0 {
				d = -1.0
			}

			// Parabolic formula.
			newHeight := p2.parabolic(i, d)

			if p2.markers[i-1] < newHeight && newHeight < p2.markers[i+1] {
				p2.markers[i] = newHeight
			} else {
				// Linear formula.
				p2.markers[i] = p2.linear(i, d)
			}

			p2.positions[i] += int(d)
		}
	}
}

// GetQuantile returns the current quantile estimate.
func (p2 *P2Estimator) GetQuantile() float64 {
	if p2.count < 5 {
		// Not enough samples, return approximate.
		if p2.count == 0 {
			return 0
		}
		// Simple approximation for small samples.
		return p2.markers[int(p2.quantile*float64(p2.count-1))]
	}

	return p2.markers[2] // Middle marker contains the quantile estimate
}

// getDesiredPosition calculates desired position for marker i.
func (p2 *P2Estimator) getDesiredPosition(i int) float64 {
	switch i {
	case 0:
		return 0
	case 1:
		return 2 * p2.quantile
	case 2:
		return 4 * p2.quantile
	case 3:
		return 2 + 2*p2.quantile
	case 4:
		return 4
	}
	return 0
}

// parabolic calculates new height using parabolic formula.
func (p2 *P2Estimator) parabolic(i int, d float64) float64 {
	return p2.markers[i] + d*(p2.markers[i+1]-p2.markers[i-1])/(float64(p2.positions[i+1]-p2.positions[i-1]))
}

// linear calculates new height using linear formula.
func (p2 *P2Estimator) linear(i int, d float64) float64 {
	if d > 0 {
		return p2.markers[i] + d*(p2.markers[i+1]-p2.markers[i])/float64(p2.positions[i+1]-p2.positions[i])
	}
	return p2.markers[i] - d*(p2.markers[i]-p2.markers[i-1])/float64(p2.positions[i]-p2.positions[i-1])
}

// CircularBuffer provides efficient ring buffer for time series data.
type CircularBuffer struct {
	data     []float64
	times    []time.Time
	capacity int
	size     int
	head     int
	tail     int
	mu       sync.RWMutex
}

// NewCircularBuffer creates a new circular buffer.
func NewCircularBuffer(capacity int) *CircularBuffer {
	return &CircularBuffer{
		data:     make([]float64, capacity),
		times:    make([]time.Time, capacity),
		capacity: capacity,
	}
}

// Add adds a new value to the circular buffer.
func (cb *CircularBuffer) Add(timestamp time.Time, value float64) {
	cb.mu.Lock()
	defer cb.mu.Unlock()

	cb.data[cb.head] = value
	cb.times[cb.head] = timestamp

	cb.head = (cb.head + 1) % cb.capacity

	if cb.size < cb.capacity {
		cb.size++
	} else {
		cb.tail = (cb.tail + 1) % cb.capacity
	}
}

// GetRecent returns the most recent n values.
func (cb *CircularBuffer) GetRecent(n int) ([]time.Time, []float64) {
	cb.mu.RLock()
	defer cb.mu.RUnlock()

	if n > cb.size {
		n = cb.size
	}

	times := make([]time.Time, n)
	values := make([]float64, n)

	for i := 0; i < n; i++ {
		idx := (cb.head - 1 - i + cb.capacity) % cb.capacity
		times[n-1-i] = cb.times[idx]
		values[n-1-i] = cb.data[idx]
	}

	return times, values
}

// Range iterates over all values in the circular buffer.
func (cb *CircularBuffer) Range(fn func(float64) bool) {
	cb.mu.RLock()
	defer cb.mu.RUnlock()

	if cb.size == 0 {
		return
	}

	// Iterate from tail to head (oldest to newest).
	for i := 0; i < cb.size; i++ {
		idx := (cb.tail + i) % cb.capacity
		if !fn(cb.data[idx]) {
			break
		}
	}
}

// RangeWithTime iterates over all timestamp-value pairs in the circular buffer.
func (cb *CircularBuffer) RangeWithTime(fn func(time.Time, float64) bool) {
	cb.mu.RLock()
	defer cb.mu.RUnlock()

	if cb.size == 0 {
		return
	}

	// Iterate from tail to head (oldest to newest).
	for i := 0; i < cb.size; i++ {
		idx := (cb.tail + i) % cb.capacity
		if !fn(cb.times[idx], cb.data[idx]) {
			break
		}
	}
}

// Common errors.
var (
	// ErrBufferFull holds errbufferfull value.
	ErrBufferFull = fmt.Errorf("metrics buffer is full")
)

// TimeSeries represents a time series for historical data tracking.
type TimeSeries struct {
	points    []TimePoint
	maxPoints int
	mu        sync.RWMutex
}

// TimePoint represents a single point in time series.
type TimePoint struct {
	Timestamp time.Time
	Value     float64
}

// NewTimeSeries creates a new time series.
func NewTimeSeries(maxPoints int) *TimeSeries {
	return &TimeSeries{
		points:    make([]TimePoint, 0, maxPoints),
		maxPoints: maxPoints,
	}
}

// Add adds a new point to the time series.
func (ts *TimeSeries) Add(timestamp time.Time, value float64) {
	ts.mu.Lock()
	defer ts.mu.Unlock()

	point := TimePoint{
		Timestamp: timestamp,
		Value:     value,
	}

	ts.points = append(ts.points, point)

	// Remove old points if exceeding maximum.
	if len(ts.points) > ts.maxPoints {
		ts.points = ts.points[1:]
	}
}

// GetRecent returns the most recent n time points.
func (ts *TimeSeries) GetRecent(n int) ([]time.Time, []float64) {
	ts.mu.RLock()
	defer ts.mu.RUnlock()

	if n > len(ts.points) {
		n = len(ts.points)
	}

	if n == 0 {
		return []time.Time{}, []float64{}
	}

	// Get the last n points.
	startIdx := len(ts.points) - n
	times := make([]time.Time, n)
	values := make([]float64, n)

	for i := 0; i < n; i++ {
		point := ts.points[startIdx+i]
		times[i] = point.Timestamp
		values[i] = point.Value
	}

	return times, values
}

// GetTrend calculates the trend over the specified duration.
func (ts *TimeSeries) GetTrend(duration time.Duration) float64 {
	ts.mu.RLock()
	defer ts.mu.RUnlock()

	if len(ts.points) < 2 {
		return 0
	}

	cutoff := time.Now().Add(-duration)

	// Find relevant points.
	var relevantPoints []TimePoint
	for _, point := range ts.points {
		if point.Timestamp.After(cutoff) {
			relevantPoints = append(relevantPoints, point)
		}
	}

	if len(relevantPoints) < 2 {
		return 0
	}

	// Calculate linear regression slope.
	return ts.calculateSlope(relevantPoints)
}

// calculateSlope calculates the slope using linear regression.
func (ts *TimeSeries) calculateSlope(points []TimePoint) float64 {
	n := float64(len(points))

	// Convert timestamps to seconds for calculation.
	baseTime := points[0].Timestamp.Unix()

	var sumX, sumY, sumXY, sumXX float64

	for _, point := range points {
		x := float64(point.Timestamp.Unix() - baseTime)
		y := point.Value

		sumX += x
		sumY += y
		sumXY += x * y
		sumXX += x * x
	}

	// Linear regression: slope = (n*sumXY - sumX*sumY) / (n*sumXX - sumX*sumX).
	denominator := n*sumXX - sumX*sumX
	if math.Abs(denominator) < 1e-10 {
		return 0
	}

	return (n*sumXY - sumX*sumY) / denominator
}

// ThroughputCalculator calculates throughput metrics.
type ThroughputCalculator struct {
	windowSize time.Duration
	requests   *CircularBuffer
	mu         sync.RWMutex
}

// NewThroughputCalculator creates a new throughput calculator.
func NewThroughputCalculator(windowSize time.Duration) *ThroughputCalculator {
	return &ThroughputCalculator{
		windowSize: windowSize,
		requests:   NewCircularBuffer(1000),
	}
}

// RecordRequest records a new request for throughput calculation.
func (tc *ThroughputCalculator) RecordRequest(timestamp time.Time) {
	tc.mu.Lock()
	defer tc.mu.Unlock()
	tc.requests.Add(timestamp, 1.0) // Store timestamp with value 1.0 to represent a request
}

// Calculate calculates current throughput (requests per second).
func (tc *ThroughputCalculator) Calculate() float64 {
	tc.mu.RLock()
	defer tc.mu.RUnlock()

	now := time.Now()
	cutoff := now.Add(-tc.windowSize)

	count := 0
	tc.requests.RangeWithTime(func(timestamp time.Time, value float64) bool {
		if timestamp.After(cutoff) {
			count++
		}
		return true
	})

	return float64(count) / tc.windowSize.Seconds()
}

// ErrorRateCalculator calculates error rate metrics.
type ErrorRateCalculator struct {
	windowSize    time.Duration
	totalRequests *CircularBuffer
	errorRequests *CircularBuffer
	mu            sync.RWMutex
}

// NewErrorRateCalculator creates a new error rate calculator.
func NewErrorRateCalculator(windowSize time.Duration) *ErrorRateCalculator {
	return &ErrorRateCalculator{
		windowSize:    windowSize,
		totalRequests: NewCircularBuffer(1000),
		errorRequests: NewCircularBuffer(1000),
	}
}

// RecordRequest records a request (total and error status).
func (erc *ErrorRateCalculator) RecordRequest(timestamp time.Time, isError bool) {
	erc.mu.Lock()
	defer erc.mu.Unlock()

	erc.totalRequests.Add(timestamp, 1.0) // Store timestamp with value 1.0 to represent a request
	if isError {
		erc.errorRequests.Add(timestamp, 1.0) // Store timestamp with value 1.0 to represent an error
	}
}

// Calculate calculates current error rate (0.0 to 1.0).
func (erc *ErrorRateCalculator) Calculate() float64 {
	erc.mu.RLock()
	defer erc.mu.RUnlock()

	now := time.Now()
	cutoff := now.Add(-erc.windowSize)

	totalCount := 0
	errorCount := 0

	erc.totalRequests.RangeWithTime(func(timestamp time.Time, value float64) bool {
		if timestamp.After(cutoff) {
			totalCount++
		}
		return true
	})

	erc.errorRequests.RangeWithTime(func(timestamp time.Time, value float64) bool {
		if timestamp.After(cutoff) {
			errorCount++
		}
		return true
	})

	if totalCount == 0 {
		return 0.0
	}

	return float64(errorCount) / float64(totalCount)
}

// PercentileCalculator calculates percentile metrics for latency.
type PercentileCalculator struct {
	windowSize time.Duration
	values     *CircularBuffer
	mu         sync.RWMutex
}

// NewPercentileCalculator creates a new percentile calculator.
func NewPercentileCalculator(windowSize time.Duration) *PercentileCalculator {
	return &PercentileCalculator{
		windowSize: windowSize,
		values:     NewCircularBuffer(1000),
	}
}

// RecordValue records a latency value.
func (pc *PercentileCalculator) RecordValue(value float64) {
	pc.mu.Lock()
	defer pc.mu.Unlock()
	pc.values.Add(time.Now(), value)
}

// Calculate calculates the specified percentile.
func (pc *PercentileCalculator) Calculate(percentile float64) float64 {
	pc.mu.RLock()
	defer pc.mu.RUnlock()

	var values []float64
	pc.values.Range(func(value float64) bool {
		values = append(values, value)
		return true
	})

	if len(values) == 0 {
		return 0.0
	}

	// Sort values.
	sort.Float64s(values)

	// Calculate percentile index.
	index := percentile / 100.0 * float64(len(values)-1)

	if index == float64(int(index)) {
		return values[int(index)]
	}

	// Linear interpolation.
	lower := int(index)
	upper := lower + 1
	if upper >= len(values) {
		return values[len(values)-1]
	}

	weight := index - float64(lower)
	return values[lower]*(1-weight) + values[upper]*weight
}

// SLAComplianceTracker tracks SLA compliance over time.
type SLAComplianceTracker struct {
	violations *CircularBuffer
	windowSize time.Duration
	mu         sync.RWMutex
}

// NewSLAComplianceTracker creates a new SLA compliance tracker.
func NewSLAComplianceTracker(windowSize time.Duration) *SLAComplianceTracker {
	return &SLAComplianceTracker{
		violations: NewCircularBuffer(1000),
		windowSize: windowSize,
	}
}

// RecordViolation records an SLA violation.
func (sct *SLAComplianceTracker) RecordViolation(timestamp time.Time, severity float64) {
	sct.mu.Lock()
	defer sct.mu.Unlock()
	sct.violations.Add(timestamp, severity)
}

// GetComplianceRate returns the current compliance rate (0.0 to 1.0).
func (sct *SLAComplianceTracker) GetComplianceRate() float64 {
	sct.mu.RLock()
	defer sct.mu.RUnlock()

	now := time.Now()
	cutoff := now.Add(-sct.windowSize)

	violationCount := 0
	totalMeasurements := 0

	sct.violations.RangeWithTime(func(timestamp time.Time, value float64) bool {
		if timestamp.After(cutoff) {
			totalMeasurements++
			if value > 0 {
				violationCount++
			}
		}
		return true
	})

	if totalMeasurements == 0 {
		return 1.0 // 100% compliance when no measurements
	}

	return 1.0 - (float64(violationCount) / float64(totalMeasurements))
}
