/*

Copyright 2025.



Licensed under the Apache License, Version 2.0 (the "License");

you may not use this file except in compliance with the License.

You may obtain a copy of the License at



    http://www.apache.org/licenses/LICENSE-2.0



Unless required by applicable law or agreed to in writing, software

distributed under the License is distributed on an "AS IS" BASIS,

WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.

See the License for the specific language governing permissions and

limitations under the License.

*/

package shared

import (
	"context"
	"sync"
	"time"

	"github.com/go-logr/logr"

	ctrl "sigs.k8s.io/controller-runtime"
)

// PerformanceOptimizer manages system performance optimization.

type PerformanceOptimizer struct {
	logger logr.Logger

	// Connection pooling.

	connectionPools map[string]*ConnectionPool

	poolMutex sync.RWMutex

	// Batch processing.

	batchProcessors map[string]*BatchProcessor

	batchMutex sync.RWMutex

	// Memory optimization.

	memoryManager *MemoryManager

	// CPU optimization.

	cpuManager *CPUManager

	// I/O optimization.

	ioOptimizer *IOOptimizer

	// Caching optimization.

	cacheOptimizer *CacheOptimizer

	// Performance monitoring.

	performanceMonitor *PerformanceMonitor

	// Configuration.

	config *PerformanceConfig

	// Runtime state.

	mutex sync.RWMutex

	started bool

	stopChan chan bool

	workerWG sync.WaitGroup
}

// PerformanceConfig provides configuration for performance optimization.

type PerformanceConfig struct {

	// Connection pooling.

	DefaultPoolSize int `json:"defaultPoolSize"`

	MaxPoolSize int `json:"maxPoolSize"`

	PoolIdleTimeout time.Duration `json:"poolIdleTimeout"`

	PoolHealthCheckInterval time.Duration `json:"poolHealthCheckInterval"`

	// Batch processing.

	DefaultBatchSize int `json:"defaultBatchSize"`

	MaxBatchSize int `json:"maxBatchSize"`

	BatchTimeout time.Duration `json:"batchTimeout"`

	EnableAdaptiveBatching bool `json:"enableAdaptiveBatching"`

	// Memory management.

	MaxMemoryUsage int64 `json:"maxMemoryUsage"` // in bytes

	GCThreshold float64 `json:"gcThreshold"` // memory usage percentage

	MemoryCheckInterval time.Duration `json:"memoryCheckInterval"`

	// CPU management.

	MaxCPUUsage float64 `json:"maxCPUUsage"` // percentage

	CPUThrottleThreshold float64 `json:"cpuThrottleThreshold"`

	CPUCheckInterval time.Duration `json:"cpuCheckInterval"`

	// I/O optimization.

	MaxConcurrentIO int `json:"maxConcurrentIO"`

	IOTimeoutDefault time.Duration `json:"ioTimeoutDefault"`

	EnableIOBuffering bool `json:"enableIOBuffering"`

	IOBufferSize int `json:"ioBufferSize"`

	// Cache optimization.

	CacheHitRateThreshold float64 `json:"cacheHitRateThreshold"`

	CacheEvictionStrategy string `json:"cacheEvictionStrategy"`

	CacheSizeThreshold int64 `json:"cacheSizeThreshold"`

	// Monitoring.

	MonitoringInterval time.Duration `json:"monitoringInterval"`

	MetricsRetentionDays int `json:"metricsRetentionDays"`

	EnableProfiling bool `json:"enableProfiling"`
}

// DefaultPerformanceConfig returns default performance configuration.

func DefaultPerformanceConfig() *PerformanceConfig {

	return &PerformanceConfig{

		DefaultPoolSize: 10,

		MaxPoolSize: 100,

		PoolIdleTimeout: 5 * time.Minute,

		PoolHealthCheckInterval: 30 * time.Second,

		DefaultBatchSize: 50,

		MaxBatchSize: 1000,

		BatchTimeout: 1 * time.Second,

		EnableAdaptiveBatching: true,

		MaxMemoryUsage: 1024 * 1024 * 1024, // 1GB

		GCThreshold: 0.8, // 80%

		MemoryCheckInterval: 30 * time.Second,

		MaxCPUUsage: 0.8, // 80%

		CPUThrottleThreshold: 0.9, // 90%

		CPUCheckInterval: 10 * time.Second,

		MaxConcurrentIO: 50,

		IOTimeoutDefault: 30 * time.Second,

		EnableIOBuffering: true,

		IOBufferSize: 64 * 1024, // 64KB

		CacheHitRateThreshold: 0.7, // 70%

		CacheEvictionStrategy: "lru",

		CacheSizeThreshold: 100 * 1024 * 1024, // 100MB

		MonitoringInterval: 1 * time.Minute,

		MetricsRetentionDays: 7,

		EnableProfiling: false,
	}

}

// ConnectionPool manages a pool of connections.

type ConnectionPool struct {
	name string

	connections []Connection

	available chan Connection

	inUse map[string]Connection

	mutex sync.RWMutex

	maxSize int

	currentSize int

	idleTimeout time.Duration

	healthChecker func(Connection) bool

	factory func() (Connection, error)

	// Statistics.

	totalCreated int64

	totalDestroyed int64

	totalUsed int64

	totalReturned int64
}

// Connection represents a generic connection interface.

type Connection interface {
	ID() string

	IsHealthy() bool

	LastUsed() time.Time

	Close() error
}

// BatchProcessor handles batch processing of items.

type BatchProcessor struct {
	name string

	batchSize int

	timeout time.Duration

	processor func([]interface{}) error

	buffer []interface{}

	bufferMutex sync.Mutex

	ticker *time.Ticker

	stopChan chan bool

	// Adaptive batching.

	adaptiveBatching bool

	avgProcessTime time.Duration

	throughputHistory []float64
}

// MemoryManager manages memory usage and optimization.

type MemoryManager struct {
	maxMemory int64

	gcThreshold float64

	currentMemory int64

	mutex sync.RWMutex

	// Memory pools.

	pools map[string]*sync.Pool

	// Statistics.

	allocations int64

	deallocations int64

	gcRuns int64
}

// CPUManager manages CPU usage and throttling.

type CPUManager struct {
	maxCPUUsage float64

	throttleThreshold float64

	currentCPUUsage float64

	throttleActive bool

	mutex sync.RWMutex

	// Throttling control.

	throttleRequests chan bool

	throttleResponses chan bool
}

// IOOptimizer optimizes I/O operations.

type IOOptimizer struct {
	maxConcurrent int

	semaphore chan struct{}

	defaultTimeout time.Duration

	bufferingEnabled bool

	bufferSize int

	// I/O statistics.

	totalOperations int64

	averageLatency time.Duration

	concurrentOps int64

	mutex sync.RWMutex
}

// CacheOptimizer optimizes cache performance.

type CacheOptimizer struct {
	hitRateThreshold float64

	evictionStrategy string

	sizeThreshold int64

	// Cache statistics.

	totalHits int64

	totalMisses int64

	totalEvictions int64

	currentSize int64

	mutex sync.RWMutex
}

// PerformanceMonitor monitors system performance.

type PerformanceMonitor struct {
	metrics map[string]*PerformanceMetric

	mutex sync.RWMutex

	// Monitoring configuration.

	interval time.Duration

	retentionDays int

	profiling bool
}

// PerformanceMetric represents a performance metric.

type PerformanceMetric struct {
	Name string `json:"name"`

	Value float64 `json:"value"`

	Unit string `json:"unit"`

	Timestamp time.Time `json:"timestamp"`

	Tags map[string]string `json:"tags"`

	History []float64 `json:"history"`
}

// NewPerformanceOptimizer creates a new performance optimizer.

func NewPerformanceOptimizer(config *PerformanceConfig) *PerformanceOptimizer {

	if config == nil {

		config = DefaultPerformanceConfig()

	}

	po := &PerformanceOptimizer{

		logger: ctrl.Log.WithName("performance-optimizer"),

		connectionPools: make(map[string]*ConnectionPool),

		batchProcessors: make(map[string]*BatchProcessor),

		config: config,

		stopChan: make(chan bool),
	}

	// Initialize components.

	po.memoryManager = NewMemoryManager(config.MaxMemoryUsage, config.GCThreshold)

	po.cpuManager = NewCPUManager(config.MaxCPUUsage, config.CPUThrottleThreshold)

	po.ioOptimizer = NewIOOptimizer(config.MaxConcurrentIO, config.IOTimeoutDefault,

		config.EnableIOBuffering, config.IOBufferSize)

	po.cacheOptimizer = NewCacheOptimizer(config.CacheHitRateThreshold,

		config.CacheEvictionStrategy, config.CacheSizeThreshold)

	po.performanceMonitor = NewPerformanceMonitor(config.MonitoringInterval,

		config.MetricsRetentionDays, config.EnableProfiling)

	return po

}

// Start starts the performance optimizer.

func (po *PerformanceOptimizer) Start(ctx context.Context) error {

	po.mutex.Lock()

	defer po.mutex.Unlock()

	if po.started {

		return nil

	}

	// Start memory manager.

	po.workerWG.Add(1)

	go po.memoryManagerWorker(ctx)

	// Start CPU manager.

	po.workerWG.Add(1)

	go po.cpuManagerWorker(ctx)

	// Start performance monitor.

	po.workerWG.Add(1)

	go po.performanceMonitorWorker(ctx)

	po.started = true

	po.logger.Info("Performance optimizer started")

	return nil

}

// Stop stops the performance optimizer.

func (po *PerformanceOptimizer) Stop(ctx context.Context) error {

	po.mutex.Lock()

	defer po.mutex.Unlock()

	if !po.started {

		return nil

	}

	// Signal stop.

	close(po.stopChan)

	// Stop all connection pools.

	po.poolMutex.Lock()

	for _, pool := range po.connectionPools {

		pool.Close()

	}

	po.poolMutex.Unlock()

	// Stop all batch processors.

	po.batchMutex.Lock()

	for _, processor := range po.batchProcessors {

		processor.Stop()

	}

	po.batchMutex.Unlock()

	// Wait for workers.

	po.workerWG.Wait()

	po.started = false

	po.logger.Info("Performance optimizer stopped")

	return nil

}

// Connection pool management.

// CreateConnectionPool performs createconnectionpool operation.

func (po *PerformanceOptimizer) CreateConnectionPool(name string, factory func() (Connection, error), maxSize int) *ConnectionPool {

	po.poolMutex.Lock()

	defer po.poolMutex.Unlock()

	if pool, exists := po.connectionPools[name]; exists {

		return pool

	}

	pool := &ConnectionPool{

		name: name,

		connections: make([]Connection, 0, maxSize),

		available: make(chan Connection, maxSize),

		inUse: make(map[string]Connection),

		maxSize: maxSize,

		idleTimeout: po.config.PoolIdleTimeout,

		factory: factory,
	}

	po.connectionPools[name] = pool

	// Start pool maintenance.

	go pool.maintenanceWorker()

	po.logger.Info("Created connection pool", "name", name, "maxSize", maxSize)

	return pool

}

// GetConnectionPool performs getconnectionpool operation.

func (po *PerformanceOptimizer) GetConnectionPool(name string) *ConnectionPool {

	po.poolMutex.RLock()

	defer po.poolMutex.RUnlock()

	return po.connectionPools[name]

}

// Batch processing management.

// CreateBatchProcessor performs createbatchprocessor operation.

func (po *PerformanceOptimizer) CreateBatchProcessor(name string, batchSize int,

	processor func([]interface{}) error,

) *BatchProcessor {

	po.batchMutex.Lock()

	defer po.batchMutex.Unlock()

	if bp, exists := po.batchProcessors[name]; exists {

		return bp

	}

	bp := &BatchProcessor{

		name: name,

		batchSize: batchSize,

		timeout: po.config.BatchTimeout,

		processor: processor,

		buffer: make([]interface{}, 0, batchSize),

		ticker: time.NewTicker(po.config.BatchTimeout),

		stopChan: make(chan bool),

		adaptiveBatching: po.config.EnableAdaptiveBatching,

		throughputHistory: make([]float64, 0, 10),
	}

	// Start batch processing.

	go bp.processLoop()

	po.batchProcessors[name] = bp

	po.logger.Info("Created batch processor", "name", name, "batchSize", batchSize)

	return bp

}

// GetBatchProcessor performs getbatchprocessor operation.

func (po *PerformanceOptimizer) GetBatchProcessor(name string) *BatchProcessor {

	po.batchMutex.RLock()

	defer po.batchMutex.RUnlock()

	return po.batchProcessors[name]

}

// Performance optimization methods.

// OptimizeMemoryUsage performs optimizememoryusage operation.

func (po *PerformanceOptimizer) OptimizeMemoryUsage(ctx context.Context) error {

	return po.memoryManager.Optimize(ctx)

}

// OptimizeCPUUsage performs optimizecpuusage operation.

func (po *PerformanceOptimizer) OptimizeCPUUsage(ctx context.Context) error {

	return po.cpuManager.Optimize(ctx)

}

// OptimizeIOPerformance performs optimizeioperformance operation.

func (po *PerformanceOptimizer) OptimizeIOPerformance(ctx context.Context) error {

	return po.ioOptimizer.Optimize(ctx)

}

// OptimizeCachePerformance performs optimizecacheperformance operation.

func (po *PerformanceOptimizer) OptimizeCachePerformance(ctx context.Context) error {

	return po.cacheOptimizer.Optimize(ctx)

}

// Worker methods.

func (po *PerformanceOptimizer) memoryManagerWorker(ctx context.Context) {

	defer po.workerWG.Done()

	ticker := time.NewTicker(po.config.MemoryCheckInterval)

	defer ticker.Stop()

	for {

		select {

		case <-ticker.C:

			po.OptimizeMemoryUsage(ctx)

		case <-po.stopChan:

			return

		case <-ctx.Done():

			return

		}

	}

}

func (po *PerformanceOptimizer) cpuManagerWorker(ctx context.Context) {

	defer po.workerWG.Done()

	ticker := time.NewTicker(po.config.CPUCheckInterval)

	defer ticker.Stop()

	for {

		select {

		case <-ticker.C:

			po.OptimizeCPUUsage(ctx)

		case <-po.stopChan:

			return

		case <-ctx.Done():

			return

		}

	}

}

func (po *PerformanceOptimizer) performanceMonitorWorker(ctx context.Context) {

	defer po.workerWG.Done()

	ticker := time.NewTicker(po.config.MonitoringInterval)

	defer ticker.Stop()

	for {

		select {

		case <-ticker.C:

			po.performanceMonitor.CollectMetrics(ctx)

		case <-po.stopChan:

			return

		case <-ctx.Done():

			return

		}

	}

}

// Component implementations.

// NewMemoryManager performs newmemorymanager operation.

func NewMemoryManager(maxMemory int64, gcThreshold float64) *MemoryManager {

	return &MemoryManager{

		maxMemory: maxMemory,

		gcThreshold: gcThreshold,

		pools: make(map[string]*sync.Pool),
	}

}

// Optimize performs optimize operation.

func (mm *MemoryManager) Optimize(ctx context.Context) error {

	mm.mutex.Lock()

	defer mm.mutex.Unlock()

	// Check memory usage.

	memoryUsage := float64(mm.currentMemory) / float64(mm.maxMemory)

	if memoryUsage > mm.gcThreshold {

		// Trigger garbage collection.

		mm.gcRuns++

		// In a real implementation, this would trigger actual GC.

	}

	return nil

}

// NewCPUManager performs newcpumanager operation.

func NewCPUManager(maxCPU, throttleThreshold float64) *CPUManager {

	return &CPUManager{

		maxCPUUsage: maxCPU,

		throttleThreshold: throttleThreshold,

		throttleRequests: make(chan bool, 100),

		throttleResponses: make(chan bool, 100),
	}

}

// Optimize performs optimize operation.

func (cm *CPUManager) Optimize(ctx context.Context) error {

	cm.mutex.Lock()

	defer cm.mutex.Unlock()

	// Check if throttling is needed.

	if cm.currentCPUUsage > cm.throttleThreshold && !cm.throttleActive {

		cm.throttleActive = true

		// Start throttling.

	} else if cm.currentCPUUsage < cm.maxCPUUsage && cm.throttleActive {

		cm.throttleActive = false

		// Stop throttling.

	}

	return nil

}

// NewIOOptimizer performs newiooptimizer operation.

func NewIOOptimizer(maxConcurrent int, defaultTimeout time.Duration,

	bufferingEnabled bool, bufferSize int,

) *IOOptimizer {

	return &IOOptimizer{

		maxConcurrent: maxConcurrent,

		semaphore: make(chan struct{}, maxConcurrent),

		defaultTimeout: defaultTimeout,

		bufferingEnabled: bufferingEnabled,

		bufferSize: bufferSize,
	}

}

// Optimize performs optimize operation.

func (io *IOOptimizer) Optimize(ctx context.Context) error {

	// Placeholder for I/O optimization logic.

	return nil

}

// NewCacheOptimizer performs newcacheoptimizer operation.

func NewCacheOptimizer(hitRateThreshold float64, evictionStrategy string,

	sizeThreshold int64,

) *CacheOptimizer {

	return &CacheOptimizer{

		hitRateThreshold: hitRateThreshold,

		evictionStrategy: evictionStrategy,

		sizeThreshold: sizeThreshold,
	}

}

// Optimize performs optimize operation.

func (co *CacheOptimizer) Optimize(ctx context.Context) error {

	co.mutex.Lock()

	defer co.mutex.Unlock()

	// Calculate hit rate.

	total := co.totalHits + co.totalMisses

	if total == 0 {

		return nil

	}

	hitRate := float64(co.totalHits) / float64(total)

	// Optimize cache if hit rate is below threshold.

	if hitRate < co.hitRateThreshold {

		// Implement cache optimization strategies.

	}

	return nil

}

// NewPerformanceMonitor performs newperformancemonitor operation.

func NewPerformanceMonitor(interval time.Duration, retentionDays int,

	profiling bool,

) *PerformanceMonitor {

	return &PerformanceMonitor{

		metrics: make(map[string]*PerformanceMetric),

		interval: interval,

		retentionDays: retentionDays,

		profiling: profiling,
	}

}

// CollectMetrics performs collectmetrics operation.

func (pm *PerformanceMonitor) CollectMetrics(ctx context.Context) {

	pm.mutex.Lock()

	defer pm.mutex.Unlock()

	// Collect various performance metrics.

	now := time.Now()

	// Example metrics collection.

	pm.recordMetric("memory.usage", 0.0, "percentage", now, nil)

	pm.recordMetric("cpu.usage", 0.0, "percentage", now, nil)

	pm.recordMetric("io.operations", 0.0, "ops/sec", now, nil)

	pm.recordMetric("cache.hit_rate", 0.0, "percentage", now, nil)

}

func (pm *PerformanceMonitor) recordMetric(name string, value float64, unit string,

	timestamp time.Time, tags map[string]string,

) {

	if _, exists := pm.metrics[name]; !exists {

		pm.metrics[name] = &PerformanceMetric{

			Name: name,

			Unit: unit,

			Tags: tags,

			History: make([]float64, 0, 1000),
		}

	}

	metric := pm.metrics[name]

	metric.Value = value

	metric.Timestamp = timestamp

	metric.History = append(metric.History, value)

	// Keep only recent history.

	if len(metric.History) > 1000 {

		metric.History = metric.History[100:]

	}

}

// Connection pool methods.

// Get performs get operation.

func (cp *ConnectionPool) Get(ctx context.Context) (Connection, error) {

	// Try to get from available connections.

	select {

	case conn := <-cp.available:

		cp.mutex.Lock()

		cp.inUse[conn.ID()] = conn

		cp.totalUsed++

		cp.mutex.Unlock()

		return conn, nil

	default:

		// Create new connection if under limit.

		if cp.currentSize < cp.maxSize {

			conn, err := cp.factory()

			if err != nil {

				return nil, err

			}

			cp.mutex.Lock()

			cp.connections = append(cp.connections, conn)

			cp.inUse[conn.ID()] = conn

			cp.currentSize++

			cp.totalCreated++

			cp.totalUsed++

			cp.mutex.Unlock()

			return conn, nil

		}

		// Wait for available connection.

		select {

		case conn := <-cp.available:

			cp.mutex.Lock()

			cp.inUse[conn.ID()] = conn

			cp.totalUsed++

			cp.mutex.Unlock()

			return conn, nil

		case <-ctx.Done():

			return nil, ctx.Err()

		}

	}

}

// Return performs return operation.

func (cp *ConnectionPool) Return(conn Connection) {

	cp.mutex.Lock()

	defer cp.mutex.Unlock()

	delete(cp.inUse, conn.ID())

	cp.totalReturned++

	if conn.IsHealthy() {

		select {

		case cp.available <- conn:

			// Connection returned to pool.

		default:

			// Pool is full, close connection.

			conn.Close()

			cp.currentSize--

			cp.totalDestroyed++

		}

	} else {

		// Connection is unhealthy, close it.

		conn.Close()

		cp.currentSize--

		cp.totalDestroyed++

	}

}

// Close performs close operation.

func (cp *ConnectionPool) Close() {

	cp.mutex.Lock()

	defer cp.mutex.Unlock()

	// Close all connections.

	for _, conn := range cp.connections {

		conn.Close()

	}

	// Close all in-use connections.

	for _, conn := range cp.inUse {

		conn.Close()

	}

	cp.connections = nil

	cp.inUse = make(map[string]Connection)

	cp.currentSize = 0

}

func (cp *ConnectionPool) maintenanceWorker() {

	ticker := time.NewTicker(1 * time.Minute)

	defer ticker.Stop()

	for range ticker.C {

		cp.performMaintenance()

	}

}

func (cp *ConnectionPool) performMaintenance() {

	cp.mutex.Lock()

	defer cp.mutex.Unlock()

	// Remove idle connections that have exceeded idle timeout.

	now := time.Now()

	for i := len(cp.connections) - 1; i >= 0; i-- {

		conn := cp.connections[i]

		if now.Sub(conn.LastUsed()) > cp.idleTimeout {

			conn.Close()

			cp.connections = append(cp.connections[:i], cp.connections[i+1:]...)

			cp.currentSize--

			cp.totalDestroyed++

		}

	}

}

// Batch processor methods.

// Add performs add operation.

func (bp *BatchProcessor) Add(item interface{}) {

	bp.bufferMutex.Lock()

	defer bp.bufferMutex.Unlock()

	bp.buffer = append(bp.buffer, item)

	if len(bp.buffer) >= bp.batchSize {

		bp.processBatch()

	}

}

func (bp *BatchProcessor) processBatch() {

	if len(bp.buffer) == 0 {

		return

	}

	batch := make([]interface{}, len(bp.buffer))

	copy(batch, bp.buffer)

	bp.buffer = bp.buffer[:0]

	start := time.Now()

	err := bp.processor(batch)

	duration := time.Since(start)

	if bp.adaptiveBatching {

		bp.updatePerformanceMetrics(len(batch), duration, err == nil)

	}

}

func (bp *BatchProcessor) processLoop() {

	for {

		select {

		case <-bp.ticker.C:

			bp.bufferMutex.Lock()

			bp.processBatch()

			bp.bufferMutex.Unlock()

		case <-bp.stopChan:

			// Process remaining items.

			bp.bufferMutex.Lock()

			bp.processBatch()

			bp.bufferMutex.Unlock()

			return

		}

	}

}

func (bp *BatchProcessor) updatePerformanceMetrics(batchSize int, duration time.Duration, success bool) {

	// Update average processing time.

	if bp.avgProcessTime == 0 {

		bp.avgProcessTime = duration

	} else {

		bp.avgProcessTime = (bp.avgProcessTime + duration) / 2

	}

	// Calculate throughput (items per second).

	throughput := float64(batchSize) / duration.Seconds()

	bp.throughputHistory = append(bp.throughputHistory, throughput)

	// Keep only recent history.

	if len(bp.throughputHistory) > 10 {

		bp.throughputHistory = bp.throughputHistory[1:]

	}

	// Adapt batch size based on performance.

	if len(bp.throughputHistory) >= 3 {

		bp.adaptBatchSize()

	}

}

func (bp *BatchProcessor) adaptBatchSize() {

	// Calculate average throughput.

	var totalThroughput float64

	for _, t := range bp.throughputHistory {

		totalThroughput += t

	}

	avgThroughput := totalThroughput / float64(len(bp.throughputHistory))

	// Adjust batch size based on throughput trend.

	recentThroughput := bp.throughputHistory[len(bp.throughputHistory)-1]

	if recentThroughput > avgThroughput*1.1 && bp.batchSize < 1000 {

		// Throughput is improving, increase batch size.

		bp.batchSize = int(float64(bp.batchSize) * 1.1)

	} else if recentThroughput < avgThroughput*0.9 && bp.batchSize > 10 {

		// Throughput is declining, decrease batch size.

		bp.batchSize = int(float64(bp.batchSize) * 0.9)

	}

}

// Stop performs stop operation.

func (bp *BatchProcessor) Stop() {

	bp.ticker.Stop()

	bp.stopChan <- true

}
