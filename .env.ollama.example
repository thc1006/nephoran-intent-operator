# Nephoran Intent Operator - Ollama Configuration Example
# Copy this file to .env and adjust as needed

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# LLM Provider: "ollama" or "openai"
LLM_PROVIDER=ollama

# Model Selection
# Ollama models: llama2:7b, llama2:13b, mistral:7b, codellama:7b
# OpenAI models: gpt-4o-mini, gpt-4o-2024-08-06, gpt-4-turbo-preview
OLLAMA_MODEL=llama2:7b

# Ollama Base URL
# Local: http://localhost:11434
# Docker: http://ollama:11434
# Remote: http://your-ollama-server:11434
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI API Key (only needed if LLM_PROVIDER=openai)
# OPENAI_API_KEY=sk-your-key-here

# ============================================================================
# Vector Store Configuration
# ============================================================================

# Weaviate URL
# Local: http://localhost:8080
# Docker: http://weaviate:8080
# Kubernetes: http://weaviate.nephoran-system.svc.cluster.local:8080
WEAVIATE_URL=http://localhost:8080

# Weaviate API Key (optional, for production)
# WEAVIATE_API_KEY=your-weaviate-key

# ============================================================================
# RAG Pipeline Configuration
# ============================================================================

# Cache Settings
CACHE_MAX_SIZE=1000
CACHE_TTL_SECONDS=3600

# Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CONCURRENT_FILES=5

# Knowledge Base Path
KNOWLEDGE_BASE_PATH=/app/knowledge_base

# ============================================================================
# Logging Configuration
# ============================================================================

# Log Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================================
# Advanced Configuration (Optional)
# ============================================================================

# Ollama Advanced Settings
# OLLAMA_NUM_PARALLEL=2
# OLLAMA_MAX_LOADED_MODELS=2
# OLLAMA_NUM_GPU=1

# FastAPI Settings
# FASTAPI_DEBUG=false
# WORKERS=4

# ============================================================================
# Development Settings
# ============================================================================

# Enable auto-reload in development
# FASTAPI_RELOAD=true

# Development mode
# ENVIRONMENT=development
