# =============================================================================
# Nephoran Intent Operator - Consolidated CI/CD Pipeline 2025
# =============================================================================
# Production-ready CI/CD pipeline replacing all fragmented workflows
# Features: 20+ min timeouts, intelligent multi-layer caching, parallel execution
# Target: Large Go codebase (1,338+ files, 381 deps, 30+ binaries)
# Focus: Ubuntu Linux-only deployment for O-RAN/5G network orchestration
# =============================================================================

name: Nephoran CI/CD 2025 - Consolidated Pipeline

# Comprehensive trigger configuration for all scenarios
on:
  push:
    branches: 
      - main
      - integrate/**
      - feat/**
      - fix/**
      - release/**
    paths:
      - '**.go'
      - 'go.mod'
      - 'go.sum'
      - 'api/**'
      - 'cmd/**'
      - 'controllers/**'
      - 'pkg/**'
      - 'internal/**'
      - 'Makefile*'
      - 'scripts/**'
      - '.github/workflows/**'
      - 'config/**'
      - 'helm/**'
      - 'k8s/**'
  
  # pull_request: DISABLED - Duplicate of nephoran-ci-consolidated-2025.yml
  #   types: [opened, synchronize, reopened, ready_for_review]
  #   branches:
  #     - main
  #     - integrate/**
    paths:
      - '**.go'
      - 'go.mod'
      - 'go.sum'
      - 'api/**'
      - 'cmd/**'
      - 'controllers/**'
      - 'pkg/**'
      - 'internal/**'
      - 'Makefile*'
      - 'scripts/**'
      - '.github/workflows/**'
      - 'config/**'
      - 'helm/**'
      - 'k8s/**'
  
  workflow_dispatch:
    inputs:
      build_mode:
        description: 'Build execution mode'
        type: choice
        options: ['fast', 'full', 'debug', 'security']
        default: 'fast'
      skip_tests:
        description: 'Skip test execution (emergency builds)'
        type: boolean
        default: false
      force_cache_reset:
        description: 'Force cache reset (debugging)'
        type: boolean
        default: false
      run_security_scans:
        description: 'Enable comprehensive security scanning'
        type: boolean
        default: true
      parallel_jobs:
        description: 'Maximum parallel jobs (1-12)'
        type: number
        default: 8

  schedule:
    # Nightly full build and security scan (2 AM UTC)
    - cron: '0 2 * * *'

# Strict concurrency control with branch-level isolation
concurrency:
  group: nephoran-consolidated-${{ github.ref }}-${{ github.event_name }}
  cancel-in-progress: true

# Security-first permissions model
permissions:
  contents: read
  actions: read
  security-events: write
  checks: write
  pull-requests: write
  packages: write
  id-token: write  # For OIDC token access

# Production environment configuration for Ubuntu Linux-only deployment
env:
  # Go configuration - Latest stable with performance optimizations
  GO_VERSION: "1.24.6"
  GOPROXY: "https://proxy.golang.org,direct"
  GOSUMDB: "sum.golang.org"
  GOPRIVATE: "github.com/thc1006/*"
  
  # Build optimization for Linux-only deployment
  CGO_ENABLED: "0"
  GOOS: "linux"
  GOARCH: "amd64"
  GOMAXPROCS: "8"  # Optimized for GitHub runners
  GOMEMLIMIT: "6GiB"
  GOGC: "100"
  GODEBUG: "gctrace=0"
  
  # Cache configuration with multiple fallback layers
  GOCACHE: "/tmp/go-build-cache"
  GOMODCACHE: "/tmp/go-mod-cache"
  DOCKER_BUILDKIT: "1"
  BUILDX_PLATFORMS: "linux/amd64"
  
  # Pipeline configuration
  BUILD_MODE: ${{ github.event.inputs.build_mode || 'fast' }}
  SKIP_TESTS: ${{ github.event.inputs.skip_tests == 'true' }}
  FORCE_CACHE_RESET: ${{ github.event.inputs.force_cache_reset == 'true' }}
  RUN_SECURITY_SCANS: ${{ github.event.inputs.run_security_scans != 'false' }}
  MAX_PARALLEL_JOBS: ${{ github.event.inputs.parallel_jobs || 8 }}
  
  # Security configuration
  COSIGN_EXPERIMENTAL: "1"
  DOCKER_CONTENT_TRUST: "1"

jobs:
  # =============================================================================
  # STAGE 1: INTELLIGENT SETUP & CHANGE DETECTION (< 3 minutes)
  # =============================================================================
  setup:
    name: 🚀 Intelligent Setup & Change Detection
    runs-on: ubuntu-24.04
    timeout-minutes: 5
    outputs:
      # Build control outputs
      should-build: ${{ steps.changes.outputs.should-build }}
      build-matrix: ${{ steps.matrix.outputs.build-matrix }}
      test-matrix: ${{ steps.matrix.outputs.test-matrix }}
      security-matrix: ${{ steps.matrix.outputs.security-matrix }}
      
      # Cache optimization outputs
      cache-key-primary: ${{ steps.cache-strategy.outputs.primary-key }}
      cache-key-secondary: ${{ steps.cache-strategy.outputs.secondary-key }}
      cache-key-tertiary: ${{ steps.cache-strategy.outputs.tertiary-key }}
      cache-paths: ${{ steps.cache-strategy.outputs.cache-paths }}
      
      # Build metadata
      go-version: ${{ steps.go-setup.outputs.go-version }}
      commit-sha: ${{ github.sha }}
      build-timestamp: ${{ steps.metadata.outputs.build-timestamp }}
      
      # Change analysis
      api-changed: ${{ steps.changes.outputs.api }}
      controllers-changed: ${{ steps.changes.outputs.controllers }}
      cmd-changed: ${{ steps.changes.outputs.cmd }}
      pkg-changed: ${{ steps.changes.outputs.pkg }}
      
    steps:
      - name: Checkout repository with optimized settings
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Minimal depth for change detection
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate build metadata
        id: metadata
        run: |
          echo "🏗️ Generating build metadata..."
          
          # Build timestamp for cache invalidation and artifacts
          BUILD_TIMESTAMP=$(date -u +"%Y%m%d-%H%M%S")
          echo "build-timestamp=$BUILD_TIMESTAMP" >> $GITHUB_OUTPUT
          
          # Build identification
          echo "BUILD_ID=${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}" >> $GITHUB_ENV
          echo "BUILD_REF=${GITHUB_REF##*/}" >> $GITHUB_ENV
          
          echo "✅ Build metadata generated: $BUILD_TIMESTAMP"

      - name: Advanced change detection with path analysis
        id: changes
        run: |
          echo "🔍 Performing intelligent change detection..."
          
          # Determine comparison base
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            BASE_REF="origin/${{ github.base_ref }}"
            git fetch origin ${{ github.base_ref }} --depth=1
          else
            BASE_REF="HEAD~1"
          fi
          
          # Get changed files with enhanced analysis
          CHANGED_FILES=$(git diff --name-only $BASE_REF HEAD 2>/dev/null || echo "")
          
          echo "Changed files:"
          echo "$CHANGED_FILES" | head -20
          
          # Intelligent build decision logic
          SHOULD_BUILD="false"
          API_CHANGED="false"
          CONTROLLERS_CHANGED="false"
          CMD_CHANGED="false"
          PKG_CHANGED="false"
          
          if echo "$CHANGED_FILES" | grep -qE '\.(go|mod|sum)$|^(api|cmd|controllers|pkg|internal)/|Makefile|\.github/workflows'; then
            SHOULD_BUILD="true"
            echo "✅ Significant Go/build changes detected - full CI required"
            
            # Categorize changes for matrix optimization
            if echo "$CHANGED_FILES" | grep -q '^api/'; then
              API_CHANGED="true"
              echo "📡 API changes detected"
            fi
            
            if echo "$CHANGED_FILES" | grep -q '^controllers/'; then
              CONTROLLERS_CHANGED="true"
              echo "🎛️ Controller changes detected"
            fi
            
            if echo "$CHANGED_FILES" | grep -q '^cmd/'; then
              CMD_CHANGED="true"
              echo "🔧 Command binary changes detected"
            fi
            
            if echo "$CHANGED_FILES" | grep -q '^pkg/'; then
              PKG_CHANGED="true"
              echo "📦 Package changes detected"
            fi
          else
            echo "ℹ️ No significant changes - skipping build"
          fi
          
          # Set outputs for matrix generation
          echo "should-build=$SHOULD_BUILD" >> $GITHUB_OUTPUT
          echo "api=$API_CHANGED" >> $GITHUB_OUTPUT
          echo "controllers=$CONTROLLERS_CHANGED" >> $GITHUB_OUTPUT
          echo "cmd=$CMD_CHANGED" >> $GITHUB_OUTPUT
          echo "pkg=$PKG_CHANGED" >> $GITHUB_OUTPUT

      - name: Setup Go with performance optimizations
        if: steps.changes.outputs.should-build == 'true'
        id: go-setup
        uses: actions/setup-go@v5
        with:
          go-version: '1.24.6'
          cache: false  # We handle caching manually for better control
          check-latest: true

      - name: Multi-layer cache strategy implementation
        if: steps.changes.outputs.should-build == 'true'
        id: cache-strategy
        run: |
          echo "💾 Implementing intelligent multi-layer cache strategy..."
          
          # Generate comprehensive cache fingerprints
          GO_VERSION_HASH=$(echo "${{ env.GO_VERSION }}" | sha256sum | cut -c1-8)
          
          # Primary cache components with enhanced fingerprinting
          GO_SUM_HASH=""
          GO_MOD_HASH=""
          DEPS_HASH=""
          
          if [[ -f "go.sum" ]]; then
            GO_SUM_HASH=$(sha256sum go.sum | cut -d' ' -f1 | head -c16)
          else
            GO_SUM_HASH="no-sum-$(date +%Y%m%d)"
          fi
          
          if [[ -f "go.mod" ]]; then
            GO_MOD_HASH=$(sha256sum go.mod | cut -d' ' -f1 | head -c16)
          else
            GO_MOD_HASH="no-mod"
          fi
          
          # Dependencies hash from go.mod content
          if [[ -f "go.mod" ]]; then
            DEPS_HASH=$(grep -E '^[[:space:]]*[^[:space:]]+' go.mod | sha256sum | cut -c1-12)
          else
            DEPS_HASH="no-deps"
          fi
          
          # Build mode fingerprint
          BUILD_MODE_HASH=$(echo "$BUILD_MODE-${{ github.ref_name }}" | sha256sum | cut -c1-8)
          
          # Generate hierarchical cache keys for maximum reuse
          PRIMARY_KEY="nephoran-v8-ubuntu24-go${GO_VERSION_HASH}-${GO_SUM_HASH}-${GO_MOD_HASH}-${DEPS_HASH}-${BUILD_MODE_HASH}"
          SECONDARY_KEY="nephoran-v8-ubuntu24-go${GO_VERSION_HASH}-${GO_SUM_HASH}-${GO_MOD_HASH}"
          TERTIARY_KEY="nephoran-v8-ubuntu24-go${GO_VERSION_HASH}-${GO_SUM_HASH}"
          
          # Enhanced cache paths for comprehensive coverage
          CACHE_PATHS="/tmp/go-build-cache
          /tmp/go-mod-cache
          ~/.cache/go-build
          ~/go/pkg/mod
          ~/.cache/golangci-lint
          /tmp/staticcheck-cache
          ~/.docker/buildx"
          
          echo "Generated cache keys:"
          echo "Primary: $PRIMARY_KEY"
          echo "Secondary: $SECONDARY_KEY" 
          echo "Tertiary: $TERTIARY_KEY"
          
          echo "primary-key=$PRIMARY_KEY" >> $GITHUB_OUTPUT
          echo "secondary-key=$SECONDARY_KEY" >> $GITHUB_OUTPUT
          echo "tertiary-key=$TERTIARY_KEY" >> $GITHUB_OUTPUT
          echo "cache-paths<<EOF" >> $GITHUB_OUTPUT
          echo "$CACHE_PATHS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Restore multi-layer Go cache with fallbacks
        if: steps.changes.outputs.should-build == 'true'
        uses: actions/cache@v4
        with:
          path: ${{ steps.cache-strategy.outputs.cache-paths }}
          key: ${{ steps.cache-strategy.outputs.primary-key }}
          restore-keys: |
            ${{ steps.cache-strategy.outputs.secondary-key }}
            ${{ steps.cache-strategy.outputs.tertiary-key }}
            nephoran-v8-ubuntu24-go
          enableCrossOsArchive: false

      - name: Enhanced dependency download with retry logic
        if: steps.changes.outputs.should-build == 'true'
        timeout-minutes: 8
        run: |
          echo "📦 Enhanced dependency download with intelligent retry..."
          
          # Configure Git for private repositories
          git config --global url."https://${{ secrets.GITHUB_TOKEN }}@github.com/".insteadOf "https://github.com/"
          
          # Setup optimized cache directories
          sudo mkdir -p /tmp/go-build-cache /tmp/go-mod-cache
          sudo chown -R runner:runner /tmp/go-build-cache /tmp/go-mod-cache
          chmod -R 755 /tmp/go-build-cache /tmp/go-mod-cache
          
          # Download with exponential backoff retry
          MAX_ATTEMPTS=5
          ATTEMPT=1
          
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            echo "📥 Download attempt $ATTEMPT/$MAX_ATTEMPTS..."
            
            if timeout 300s go mod download -x; then
              echo "✅ Dependencies downloaded successfully on attempt $ATTEMPT"
              break
            elif [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
              echo "❌ Failed to download dependencies after $MAX_ATTEMPTS attempts"
              exit 1
            else
              WAIT_TIME=$((ATTEMPT * ATTEMPT * 10))  # Exponential backoff
              echo "⚠️ Download failed, waiting ${WAIT_TIME}s before retry..."
              sleep $WAIT_TIME
            fi
            
            ATTEMPT=$((ATTEMPT + 1))
          done
          
          # Verify module integrity
          echo "🔍 Verifying module integrity..."
          go mod verify
          
          # Cache statistics
          echo "📊 Cache statistics:"
          du -sh /tmp/go-build-cache /tmp/go-mod-cache 2>/dev/null || echo "Cache dirs not accessible"

      - name: Generate intelligent build matrices
        if: steps.changes.outputs.should-build == 'true'
        id: matrix
        run: |
          echo "🧩 Generating intelligent build matrices based on changes and mode..."
          
          # Base build matrix adapts to detected changes and build mode
          case "$BUILD_MODE" in
            "fast")
              # Fast mode: Priority-based incremental building
              if [ "${{ steps.changes.outputs.api }}" = "true" ] || [ "${{ steps.changes.outputs.controllers }}" = "true" ]; then
                build_matrix='{
                  "include": [
                    {"name": "critical-core", "priority": "critical", "timeout": 15, "parallel": 4, "components": "controllers api/intent/v1alpha1", "test_pattern": "./controllers/... ./api/intent/..."},
                    {"name": "essential-cmds", "priority": "high", "timeout": 12, "parallel": 3, "components": "cmd/intent-ingest cmd/conductor-loop cmd/webhook", "test_pattern": ""},
                    {"name": "core-packages", "priority": "high", "timeout": 10, "parallel": 3, "components": "pkg/context pkg/clients pkg/nephio", "test_pattern": "./pkg/context/... ./pkg/clients/... ./pkg/nephio/..."}
                  ]
                }'
              else
                build_matrix='{
                  "include": [
                    {"name": "changed-components", "priority": "high", "timeout": 12, "parallel": 4, "components": "auto-detect", "test_pattern": "./..."}
                  ]
                }'
              fi
              
              test_matrix='{
                "include": [
                  {"name": "unit-critical", "pattern": "./controllers/... ./pkg/controllers/... ./api/...", "timeout": 12, "coverage": true, "race": true},
                  {"name": "unit-core", "pattern": "./pkg/context/... ./pkg/clients/... ./pkg/nephio/...", "timeout": 10, "coverage": true, "race": false}
                ]
              }'
              ;;
              
            "full")
              # Full mode: Comprehensive parallel build
              build_matrix='{
                "include": [
                  {"name": "controllers-api", "priority": "critical", "timeout": 20, "parallel": 4, "components": "controllers api", "test_pattern": "./controllers/... ./pkg/controllers/... ./api/..."},
                  {"name": "core-packages", "priority": "critical", "timeout": 18, "parallel": 4, "components": "pkg/context pkg/clients pkg/nephio pkg/core pkg/security pkg/monitoring", "test_pattern": "./pkg/context/... ./pkg/clients/... ./pkg/nephio/... ./pkg/core/... ./pkg/security/... ./pkg/monitoring/..."},
                  {"name": "cmd-critical", "priority": "high", "timeout": 15, "parallel": 4, "components": "cmd/intent-ingest cmd/conductor-loop cmd/llm-processor cmd/webhook cmd/porch-publisher", "test_pattern": ""},
                  {"name": "cmd-services", "priority": "high", "timeout": 15, "parallel": 3, "components": "cmd/conductor cmd/nephio-bridge cmd/a1-sim cmd/e2-kmp-sim cmd/fcaps-sim", "test_pattern": ""},
                  {"name": "cmd-tools", "priority": "medium", "timeout": 12, "parallel": 3, "components": "cmd/o1-ves-sim cmd/oran-adaptor cmd/porch-direct cmd/porch-structured-patch", "test_pattern": ""},
                  {"name": "internal-extended", "priority": "medium", "timeout": 15, "parallel": 2, "components": "internal pkg/extended", "test_pattern": "./internal/..."}
                ]
              }'
              
              test_matrix='{
                "include": [
                  {"name": "unit-controllers", "pattern": "./controllers/...", "timeout": 15, "coverage": true, "race": true},
                  {"name": "unit-api", "pattern": "./api/...", "timeout": 12, "coverage": true, "race": false},
                  {"name": "unit-core-pkg", "pattern": "./pkg/context/... ./pkg/clients/... ./pkg/nephio/... ./pkg/core/...", "timeout": 18, "coverage": true, "race": false},
                  {"name": "unit-extended", "pattern": "./pkg/... ./internal/...", "timeout": 20, "coverage": true, "race": false},
                  {"name": "integration-smoke", "pattern": "./tests/integration/smoke/...", "timeout": 15, "coverage": false, "race": false},
                  {"name": "integration-e2e", "pattern": "./tests/integration/e2e/...", "timeout": 25, "coverage": false, "race": false}
                ]
              }'
              ;;
              
            "debug")
              # Debug mode: Single comprehensive build with extensive logging
              build_matrix='{
                "include": [
                  {"name": "debug-comprehensive", "priority": "debug", "timeout": 30, "parallel": 2, "components": "all", "test_pattern": "./..."}
                ]
              }'
              
              test_matrix='{
                "include": [
                  {"name": "debug-all", "pattern": "./...", "timeout": 35, "coverage": true, "race": true}
                ]
              }'
              ;;
              
            "security")
              # Security mode: Security-focused build with comprehensive scanning
              build_matrix='{
                "include": [
                  {"name": "security-critical", "priority": "critical", "timeout": 20, "parallel": 4, "components": "controllers api pkg/security", "test_pattern": "./controllers/... ./api/... ./pkg/security/..."},
                  {"name": "security-extended", "priority": "high", "timeout": 18, "parallel": 3, "components": "pkg cmd", "test_pattern": "./pkg/... ./cmd/..."}
                ]
              }'
              
              test_matrix='{
                "include": [
                  {"name": "security-unit", "pattern": "./controllers/... ./api/... ./pkg/security/...", "timeout": 15, "coverage": true, "race": true},
                  {"name": "security-integration", "pattern": "./tests/security/...", "timeout": 20, "coverage": false, "race": false}
                ]
              }'
              ;;
          esac
          
          # Security scan matrix (always enabled unless explicitly disabled)
          if [ "$RUN_SECURITY_SCANS" = "true" ]; then
            security_matrix='{
              "include": [
                {"name": "golang-vuln", "tool": "govulncheck", "timeout": 10, "args": "./..."},
                {"name": "static-analysis", "tool": "staticcheck", "timeout": 12, "args": "./..."},
                {"name": "security-lint", "tool": "gosec", "timeout": 8, "args": "./..."},
                {"name": "dependency-check", "tool": "nancy", "timeout": 8, "args": "go.sum"}
              ]
            }'
          else
            security_matrix='{"include": []}'
          fi
          
          echo "Build matrix: $build_matrix"
          echo "Test matrix: $test_matrix"
          echo "Security matrix: $security_matrix"
          
          echo "build-matrix=$build_matrix" >> $GITHUB_OUTPUT
          echo "test-matrix=$test_matrix" >> $GITHUB_OUTPUT
          echo "security-matrix=$security_matrix" >> $GITHUB_OUTPUT

  # =============================================================================
  # STAGE 2: PARALLEL BUILD EXECUTION (< 20 minutes)
  # =============================================================================
  build:
    name: 🏗️ Build - ${{ matrix.name }}
    runs-on: ubuntu-24.04
    needs: setup
    if: needs.setup.outputs.should-build == 'true'
    timeout-minutes: ${{ matrix.timeout }}
    
    strategy:
      fail-fast: false
      max-parallel: ${{ fromJSON(env.MAX_PARALLEL_JOBS) }}
      matrix: ${{ fromJSON(needs.setup.outputs.build-matrix) }}

    steps:
      - name: Checkout repository with sparse checkout optimization
        uses: actions/checkout@v4
        with:
          sparse-checkout: |
            api/
            cmd/
            controllers/
            pkg/
            internal/
            go.mod
            go.sum
            Makefile*
            scripts/

      - name: Setup Go with build optimizations
        uses: actions/setup-go@v5
        with:
          go-version: '1.24.6'
          cache: false

      - name: Setup optimized build environment
        run: |
          echo "🔧 Setting up optimized build environment for: ${{ matrix.name }}"
          
          # Create optimized cache directories with proper permissions
          sudo mkdir -p /tmp/go-build-cache /tmp/go-mod-cache
          sudo chown -R runner:runner /tmp/go-build-cache /tmp/go-mod-cache
          chmod -R 755 /tmp/go-build-cache /tmp/go-mod-cache
          
          # Configure Go environment for maximum performance
          export GOCACHE="/tmp/go-build-cache"
          export GOMODCACHE="/tmp/go-mod-cache"
          
          # Set parallel compilation based on matrix configuration
          export GOMAXPROCS=${{ matrix.parallel }}
          
          # Environment verification
          echo "Go version: $(go version)"
          echo "GOCACHE: $GOCACHE"
          echo "GOMODCACHE: $GOMODCACHE"
          echo "GOMAXPROCS: $GOMAXPROCS"
          echo "Available memory: $(free -h | grep Mem | awk '{print $2}')"
          echo "Available disk: $(df -h /tmp | tail -1 | awk '{print $4}')"
          
          # Store in environment for subsequent steps
          echo "GOCACHE=/tmp/go-build-cache" >> $GITHUB_ENV
          echo "GOMODCACHE=/tmp/go-mod-cache" >> $GITHUB_ENV
          echo "GOMAXPROCS=${{ matrix.parallel }}" >> $GITHUB_ENV

      - name: Restore multi-layer cache with performance monitoring
        uses: actions/cache@v4
        with:
          path: ${{ needs.setup.outputs.cache-paths }}
          key: ${{ needs.setup.outputs.cache-key-primary }}
          restore-keys: |
            ${{ needs.setup.outputs.cache-key-secondary }}
            ${{ needs.setup.outputs.cache-key-tertiary }}
          enableCrossOsArchive: false
        env:
          SEGMENT_DOWNLOAD_TIMEOUT_MINS: 5

      - name: Intelligent component building with error recovery
        timeout-minutes: ${{ matrix.timeout - 2 }}
        run: |
          echo "🏗️ Building components for ${{ matrix.name }} (Priority: ${{ matrix.priority }})"
          echo "Components: ${{ matrix.components }}"
          
          mkdir -p bin/ dist/ build-logs/
          
          # Production-optimized build flags for Linux deployment
          BUILD_FLAGS="-trimpath -ldflags='-s -w -extldflags=-static' -tags='netgo,osusergo,static_build'"
          BUILD_TAGS="netgo,osusergo,static_build,release"
          
          # Build performance metrics
          START_TIME=$(date +%s)
          BUILD_COUNT=0
          SUCCESS_COUNT=0
          FAILED_BUILDS=()
          
          # Enhanced component building function with error recovery
          build_component() {
            local component="$1"
            local timeout_duration="${2:-$(((${{ matrix.timeout }} - 2) * 60 / 4))}"
            local log_file="build-logs/${component//\//_}.log"
            
            echo "🔨 Building: $component" | tee -a "$log_file"
            BUILD_COUNT=$((BUILD_COUNT + 1))
            
            case "$component" in
              "controllers")
                echo "Building controllers package..." | tee -a "$log_file"
                if timeout ${timeout_duration}s go build $BUILD_FLAGS -tags="$BUILD_TAGS" ./controllers/... 2>&1 | tee -a "$log_file"; then
                  echo "✅ Controllers built successfully" | tee -a "$log_file"
                  SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                else
                  echo "⚠️ Controllers build failed (continuing...)" | tee -a "$log_file"
                  FAILED_BUILDS+=("controllers")
                fi
                ;;
                
              "api"|"api/intent/v1alpha1")
                echo "Building API packages..." | tee -a "$log_file"
                if timeout ${timeout_duration}s go build $BUILD_FLAGS -tags="$BUILD_TAGS" ./api/... 2>&1 | tee -a "$log_file"; then
                  echo "✅ API packages built successfully" | tee -a "$log_file"
                  SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                else
                  echo "⚠️ API packages build failed (continuing...)" | tee -a "$log_file"
                  FAILED_BUILDS+=("api")
                fi
                ;;
                
              cmd/*)
                if [[ -d "$component" && -f "$component/main.go" ]]; then
                  cmd_name=$(basename "$component")
                  echo "Building command: $cmd_name" | tee -a "$log_file"
                  
                  if timeout ${timeout_duration}s go build $BUILD_FLAGS -tags="$BUILD_TAGS" \
                    -o "bin/$cmd_name" "./$component" 2>&1 | tee -a "$log_file"; then
                    
                    if [[ -f "bin/$cmd_name" ]]; then
                      file_size=$(ls -lh "bin/$cmd_name" | awk '{print $5}')
                      echo "✅ $cmd_name: $file_size" | tee -a "$log_file"
                      SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                      
                      # Basic binary validation
                      if file "bin/$cmd_name" | grep -q "ELF.*executable"; then
                        echo "✅ $cmd_name: Valid Linux executable" | tee -a "$log_file"
                      else
                        echo "⚠️ $cmd_name: Unexpected binary format" | tee -a "$log_file"
                      fi
                    else
                      echo "❌ $cmd_name: Binary not created" | tee -a "$log_file"
                      FAILED_BUILDS+=("$cmd_name")
                    fi
                  else
                    echo "⚠️ $cmd_name build failed (continuing...)" | tee -a "$log_file"
                    FAILED_BUILDS+=("$cmd_name")
                  fi
                else
                  echo "⚠️ Command directory not found or no main.go: $component" | tee -a "$log_file"
                  FAILED_BUILDS+=("$component")
                fi
                ;;
                
              pkg/*)
                if [[ -d "$component" ]]; then
                  pkg_name=$(basename "$component")
                  echo "Building package: $component" | tee -a "$log_file"
                  
                  if timeout ${timeout_duration}s go build $BUILD_FLAGS -tags="$BUILD_TAGS" "./$component/..." 2>&1 | tee -a "$log_file"; then
                    echo "✅ $pkg_name package built successfully" | tee -a "$log_file"
                    SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                  else
                    echo "⚠️ $pkg_name package build failed (continuing...)" | tee -a "$log_file"
                    FAILED_BUILDS+=("$pkg_name")
                  fi
                fi
                ;;
                
              "internal")
                echo "Building internal packages..." | tee -a "$log_file"
                if timeout ${timeout_duration}s go build $BUILD_FLAGS -tags="$BUILD_TAGS" ./internal/... 2>&1 | tee -a "$log_file"; then
                  echo "✅ Internal packages built successfully" | tee -a "$log_file"
                  SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                else
                  echo "⚠️ Internal packages build failed (continuing...)" | tee -a "$log_file"
                  FAILED_BUILDS+=("internal")
                fi
                ;;
                
              "all"|"auto-detect")
                echo "Building all detected components..." | tee -a "$log_file"
                
                # Auto-detect and build based on changes
                if [ "${{ needs.setup.outputs.api-changed }}" = "true" ]; then
                  build_component "api" $((timeout_duration / 4))
                fi
                
                if [ "${{ needs.setup.outputs.controllers-changed }}" = "true" ]; then
                  build_component "controllers" $((timeout_duration / 4))
                fi
                
                if [ "${{ needs.setup.outputs.cmd-changed }}" = "true" ]; then
                  for cmd_dir in cmd/*/; do
                    if [[ -d "$cmd_dir" && -f "$cmd_dir/main.go" ]]; then
                      build_component "$cmd_dir" $((timeout_duration / 8))
                    fi
                  done
                fi
                
                if [ "${{ needs.setup.outputs.pkg-changed }}" = "true" ]; then
                  for pkg_dir in pkg/*/; do
                    if [[ -d "$pkg_dir" ]]; then
                      build_component "$pkg_dir" $((timeout_duration / 8))
                    fi
                  done
                fi
                ;;
                
              *)
                echo "⚠️ Unknown component pattern: $component" | tee -a "$log_file"
                FAILED_BUILDS+=("$component")
                ;;
            esac
          }
          
          # Parse and build components with intelligent parallelization
          IFS=' ' read -ra COMPONENTS <<< "${{ matrix.components }}"
          
          if [ ${#COMPONENTS[@]} -gt 1 ] && [ ${{ matrix.parallel }} -gt 2 ]; then
            # Parallel building for multiple components
            echo "🚀 Building ${#COMPONENTS[@]} components in parallel..."
            for component in "${COMPONENTS[@]}"; do
              build_component "$component" $(((${{ matrix.timeout }} - 2) * 60 / ${#COMPONENTS[@]})) &
            done
            wait  # Wait for all parallel builds to complete
          else
            # Sequential building
            for component in "${COMPONENTS[@]}"; do
              build_component "$component" $(((${{ matrix.timeout }} - 2) * 60 / ${#COMPONENTS[@]}))
            done
          fi
          
          # Build summary and metrics
          END_TIME=$(date +%s)
          BUILD_DURATION=$((END_TIME - START_TIME))
          
          echo ""
          echo "📊 Build Summary for ${{ matrix.name }}:"
          echo "  Total components: $BUILD_COUNT"
          echo "  Successful builds: $SUCCESS_COUNT" 
          echo "  Failed builds: $((BUILD_COUNT - SUCCESS_COUNT))"
          echo "  Build duration: ${BUILD_DURATION}s"
          
          if [ ${#FAILED_BUILDS[@]} -gt 0 ]; then
            echo "  Failed components: ${FAILED_BUILDS[*]}"
            echo "::warning::Some components failed to build: ${FAILED_BUILDS[*]}"
          fi
          
          # Binary inventory
          if [[ -d "bin" ]]; then
            echo ""
            echo "🎯 Generated binaries:"
            ls -lah bin/ | head -20
            
            total_size=$(du -sh bin/ 2>/dev/null | cut -f1 || echo "unknown")
            binary_count=$(ls -1 bin/ 2>/dev/null | wc -l || echo "0")
            echo "Total: $binary_count binaries, $total_size"
            
            # Store metrics for reporting
            echo "BINARY_COUNT=$binary_count" >> $GITHUB_ENV
            echo "TOTAL_SIZE=$total_size" >> $GITHUB_ENV
          else
            echo "No binaries produced (library-only build)"
            echo "BINARY_COUNT=0" >> $GITHUB_ENV
            echo "TOTAL_SIZE=0" >> $GITHUB_ENV
          fi
          
          # Success criteria - allow partial failures for non-critical components
          if [ $SUCCESS_COUNT -eq 0 ]; then
            echo "❌ All builds failed - marking job as failed"
            exit 1
          elif [ "${{ matrix.priority }}" = "critical" ] && [ ${#FAILED_BUILDS[@]} -gt 0 ]; then
            echo "❌ Critical component build failed"
            exit 1
          else
            echo "✅ Build completed with $SUCCESS_COUNT successful components"
          fi

      - name: Advanced binary validation and security checks
        if: success()
        timeout-minutes: 3
        run: |
          echo "🔍 Running advanced binary validation and security checks..."
          
          if [[ ! -d "bin" ]] || [ $(ls -1 bin/ 2>/dev/null | wc -l) -eq 0 ]; then
            echo "ℹ️ No binaries to validate"
            exit 0
          fi
          
          VALIDATION_PASSED=0
          VALIDATION_TOTAL=0
          
          for binary in bin/*; do
            if [[ -x "$binary" ]]; then
              name=$(basename "$binary")
              echo "🔍 Validating: $name"
              VALIDATION_TOTAL=$((VALIDATION_TOTAL + 1))
              
              # ELF format validation
              if file "$binary" | grep -q "ELF.*executable"; then
                echo "  ✅ Valid ELF executable format"
                
                # Architecture validation
                if file "$binary" | grep -q "x86-64"; then
                  echo "  ✅ Correct x86-64 architecture"
                else
                  echo "  ⚠️ Unexpected architecture"
                fi
                
                # Static linking validation (for CGO_ENABLED=0)
                if file "$binary" | grep -q "statically linked"; then
                  echo "  ✅ Statically linked (no runtime dependencies)"
                elif ldd "$binary" 2>/dev/null | grep -q "not a dynamic executable"; then
                  echo "  ✅ Not dynamically linked (static build confirmed)"
                else
                  echo "  ⚠️ May have runtime dependencies:"
                  ldd "$binary" 2>/dev/null | head -5 || echo "    (ldd check failed)"
                fi
                
                # Size validation
                size=$(stat -c%s "$binary")
                size_mb=$((size / 1024 / 1024))
                if [ $size_mb -lt 50 ]; then
                  echo "  ✅ Reasonable size: ${size_mb}MB"
                else
                  echo "  ⚠️ Large binary size: ${size_mb}MB"
                fi
                
                # Basic functionality test with timeout
                if timeout 10s "$binary" --version >/dev/null 2>&1 || \
                   timeout 10s "$binary" version >/dev/null 2>&1 || \
                   timeout 10s "$binary" --help >/dev/null 2>&1 || \
                   timeout 10s "$binary" -h >/dev/null 2>&1; then
                  echo "  ✅ Basic CLI functionality works"
                  VALIDATION_PASSED=$((VALIDATION_PASSED + 1))
                else
                  echo "  ℹ️ No standard CLI interface (may be service binary)"
                  VALIDATION_PASSED=$((VALIDATION_PASSED + 1))  # Count as success
                fi
              else
                echo "  ❌ Invalid executable format"
              fi
            fi
          done
          
          echo ""
          echo "📊 Binary validation summary:"
          echo "  Validated: $VALIDATION_PASSED/$VALIDATION_TOTAL"
          
          if [ $VALIDATION_PASSED -lt $VALIDATION_TOTAL ]; then
            echo "::warning::Some binaries failed validation"
          fi

      - name: Upload build artifacts with metadata
        if: always() && (matrix.priority == 'critical' || matrix.priority == 'high' || matrix.priority == 'debug')
        uses: actions/upload-artifact@v4
        with:
          name: build-${{ matrix.name }}-${{ needs.setup.outputs.build-timestamp }}
          path: |
            bin/
            build-logs/
          retention-days: 14
          compression-level: 6
          if-no-files-found: warn

      - name: Update build cache with optimizations
        if: always()
        uses: actions/cache@v4
        with:
          path: ${{ needs.setup.outputs.cache-paths }}
          key: ${{ needs.setup.outputs.cache-key-primary }}

  # =============================================================================
  # STAGE 3: COMPREHENSIVE TESTING (< 25 minutes)
  # =============================================================================
  test:
    name: 🧪 Test - ${{ matrix.name }}
    runs-on: ubuntu-24.04
    needs: [setup, build]
    if: needs.setup.outputs.should-build == 'true' && env.SKIP_TESTS != 'true'
    timeout-minutes: ${{ matrix.timeout }}
    
    strategy:
      fail-fast: false
      max-parallel: 6
      matrix: ${{ fromJSON(needs.setup.outputs.test-matrix) }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Go with test optimizations
        uses: actions/setup-go@v5
        with:
          go-version: '1.24.6'
          cache: false

      - name: Setup comprehensive test environment
        run: |
          echo "🧪 Setting up comprehensive test environment: ${{ matrix.name }}"
          
          # Enhanced cache setup
          sudo mkdir -p /tmp/go-build-cache /tmp/go-mod-cache
          sudo chown -R runner:runner /tmp/go-build-cache /tmp/go-mod-cache
          export GOCACHE="/tmp/go-build-cache"
          export GOMODCACHE="/tmp/go-mod-cache"
          echo "GOCACHE=/tmp/go-build-cache" >> $GITHUB_ENV
          echo "GOMODCACHE=/tmp/go-mod-cache" >> $GITHUB_ENV
          
          # Test-specific environment
          mkdir -p test-results coverage-reports test-artifacts
          
          # System information for debugging
          echo "Test environment info:"
          echo "  Go version: $(go version)"
          echo "  Available memory: $(free -h | grep Mem | awk '{print $2}')"
          echo "  Disk space: $(df -h /tmp | tail -1 | awk '{print $4}')"
          echo "  CPU cores: $(nproc)"

      - name: Restore Go cache for testing
        uses: actions/cache@v4
        with:
          path: ${{ needs.setup.outputs.cache-paths }}
          key: ${{ needs.setup.outputs.cache-key-primary }}
          restore-keys: |
            ${{ needs.setup.outputs.cache-key-secondary }}
            ${{ needs.setup.outputs.cache-key-tertiary }}

      - name: Setup Kubernetes test environment for controller tests
        if: contains(matrix.pattern, './controllers/') || contains(matrix.pattern, './api/') || contains(matrix.name, 'integration')
        timeout-minutes: 5
        run: |
          echo "🏗️ Setting up Kubernetes test environment..."
          
          # Install envtest for controller-runtime testing
          go install sigs.k8s.io/controller-runtime/tools/setup-envtest@latest
          
          # Setup specific Kubernetes version optimized for testing
          KUBEBUILDER_VERSION="1.31.0"
          setup-envtest use $KUBEBUILDER_VERSION --arch=amd64 --os=linux --bin-dir=/tmp/kubebuilder-bin
          
          KUBEBUILDER_ASSETS=$(setup-envtest use $KUBEBUILDER_VERSION --arch=amd64 --os=linux -p path --bin-dir=/tmp/kubebuilder-bin)
          echo "KUBEBUILDER_ASSETS=$KUBEBUILDER_ASSETS" >> $GITHUB_ENV
          
          # Verify installation
          echo "✅ Kubernetes test environment ready"
          echo "KUBEBUILDER_ASSETS: $KUBEBUILDER_ASSETS"
          ls -la "$KUBEBUILDER_ASSETS" || echo "Warning: kubebuilder assets not found"

      - name: Execute comprehensive tests with advanced configuration
        timeout-minutes: ${{ matrix.timeout - 3 }}
        env:
          KUBEBUILDER_ASSETS: ${{ env.KUBEBUILDER_ASSETS }}
          CGO_ENABLED: ${{ matrix.race == true && '1' || '0' }}
        run: |
          echo "🚀 Executing tests: ${{ matrix.pattern }} (Coverage: ${{ matrix.coverage }}, Race: ${{ matrix.race }})"
          
          # Advanced test configuration
          TEST_FLAGS="-v -timeout=${{ matrix.timeout - 1 }}m -parallel=6"
          TEST_OUTPUT_FILE="test-results/output-${{ matrix.name }}.log"
          JUNIT_OUTPUT_FILE="test-results/junit-${{ matrix.name }}.xml"
          
          # Race detection for critical paths
          if [[ "${{ matrix.race }}" == "true" ]]; then
            TEST_FLAGS="$TEST_FLAGS -race"
            echo "🏃 Race detection enabled for ${{ matrix.name }}"
            # Enable CGO for race detection
            export CGO_ENABLED=1
          fi
          
          # Coverage collection with enhanced reporting
          if [[ "${{ matrix.coverage }}" == "true" ]]; then
            COVERAGE_FILE="coverage-reports/coverage-${{ matrix.name }}.out"
            TEST_FLAGS="$TEST_FLAGS -coverprofile=$COVERAGE_FILE -covermode=atomic"
            echo "📊 Coverage collection enabled: $COVERAGE_FILE"
          fi
          
          # JSON output for better parsing
          TEST_FLAGS="$TEST_FLAGS -json"
          
          echo "Executing: go test $TEST_FLAGS ${{ matrix.pattern }}"
          echo "Start time: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          
          # Execute tests with comprehensive error handling
          TEST_START_TIME=$(date +%s)
          
          if go test $TEST_FLAGS ${{ matrix.pattern }} 2>&1 | tee "$TEST_OUTPUT_FILE"; then
            TEST_EXIT_CODE=0
            echo "✅ Tests passed for ${{ matrix.name }}"
          else
            TEST_EXIT_CODE=$?
            echo "❌ Tests failed for ${{ matrix.name }} (exit code: $TEST_EXIT_CODE)"
          fi
          
          TEST_END_TIME=$(date +%s)
          TEST_DURATION=$((TEST_END_TIME - TEST_START_TIME))
          
          # Parse test results from JSON output
          if command -v jq >/dev/null 2>&1; then
            echo "📊 Parsing test results..."
            
            # Extract test statistics
            TOTAL_TESTS=$(grep '"Action":"pass"\|"Action":"fail"' "$TEST_OUTPUT_FILE" | grep '"Test":' | wc -l || echo "0")
            PASSED_TESTS=$(grep '"Action":"pass"' "$TEST_OUTPUT_FILE" | grep '"Test":' | wc -l || echo "0")
            FAILED_TESTS=$(grep '"Action":"fail"' "$TEST_OUTPUT_FILE" | grep '"Test":' | wc -l || echo "0")
            
            echo "Test Summary for ${{ matrix.name }}:"
            echo "  Total tests: $TOTAL_TESTS"
            echo "  Passed: $PASSED_TESTS"
            echo "  Failed: $FAILED_TESTS"
            echo "  Duration: ${TEST_DURATION}s"
            
            # Store results for status reporting
            cat > "test-results/summary-${{ matrix.name }}.json" <<EOF
          {
            "name": "${{ matrix.name }}",
            "total": $TOTAL_TESTS,
            "passed": $PASSED_TESTS,
            "failed": $FAILED_TESTS,
            "duration": $TEST_DURATION,
            "exit_code": $TEST_EXIT_CODE
          }
          EOF
          else
            echo "jq not available - basic result parsing"
            grep -E "(PASS|FAIL|ok |FAIL)" "$TEST_OUTPUT_FILE" | tail -10
          fi
          
          # Store exit status
          echo "test_status=$([[ $TEST_EXIT_CODE -eq 0 ]] && echo "success" || echo "failed")" > "test-results/status-${{ matrix.name }}.txt"
          echo "exit_code=$TEST_EXIT_CODE" >> "test-results/status-${{ matrix.name }}.txt"
          echo "duration=$TEST_DURATION" >> "test-results/status-${{ matrix.name }}.txt"
          
          # Don't fail the job immediately - collect all test results first
          if [ $TEST_EXIT_CODE -ne 0 ]; then
            echo "::warning::Test suite ${{ matrix.name }} failed with exit code $TEST_EXIT_CODE"
          fi
          
          # Return the actual exit code for final decision
          exit $TEST_EXIT_CODE

      - name: Process and analyze coverage results
        if: always() && matrix.coverage == true
        timeout-minutes: 3
        run: |
          coverage_file="coverage-reports/coverage-${{ matrix.name }}.out"
          
          if [[ -f "$coverage_file" ]]; then
            echo "📊 Processing coverage for ${{ matrix.name }}..."
            
            # Generate comprehensive coverage reports
            go tool cover -html="$coverage_file" -o "coverage-reports/coverage-${{ matrix.name }}.html"
            go tool cover -func="$coverage_file" > "coverage-reports/coverage-func-${{ matrix.name }}.txt"
            
            # Extract and analyze coverage metrics
            coverage_pct=$(go tool cover -func="$coverage_file" | grep "total:" | awk '{print $3}' | tr -d '%' || echo "0")
            coverage_num=$(echo "$coverage_pct" | cut -d. -f1)
            
            echo "Coverage analysis for ${{ matrix.name }}:"
            echo "  Coverage percentage: $coverage_pct%"
            
            # Coverage quality assessment
            if [ "$coverage_num" -ge 80 ]; then
              echo "  ✅ Excellent coverage (≥80%)"
              coverage_quality="excellent"
            elif [ "$coverage_num" -ge 60 ]; then
              echo "  ✅ Good coverage (≥60%)"
              coverage_quality="good"
            elif [ "$coverage_num" -ge 40 ]; then
              echo "  ⚠️ Moderate coverage (≥40%)"
              coverage_quality="moderate"
            else
              echo "  ❌ Low coverage (<40%)"
              coverage_quality="low"
            fi
            
            # Store coverage metrics
            cat > "test-results/coverage-${{ matrix.name }}.json" <<EOF
          {
            "name": "${{ matrix.name }}",
            "percentage": $coverage_pct,
            "quality": "$coverage_quality"
          }
          EOF
            
            # Generate coverage summary for step output
            echo "## Coverage Report - ${{ matrix.name }}" >> $GITHUB_STEP_SUMMARY
            echo "**Coverage:** $coverage_pct% ($coverage_quality)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Show top uncovered functions for improvement suggestions
            echo "### Coverage Details" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            tail -10 "coverage-reports/coverage-func-${{ matrix.name }}.txt" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ No coverage file found for ${{ matrix.name }}"
            echo "Expected: $coverage_file"
          fi

      - name: Upload comprehensive test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.name }}-${{ needs.setup.outputs.build-timestamp }}
          path: |
            test-results/
            coverage-reports/
            test-artifacts/
          retention-days: 14
          compression-level: 6

  # =============================================================================
  # STAGE 4: SECURITY & QUALITY ASSURANCE (< 15 minutes)  
  # =============================================================================
  security:
    name: 🔒 Security - ${{ matrix.name }}
    runs-on: ubuntu-24.04
    needs: [setup, build]
    if: needs.setup.outputs.should-build == 'true' && env.RUN_SECURITY_SCANS == 'true'
    timeout-minutes: ${{ matrix.timeout }}
    
    strategy:
      fail-fast: false
      max-parallel: 4
      matrix: ${{ fromJSON(needs.setup.outputs.security-matrix) }}

    steps:
      - name: Checkout repository with security focus
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for security analysis

      - name: Setup Go with security tools
        uses: actions/setup-go@v5
        with:
          go-version: '1.24.6'
          cache: false

      - name: Restore Go cache for security tools
        uses: actions/cache@v4
        with:
          path: ${{ needs.setup.outputs.cache-paths }}
          key: ${{ needs.setup.outputs.cache-key-primary }}
          restore-keys: |
            ${{ needs.setup.outputs.cache-key-secondary }}

      - name: Setup security scanning environment
        run: |
          echo "🔒 Setting up security scanning environment for: ${{ matrix.name }}"
          
          mkdir -p security-reports security-artifacts
          export GOCACHE="/tmp/go-build-cache"
          export GOMODCACHE="/tmp/go-mod-cache"
          echo "GOCACHE=/tmp/go-build-cache" >> $GITHUB_ENV
          echo "GOMODCACHE=/tmp/go-mod-cache" >> $GITHUB_ENV

      - name: Execute security scanning - ${{ matrix.tool }}
        timeout-minutes: ${{ matrix.timeout - 2 }}
        run: |
          echo "🔍 Running ${{ matrix.tool }} security scan..."
          
          SCAN_START_TIME=$(date +%s)
          SCAN_SUCCESS=true
          REPORT_FILE="security-reports/${{ matrix.name }}-report.txt"
          JSON_REPORT="security-reports/${{ matrix.name }}-report.json"
          
          case "${{ matrix.tool }}" in
            "govulncheck")
              echo "🔍 Running Go vulnerability check..."
              if ! command -v govulncheck >/dev/null 2>&1; then
                go install golang.org/x/vuln/cmd/govulncheck@latest
              fi
              
              if govulncheck ${{ matrix.args }} 2>&1 | tee "$REPORT_FILE"; then
                echo "✅ No vulnerabilities found"
                echo '{"status": "clean", "vulnerabilities": 0}' > "$JSON_REPORT"
              else
                echo "⚠️ Vulnerabilities detected"
                vuln_count=$(grep -c "Vulnerability" "$REPORT_FILE" || echo "unknown")
                echo "{\"status\": \"vulnerabilities\", \"count\": \"$vuln_count\"}" > "$JSON_REPORT"
                SCAN_SUCCESS=false
              fi
              ;;
              
            "staticcheck")
              echo "🔍 Running staticcheck analysis..."
              if ! command -v staticcheck >/dev/null 2>&1; then
                go install honnef.co/go/tools/cmd/staticcheck@latest
              fi
              
              if staticcheck ${{ matrix.args }} 2>&1 | tee "$REPORT_FILE"; then
                echo "✅ Staticcheck passed"
                echo '{"status": "clean", "issues": 0}' > "$JSON_REPORT"
              else
                issue_count=$(wc -l < "$REPORT_FILE" || echo "unknown")
                echo "⚠️ Staticcheck found issues: $issue_count"
                echo "{\"status\": \"issues\", \"count\": $issue_count}" > "$JSON_REPORT"
                # Don't fail for staticcheck issues - treat as warnings
              fi
              ;;
              
            "gosec")
              echo "🔍 Running gosec security analysis..."
              if ! command -v gosec >/dev/null 2>&1; then
                curl -sfL https://raw.githubusercontent.com/securecodewarrior/gosec/master/install.sh | sh -s -- -b $(go env GOPATH)/bin
              fi
              
              if gosec -fmt json -out "$JSON_REPORT" ${{ matrix.args }} 2>&1 | tee "$REPORT_FILE"; then
                echo "✅ Gosec security check passed"
              else
                echo "⚠️ Security issues detected by gosec"
                if [[ -f "$JSON_REPORT" ]]; then
                  issue_count=$(jq -r '.Stats.found // 0' "$JSON_REPORT" 2>/dev/null || echo "unknown")
                  echo "Security issues found: $issue_count"
                fi
                SCAN_SUCCESS=false
              fi
              ;;
              
            "nancy")
              echo "🔍 Running Nancy dependency vulnerability check..."
              if ! command -v nancy >/dev/null 2>&1; then
                go install github.com/sonatypecommunity/nancy@latest
              fi
              
              if go list -json -deps ./... | nancy sleuth --loud 2>&1 | tee "$REPORT_FILE"; then
                echo "✅ No vulnerable dependencies found"
                echo '{"status": "clean", "vulnerabilities": 0}' > "$JSON_REPORT"
              else
                vuln_count=$(grep -c "Vulnerability" "$REPORT_FILE" || echo "unknown")
                echo "⚠️ Vulnerable dependencies detected: $vuln_count"
                echo "{\"status\": \"vulnerabilities\", \"count\": \"$vuln_count\"}" > "$JSON_REPORT"
                SCAN_SUCCESS=false
              fi
              ;;
              
            *)
              echo "❌ Unknown security tool: ${{ matrix.tool }}"
              exit 1
              ;;
          esac
          
          SCAN_END_TIME=$(date +%s)
          SCAN_DURATION=$((SCAN_END_TIME - SCAN_START_TIME))
          
          echo "Security scan completed in ${SCAN_DURATION}s"
          echo "duration=$SCAN_DURATION" >> "$REPORT_FILE"
          
          # Update JSON report with metadata
          if [[ -f "$JSON_REPORT" ]]; then
            jq ". + {\"tool\": \"${{ matrix.tool }}\", \"duration\": $SCAN_DURATION, \"timestamp\": \"$(date -u)\", \"success\": $SCAN_SUCCESS}" "$JSON_REPORT" > "${JSON_REPORT}.tmp" && mv "${JSON_REPORT}.tmp" "$JSON_REPORT"
          fi
          
          # Don't fail job for most security issues - collect all results
          if [[ "${{ matrix.tool }}" == "govulncheck" ]] && [[ "$SCAN_SUCCESS" == "false" ]]; then
            echo "::error::Critical vulnerabilities found by govulncheck"
            exit 1
          elif [[ "$SCAN_SUCCESS" == "false" ]]; then
            echo "::warning::Security issues detected by ${{ matrix.tool }}"
          fi

      - name: Upload security scan results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-${{ matrix.name }}-${{ needs.setup.outputs.build-timestamp }}
          path: |
            security-reports/
            security-artifacts/
          retention-days: 30  # Keep security reports longer
          compression-level: 6

  # =============================================================================
  # STAGE 5: QUALITY ASSURANCE & LINTING (< 12 minutes)
  # =============================================================================
  quality:
    name: 📋 Code Quality & Linting
    runs-on: ubuntu-24.04
    needs: setup
    if: needs.setup.outputs.should-build == 'true'
    timeout-minutes: 15

    steps:
      - name: Checkout repository with full history
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better lint analysis

      - name: Setup Go for quality tools
        uses: actions/setup-go@v5
        with:
          go-version: '1.24.6'
          cache: false

      - name: Restore Go cache for quality tools
        uses: actions/cache@v4
        with:
          path: ${{ needs.setup.outputs.cache-paths }}
          key: ${{ needs.setup.outputs.cache-key-primary }}
          restore-keys: |
            ${{ needs.setup.outputs.cache-key-secondary }}

      - name: Setup quality analysis environment
        run: |
          echo "📋 Setting up code quality analysis environment..."
          
          mkdir -p quality-reports lint-cache
          export GOCACHE="/tmp/go-build-cache"
          export GOMODCACHE="/tmp/go-mod-cache"
          echo "GOCACHE=/tmp/go-build-cache" >> $GITHUB_ENV
          echo "GOMODCACHE=/tmp/go-mod-cache" >> $GITHUB_ENV
          
          # Download dependencies if not cached
          go mod download

      - name: Go vet comprehensive analysis
        timeout-minutes: 3
        run: |
          echo "🔍 Running comprehensive go vet analysis..."
          
          VET_REPORT="quality-reports/vet-report.txt"
          
          if go vet -all ./... 2>&1 | tee "$VET_REPORT"; then
            echo "✅ go vet analysis passed"
            vet_status="passed"
            issue_count=0
          else
            echo "⚠️ go vet found issues"
            issue_count=$(wc -l < "$VET_REPORT" || echo "0")
            vet_status="issues"
            echo "::warning::go vet found $issue_count issues"
          fi
          
          # Store results
          cat > "quality-reports/vet-summary.json" <<EOF
          {
            "tool": "go vet",
            "status": "$vet_status",
            "issues": $issue_count,
            "timestamp": "$(date -u)"
          }
          EOF

      - name: Enhanced staticcheck analysis with caching
        uses: dominikh/staticcheck-action@v1.3.1
        with:
          version: "2024.1.1"
          install-go: false
          cache-key: staticcheck-${{ needs.setup.outputs.cache-key-primary }}
          working-directory: ""

      - name: golangci-lint comprehensive analysis
        uses: golangci/golangci-lint-action@v6
        with:
          version: v1.65.2
          args: --timeout=10m --verbose --issues-exit-code=0 --out-format=json:quality-reports/golangci-lint.json,colored-line-number
          skip-cache: false
          skip-save-cache: false
          only-new-issues: false

      - name: Go module tidiness verification
        timeout-minutes: 2
        run: |
          echo "🔍 Verifying go.mod and go.sum tidiness..."
          
          # Create backups
          cp go.mod go.mod.backup
          cp go.sum go.sum.backup
          
          # Run go mod tidy
          go mod tidy
          
          # Check for changes
          if diff go.mod go.mod.backup && diff go.sum go.sum.backup; then
            echo "✅ go.mod and go.sum are properly maintained"
            tidy_status="clean"
          else
            echo "❌ go.mod or go.sum requires tidying"
            echo "Changes detected:"
            git diff --no-index go.mod.backup go.mod || true
            git diff --no-index go.sum.backup go.sum || true
            tidy_status="dirty"
            echo "::error::Run 'go mod tidy' locally and commit the changes"
            exit 1
          fi
          
          # Store results
          cat > "quality-reports/tidy-summary.json" <<EOF
          {
            "tool": "go mod tidy",
            "status": "$tidy_status",
            "timestamp": "$(date -u)"
          }
          EOF

      - name: Generate comprehensive quality report
        if: always()
        run: |
          echo "📊 Generating comprehensive quality report..."
          
          # Aggregate all quality metrics
          cat > "quality-reports/quality-summary.json" <<EOF
          {
            "timestamp": "$(date -u)",
            "commit": "${{ github.sha }}",
            "branch": "${{ github.ref_name }}",
            "tools": {
              "go_vet": $(cat quality-reports/vet-summary.json 2>/dev/null || echo '{"status": "not_run"}'),
              "staticcheck": {"status": "completed", "timestamp": "$(date -u)"},
              "golangci_lint": {"status": "completed", "timestamp": "$(date -u)"},
              "mod_tidy": $(cat quality-reports/tidy-summary.json 2>/dev/null || echo '{"status": "not_run"}')
            }
          }
          EOF
          
          echo "📋 Quality analysis summary:"
          cat quality-reports/quality-summary.json | jq . || cat quality-reports/quality-summary.json

      - name: Upload quality analysis results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-reports-${{ needs.setup.outputs.build-timestamp }}
          path: quality-reports/
          retention-days: 14
          compression-level: 6

  # =============================================================================
  # STAGE 6: INTEGRATION & SMOKE TESTS (< 15 minutes)
  # =============================================================================
  integration:
    name: 🔗 Integration & Smoke Tests
    runs-on: ubuntu-24.04
    needs: [setup, build]
    if: needs.setup.outputs.should-build == 'true' && env.BUILD_MODE != 'fast'
    timeout-minutes: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all build artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: build-*
          path: artifacts/
          merge-multiple: true

      - name: Prepare comprehensive integration environment
        run: |
          echo "🔧 Preparing comprehensive integration test environment..."
          
          mkdir -p bin/ integration-results/ smoke-results/
          
          # Collect all binaries from artifacts
          find artifacts/ -name "bin" -type d | while read bin_dir; do
            if [[ -d "$bin_dir" ]]; then
              echo "Copying binaries from: $bin_dir"
              cp -r "$bin_dir"/* bin/ 2>/dev/null || true
            fi
          done
          
          # Make all binaries executable
          chmod +x bin/* 2>/dev/null || true
          
          echo "Available binaries for integration testing:"
          ls -la bin/ | head -20 || echo "No binaries found"
          
          binary_count=$(ls -1 bin/ 2>/dev/null | wc -l || echo "0")
          echo "Total binaries available: $binary_count"
          
          if [ "$binary_count" -eq 0 ]; then
            echo "::warning::No binaries available for integration testing"
            echo "SKIP_INTEGRATION=true" >> $GITHUB_ENV
          else
            echo "SKIP_INTEGRATION=false" >> $GITHUB_ENV
          fi

      - name: Comprehensive binary smoke tests with error handling
        if: env.SKIP_INTEGRATION != 'true'
        timeout-minutes: 12
        run: |
          echo "🔥 Running comprehensive binary smoke tests..."
          
          test_count=0
          success_count=0
          error_count=0
          timeout_count=0
          declare -a failed_binaries=()
          declare -a successful_binaries=()
          
          SMOKE_START_TIME=$(date +%s)
          
          for binary in bin/*; do
            if [[ -x "$binary" ]]; then
              name=$(basename "$binary")
              echo ""
              echo "🧪 Testing binary: $name"
              test_count=$((test_count + 1))
              
              test_result="unknown"
              test_output=""
              
              # Enhanced binary validation
              if file "$binary" 2>/dev/null | grep -q "ELF.*executable"; then
                echo "  ✅ Valid Linux ELF executable"
                
                # Architecture check
                if file "$binary" | grep -q "x86-64"; then
                  echo "  ✅ Correct x86-64 architecture"
                else
                  echo "  ⚠️ Unexpected architecture: $(file "$binary" | cut -d: -f2)"
                fi
                
                # Size analysis
                size=$(stat -c%s "$binary")
                size_mb=$((size / 1024 / 1024))
                echo "  📦 Binary size: ${size_mb}MB"
                
                # Comprehensive CLI interface testing
                cli_success=false
                
                # Test common CLI patterns with individual timeouts
                for cli_pattern in "--version" "version" "--help" "-h" "help"; do
                  echo "    Testing: $name $cli_pattern"
                  
                  if timeout 15s "$binary" $cli_pattern >/tmp/cli_test 2>&1; then
                    output_size=$(wc -c < /tmp/cli_test)
                    if [ $output_size -gt 0 ]; then
                      echo "    ✅ $cli_pattern: Success (${output_size} bytes output)"
                      test_output=$(head -3 /tmp/cli_test | tr '\n' '; ')
                      cli_success=true
                      test_result="cli_success"
                      break
                    fi
                  else
                    cli_exit_code=$?
                    if [ $cli_exit_code -eq 124 ]; then
                      echo "    ⏰ $cli_pattern: Timeout (15s)"
                      timeout_count=$((timeout_count + 1))
                      test_result="timeout"
                    else
                      echo "    ⚠️ $cli_pattern: Exit code $cli_exit_code"
                    fi
                  fi
                done
                
                if [ "$cli_success" = true ]; then
                  echo "  ✅ CLI interface working: $test_output"
                  successful_binaries+=("$name")
                  success_count=$((success_count + 1))
                else
                  # Try running without arguments (service-style binary)
                  echo "    Testing: $name (no arguments - service mode)"
                  if timeout 5s "$binary" >/tmp/service_test 2>&1; then
                    echo "  ✅ Service-style binary (no CLI interface needed)"
                    test_result="service_success"
                    successful_binaries+=("$name")
                    success_count=$((success_count + 1))
                  else
                    service_exit_code=$?
                    if [ $service_exit_code -eq 124 ]; then
                      echo "  ✅ Service binary (runs indefinitely - expected behavior)"
                      test_result="service_daemon"
                      successful_binaries+=("$name")
                      success_count=$((success_count + 1))
                    else
                      echo "  ❌ All interface tests failed"
                      test_result="all_failed"
                      failed_binaries+=("$name")
                      error_count=$((error_count + 1))
                    fi
                  fi
                fi
              else
                echo "  ❌ Invalid executable format"
                test_result="invalid_format"
                failed_binaries+=("$name")
                error_count=$((error_count + 1))
              fi
              
              # Store individual test result
              cat > "smoke-results/${name}-result.json" <<EOF
          {
            "binary": "$name",
            "result": "$test_result",
            "output": "$test_output",
            "size_mb": $size_mb,
            "timestamp": "$(date -u)"
          }
          EOF
            fi
          done
          
          SMOKE_END_TIME=$(date +%s)
          SMOKE_DURATION=$((SMOKE_END_TIME - SMOKE_START_TIME))
          
          # Comprehensive smoke test summary
          echo ""
          echo "📊 Comprehensive Smoke Test Results:"
          echo "  Total binaries tested: $test_count"
          echo "  Successful tests: $success_count"
          echo "  Failed tests: $error_count"
          echo "  Timeout tests: $timeout_count"
          echo "  Test duration: ${SMOKE_DURATION}s"
          echo ""
          
          if [ ${#successful_binaries[@]} -gt 0 ]; then
            echo "✅ Successful binaries:"
            printf '  %s\n' "${successful_binaries[@]}"
          fi
          
          if [ ${#failed_binaries[@]} -gt 0 ]; then
            echo "❌ Failed binaries:"
            printf '  %s\n' "${failed_binaries[@]}"
          fi
          
          # Store comprehensive results
          cat > "integration-results/smoke-test-summary.json" <<EOF
          {
            "total": $test_count,
            "successful": $success_count,
            "failed": $error_count,
            "timeouts": $timeout_count,
            "duration": $SMOKE_DURATION,
            "successful_binaries": $(printf '%s\n' "${successful_binaries[@]}" | jq -R . | jq -s . || echo '[]'),
            "failed_binaries": $(printf '%s\n' "${failed_binaries[@]}" | jq -R . | jq -s . || echo '[]'),
            "timestamp": "$(date -u)"
          }
          EOF
          
          # Success criteria: At least 70% of binaries should work
          success_rate=0
          if [ $test_count -gt 0 ]; then
            success_rate=$((success_count * 100 / test_count))
          fi
          
          echo "Success rate: ${success_rate}%"
          
          if [ $success_count -gt 0 ] && [ $success_rate -ge 70 ]; then
            echo "✅ Integration smoke tests passed (${success_rate}% success rate)"
          elif [ $success_count -eq 0 ]; then
            echo "❌ No binaries passed smoke tests"
            exit 1
          else
            echo "⚠️ Low success rate (${success_rate}%) but some binaries work"
            echo "::warning::Smoke test success rate below 70%: ${success_rate}%"
          fi

      - name: Advanced Kubernetes manifest validation
        timeout-minutes: 5
        run: |
          echo "🔍 Advanced Kubernetes manifest validation..."
          
          manifest_count=0
          valid_manifests=0
          invalid_manifests=0
          
          # Enhanced manifest discovery
          while IFS= read -r -d '' yaml_file; do
            # Check if file looks like a K8s manifest
            if [[ "$yaml_file" =~ \.(yaml|yml)$ ]] && 
               ([[ "$yaml_file" == *"k8s"* ]] || 
                [[ "$yaml_file" == *"kubernetes"* ]] || 
                [[ "$yaml_file" == *"manifests"* ]] || 
                [[ "$yaml_file" == *"deploy"* ]] ||
                [[ "$yaml_file" == *"config"* ]] ||
                [[ "$yaml_file" == *"helm"* ]]); then
              
              echo "🔍 Validating: $yaml_file"
              manifest_count=$((manifest_count + 1))
              
              # YAML syntax validation
              if python3 -c "
              import yaml, sys
              try:
                  with open('$yaml_file', 'r') as f:
                      docs = list(yaml.safe_load_all(f))
                  print(f'Valid YAML with {len(docs)} document(s)')
                  sys.exit(0)
              except Exception as e:
                  print(f'YAML error: {e}')
                  sys.exit(1)
              " 2>&1; then
                echo "  ✅ Valid YAML syntax"
                
                # K8s resource validation
                if grep -q "apiVersion\|kind" "$yaml_file"; then
                  echo "  ✅ Contains Kubernetes resource fields"
                  valid_manifests=$((valid_manifests + 1))
                else
                  echo "  ℹ️ YAML file but not K8s manifest"
                  valid_manifests=$((valid_manifests + 1))
                fi
              else
                echo "  ❌ YAML syntax errors detected"
                invalid_manifests=$((invalid_manifests + 1))
              fi
            fi
          done < <(find . -name "*.yaml" -o -name "*.yml" -print0 2>/dev/null)
          
          echo ""
          echo "📊 Manifest Validation Summary:"
          echo "  Total manifests found: $manifest_count"
          echo "  Valid manifests: $valid_manifests"  
          echo "  Invalid manifests: $invalid_manifests"
          
          if [ $manifest_count -eq 0 ]; then
            echo "ℹ️ No Kubernetes manifests found to validate"
          elif [ $invalid_manifests -gt 0 ]; then
            echo "⚠️ Some manifests have validation issues"
            echo "::warning::$invalid_manifests manifest(s) failed validation"
          else
            echo "✅ All manifests validated successfully"
          fi
          
          # Store manifest validation results
          cat > "integration-results/manifest-validation.json" <<EOF
          {
            "total": $manifest_count,
            "valid": $valid_manifests,
            "invalid": $invalid_manifests,
            "timestamp": "$(date -u)"
          }
          EOF

      - name: Upload comprehensive integration results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-results-${{ needs.setup.outputs.build-timestamp }}
          path: |
            integration-results/
            smoke-results/
          retention-days: 14
          compression-level: 6

  # =============================================================================
  # STAGE 7: CONTAINERIZATION & DEPLOYMENT PREP (< 10 minutes)
  # =============================================================================
  containerization:
    name: 🐳 Container Build & Security
    runs-on: ubuntu-24.04
    needs: [setup, build, test]
    if: needs.setup.outputs.should-build == 'true' && (github.ref == 'refs/heads/main' || contains(github.ref, 'integrate/') || env.BUILD_MODE == 'full')
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx with enhanced configuration
        uses: docker/setup-buildx-action@v3
        with:
          driver: docker-container
          use: true
          buildkitd-flags: |
            --allow-insecure-entitlement network.host
            --allow-insecure-entitlement security.insecure

      - name: Download build artifacts for containerization
        uses: actions/download-artifact@v4
        with:
          pattern: build-*
          path: artifacts/
          merge-multiple: true

      - name: Prepare container build environment
        run: |
          echo "🐳 Preparing container build environment..."
          
          # Collect binaries for containerization
          mkdir -p bin/
          find artifacts/ -name "bin" -type d | while read bin_dir; do
            if [[ -d "$bin_dir" ]]; then
              cp -r "$bin_dir"/* bin/ 2>/dev/null || true
            fi
          done
          
          chmod +x bin/* 2>/dev/null || true
          
          echo "Binaries available for containerization:"
          ls -la bin/ | head -10 || echo "No binaries found"
          
          # Generate container metadata
          echo "BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')" >> $GITHUB_ENV
          echo "VCS_REF=${{ github.sha }}" >> $GITHUB_ENV
          echo "VERSION=${GITHUB_REF##*/}" >> $GITHUB_ENV

      - name: Build production-ready container images
        timeout-minutes: 12
        run: |
          echo "🏗️ Building production-ready container images..."
          
          # Multi-stage Dockerfile for optimal security and size
          cat > Dockerfile.nephoran <<'EOF'
          # =============================================================================
          # Nephoran Intent Operator - Production Container
          # Multi-stage build for security and minimal attack surface
          # =============================================================================
          
          # Stage 1: Minimal runtime base
          FROM gcr.io/distroless/static-debian12:nonroot AS runtime
          
          # Stage 2: Final production image
          FROM runtime AS final
          
          # Security and compliance labels
          LABEL org.opencontainers.image.title="Nephoran Intent Operator"
          LABEL org.opencontainers.image.description="Cloud-native Kubernetes operator for O-RAN/5G network orchestration"
          LABEL org.opencontainers.image.url="https://github.com/thc1006/nephoran-intent-operator"
          LABEL org.opencontainers.image.source="https://github.com/thc1006/nephoran-intent-operator"
          LABEL org.opencontainers.image.version="${VERSION}"
          LABEL org.opencontainers.image.created="${BUILD_DATE}"
          LABEL org.opencontainers.image.revision="${VCS_REF}"
          LABEL org.opencontainers.image.licenses="Apache-2.0"
          LABEL org.opencontainers.image.vendor="THC1006"
          
          # Copy statically-linked binaries
          COPY bin/ /usr/local/bin/
          
          # Set non-root user (already configured in distroless)
          USER 65532:65532
          
          # Health check for container orchestration
          HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
            CMD ["/usr/local/bin/intent-ingest", "--health-check"]
          
          # Default entrypoint
          ENTRYPOINT ["/usr/local/bin/intent-ingest"]
          CMD ["--help"]
          EOF
          
          # Build container with security scanning
          echo "Building container image..."
          docker buildx build \
            --platform linux/amd64 \
            --build-arg BUILD_DATE="$BUILD_DATE" \
            --build-arg VCS_REF="$VCS_REF" \
            --build-arg VERSION="$VERSION" \
            --tag nephoran-intent-operator:latest \
            --tag nephoran-intent-operator:${{ github.sha }} \
            --file Dockerfile.nephoran \
            --load \
            .
          
          echo "✅ Container build completed"
          
          # Basic container validation
          echo "🔍 Container validation:"
          docker images nephoran-intent-operator:latest --format "table {{.Repository}}:{{.Tag}}\t{{.Size}}\t{{.CreatedAt}}"
          
          # Security scan preparation
          echo "Preparing container for security scanning..."
          docker save nephoran-intent-operator:latest -o nephoran-container.tar

      - name: Container security scanning with Trivy
        uses: aquasecurity/trivy-action@master
        with:
          input: nephoran-container.tar
          format: 'sarif'
          output: 'container-security-report.sarif'
          exit-code: '0'  # Don't fail on vulnerabilities, just report
          severity: 'CRITICAL,HIGH,MEDIUM'

      - name: Container vulnerability analysis
        run: |
          echo "🔒 Analyzing container security scan results..."
          
          if [[ -f "container-security-report.sarif" ]]; then
            # Extract vulnerability summary
            if command -v jq >/dev/null 2>&1; then
              critical_vulns=$(jq '[.runs[0].results[] | select(.level == "error")] | length' container-security-report.sarif 2>/dev/null || echo "0")
              high_vulns=$(jq '[.runs[0].results[] | select(.level == "warning")] | length' container-security-report.sarif 2>/dev/null || echo "0")
              
              echo "Container security analysis:"
              echo "  Critical vulnerabilities: $critical_vulns"
              echo "  High vulnerabilities: $high_vulns"
              
              if [ "$critical_vulns" -gt 0 ]; then
                echo "::warning::Container has $critical_vulns critical vulnerabilities"
              fi
              
              if [ "$high_vulns" -gt 10 ]; then
                echo "::warning::Container has $high_vulns high vulnerabilities"
              fi
            fi
            
            echo "✅ Security scan completed - check artifacts for details"
          else
            echo "⚠️ Security scan report not found"
          fi

      - name: Upload container artifacts and security reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: container-artifacts-${{ needs.setup.outputs.build-timestamp }}
          path: |
            nephoran-container.tar
            container-security-report.sarif
            Dockerfile.nephoran
          retention-days: 7
          compression-level: 6

  # =============================================================================
  # STAGE 8: COMPREHENSIVE STATUS REPORTING & CLEANUP
  # =============================================================================
  status:
    name: 📊 Comprehensive Pipeline Status
    runs-on: ubuntu-24.04
    needs: [setup, build, test, security, quality, integration, containerization]
    if: always()
    timeout-minutes: 8

    steps:
      - name: Download all artifacts for analysis
        if: needs.setup.outputs.should-build == 'true'
        uses: actions/download-artifact@v4
        with:
          path: all-artifacts/

      - name: Generate comprehensive pipeline metrics
        if: needs.setup.outputs.should-build == 'true'
        run: |
          echo "📊 Generating comprehensive pipeline metrics..."
          
          # Initialize counters
          total_binaries=0
          total_tests=0
          passed_tests=0
          failed_tests=0
          coverage_files=0
          security_scans=0
          
          # Analyze build artifacts
          if [[ -d "all-artifacts" ]]; then
            echo "Analyzing build artifacts..."
            
            # Count binaries
            find all-artifacts -name "bin" -type d | while read bin_dir; do
              if [[ -d "$bin_dir" ]]; then
                binary_count=$(ls -1 "$bin_dir" 2>/dev/null | wc -l || echo "0")
                total_binaries=$((total_binaries + binary_count))
              fi
            done
            
            # Analyze test results
            find all-artifacts -name "summary-*.json" -type f | while read summary_file; do
              if [[ -f "$summary_file" ]]; then
                if command -v jq >/dev/null 2>&1; then
                  test_total=$(jq '.total // 0' "$summary_file" 2>/dev/null || echo "0")
                  test_passed=$(jq '.passed // 0' "$summary_file" 2>/dev/null || echo "0")
                  test_failed=$(jq '.failed // 0' "$summary_file" 2>/dev/null || echo "0")
                  
                  total_tests=$((total_tests + test_total))
                  passed_tests=$((passed_tests + test_passed))
                  failed_tests=$((failed_tests + test_failed))
                fi
              fi
            done
            
            # Count coverage reports
            coverage_files=$(find all-artifacts -name "coverage-*.html" -type f | wc -l || echo "0")
            
            # Count security scans
            security_scans=$(find all-artifacts -name "*security*" -type f | wc -l || echo "0")
            
            echo "Pipeline metrics collected:"
            echo "  Total binaries: $total_binaries"
            echo "  Total tests: $total_tests"
            echo "  Passed tests: $passed_tests"
            echo "  Failed tests: $failed_tests"
            echo "  Coverage reports: $coverage_files"
            echo "  Security scans: $security_scans"
          fi
          
          # Store metrics for summary
          echo "TOTAL_BINARIES=$total_binaries" >> $GITHUB_ENV
          echo "TOTAL_TESTS=$total_tests" >> $GITHUB_ENV
          echo "PASSED_TESTS=$passed_tests" >> $GITHUB_ENV
          echo "FAILED_TESTS=$failed_tests" >> $GITHUB_ENV
          echo "COVERAGE_FILES=$coverage_files" >> $GITHUB_ENV
          echo "SECURITY_SCANS=$security_scans" >> $GITHUB_ENV

      - name: Generate comprehensive status report
        run: |
          echo "# 🚀 Nephoran CI/CD Pipeline 2025 - Comprehensive Status Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## 📋 Pipeline Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Pipeline Version:** Consolidated CI/CD 2025" >> $GITHUB_STEP_SUMMARY
          echo "- **Go Version:** ${{ env.GO_VERSION }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Build Mode:** ${{ env.BUILD_MODE }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Target Platform:** Ubuntu Linux (x86-64)" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Build Timestamp:** ${{ needs.setup.outputs.build-timestamp }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Max Parallel Jobs:** ${{ env.MAX_PARALLEL_JOBS }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## 🎯 Stage Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status | Duration | Notes |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| 🚀 Setup & Change Detection | ${{ needs.setup.result }} | ~3min | Intelligent change detection & matrix generation |" >> $GITHUB_STEP_SUMMARY
          echo "| 🏗️ Parallel Build Execution | ${{ needs.build.result }} | ~15min | Multi-component parallel building |" >> $GITHUB_STEP_SUMMARY
          echo "| 🧪 Comprehensive Testing | ${{ needs.test.result || 'skipped' }} | ~20min | Unit, integration & coverage tests |" >> $GITHUB_STEP_SUMMARY
          echo "| 🔒 Security Analysis | ${{ needs.security.result || 'skipped' }} | ~12min | Vulnerability & static analysis |" >> $GITHUB_STEP_SUMMARY
          echo "| 📋 Quality Assurance | ${{ needs.quality.result }} | ~10min | Linting & code quality checks |" >> $GITHUB_STEP_SUMMARY
          echo "| 🔗 Integration Testing | ${{ needs.integration.result || 'skipped' }} | ~15min | Smoke tests & manifest validation |" >> $GITHUB_STEP_SUMMARY
          echo "| 🐳 Containerization | ${{ needs.containerization.result || 'skipped' }} | ~10min | Container build & security scan |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.setup.outputs.should-build }}" = "true" ]; then
            echo "## 📊 Build Metrics & Achievements" >> $GITHUB_STEP_SUMMARY
            echo "- **Binaries Generated:** ${{ env.TOTAL_BINARIES }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Tests Executed:** ${{ env.TOTAL_TESTS }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Tests Passed:** ${{ env.PASSED_TESTS }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Coverage Reports:** ${{ env.COVERAGE_FILES }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Security Scans:** ${{ env.SECURITY_SCANS }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Determine comprehensive pipeline status
        run: |
          # Define critical and optional stages
          CRITICAL_FAILURES=""
          OPTIONAL_WARNINGS=""
          
          # Analyze critical stage results
          if [[ "${{ needs.setup.result }}" != "success" ]]; then
            CRITICAL_FAILURES="$CRITICAL_FAILURES setup"
          fi
          
          if [[ "${{ needs.build.result }}" != "success" ]] && [[ "${{ needs.setup.outputs.should-build }}" == "true" ]]; then
            CRITICAL_FAILURES="$CRITICAL_FAILURES build"
          fi
          
          if [[ "${{ needs.quality.result }}" != "success" ]] && [[ "${{ needs.setup.outputs.should-build }}" == "true" ]]; then
            CRITICAL_FAILURES="$CRITICAL_FAILURES quality"
          fi
          
          # Test failures are critical unless explicitly skipped
          if [[ "${{ needs.test.result }}" == "failure" ]] && [[ "${{ env.SKIP_TESTS }}" != "true" ]]; then
            CRITICAL_FAILURES="$CRITICAL_FAILURES tests"
          fi
          
          # Analyze optional/warning stages
          if [[ "${{ needs.security.result }}" == "failure" ]]; then
            OPTIONAL_WARNINGS="$OPTIONAL_WARNINGS security"
          fi
          
          if [[ "${{ needs.integration.result }}" == "failure" ]]; then
            OPTIONAL_WARNINGS="$OPTIONAL_WARNINGS integration"
          fi
          
          if [[ "${{ needs.containerization.result }}" == "failure" ]]; then
            OPTIONAL_WARNINGS="$OPTIONAL_WARNINGS containerization"
          fi
          
          # Generate final status determination
          if [[ -n "$CRITICAL_FAILURES" ]]; then
            echo "## ❌ Pipeline Failed" >> $GITHUB_STEP_SUMMARY
            echo "**Critical stage failures:** $CRITICAL_FAILURES" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🔧 Resolution Steps:" >> $GITHUB_STEP_SUMMARY
            echo "1. **Check failed stage logs** for specific error details" >> $GITHUB_STEP_SUMMARY
            echo "2. **Fix identified issues** in your development branch" >> $GITHUB_STEP_SUMMARY
            echo "3. **Re-run pipeline** or push new commits with fixes" >> $GITHUB_STEP_SUMMARY
            echo "4. **Contact maintainers** if issues persist or are unclear" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [[ -n "$OPTIONAL_WARNINGS" ]]; then
              echo "**Additional warnings:** $OPTIONAL_WARNINGS" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "💥 **PIPELINE FAILED** - Critical stages must pass for deployment readiness"
            exit 1
            
          elif [[ "${{ needs.setup.outputs.should-build }}" == "false" ]]; then
            echo "## ℹ️ Pipeline Skipped" >> $GITHUB_STEP_SUMMARY
            echo "**Reason:** No significant changes detected requiring full CI execution" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 📝 Change Analysis:" >> $GITHUB_STEP_SUMMARY
            echo "- No Go source files, dependencies, or build configuration modified" >> $GITHUB_STEP_SUMMARY
            echo "- Documentation, README, or comment-only changes detected" >> $GITHUB_STEP_SUMMARY
            echo "- Pipeline optimization prevented unnecessary resource usage" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "✅ **PIPELINE OPTIMIZED** - No action required"
            
          else
            echo "## ✅ Pipeline Succeeded" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🎯 Key Achievements:" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ **Build Success:** All critical components built for Linux deployment" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ **Quality Assurance:** Code quality standards maintained" >> $GITHUB_STEP_SUMMARY
            echo "- ✅ **Testing:** Comprehensive test suites executed successfully" >> $GITHUB_STEP_SUMMARY
            
            if [[ "${{ needs.security.result }}" == "success" ]]; then
              echo "- ✅ **Security:** Vulnerability scanning completed" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [[ "${{ needs.integration.result }}" == "success" ]]; then
              echo "- ✅ **Integration:** Smoke tests and validation passed" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [[ "${{ needs.containerization.result }}" == "success" ]]; then
              echo "- ✅ **Containerization:** Production-ready images built" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🚀 Ready for Next Steps:" >> $GITHUB_STEP_SUMMARY
            echo "- 📦 **Artifacts Available:** Build outputs ready for download" >> $GITHUB_STEP_SUMMARY
            echo "- 🐳 **Container Ready:** Images prepared for deployment" >> $GITHUB_STEP_SUMMARY
            echo "- 📊 **Quality Verified:** Code meets production standards" >> $GITHUB_STEP_SUMMARY
            echo "- 🔒 **Security Scanned:** Vulnerabilities assessed and documented" >> $GITHUB_STEP_SUMMARY
            
            if [[ -n "$OPTIONAL_WARNINGS" ]]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### ⚠️ Non-Critical Warnings:" >> $GITHUB_STEP_SUMMARY
              echo "**Stages with warnings:** $OPTIONAL_WARNINGS" >> $GITHUB_STEP_SUMMARY
              echo "These warnings do not block deployment but should be reviewed." >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "🎉 **PIPELINE SUCCEEDED** - Ready for production deployment!"
          fi

      - name: Cleanup and optimization recommendations
        if: always()
        run: |
          echo "🧹 Pipeline cleanup and optimization analysis..."
          
          # Disk usage analysis
          echo "Current disk usage:"
          df -h || echo "Unable to check disk usage"
          
          # Cache effectiveness analysis
          if [[ -d "/tmp/go-build-cache" ]] || [[ -d "/tmp/go-mod-cache" ]]; then
            echo "Cache analysis:"
            du -sh /tmp/go-*-cache 2>/dev/null || echo "No cache data available"
          fi
          
          # Performance recommendations based on build mode
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 💡 Performance Optimization Recommendations:" >> $GITHUB_STEP_SUMMARY
          
          case "${{ env.BUILD_MODE }}" in
            "fast")
              echo "- ⚡ **Fast mode used** - Consider 'full' mode for production branches" >> $GITHUB_STEP_SUMMARY
              echo "- 🎯 **Selective building** - Only changed components processed" >> $GITHUB_STEP_SUMMARY
              ;;
            "full")
              echo "- 🏗️ **Full mode executed** - Comprehensive build completed" >> $GITHUB_STEP_SUMMARY
              echo "- 📊 **All components validated** - Ready for production deployment" >> $GITHUB_STEP_SUMMARY
              ;;
            "debug")
              echo "- 🔍 **Debug mode used** - Extensive logging and validation performed" >> $GITHUB_STEP_SUMMARY
              echo "- ⚠️ **Not optimized for speed** - Use 'fast' or 'full' for regular development" >> $GITHUB_STEP_SUMMARY
              ;;
            "security")
              echo "- 🔒 **Security mode executed** - Enhanced security scanning performed" >> $GITHUB_STEP_SUMMARY
              echo "- 🛡️ **Comprehensive scans** - All security tools executed" >> $GITHUB_STEP_SUMMARY
              ;;
          esac
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📈 Cache Optimization:" >> $GITHUB_STEP_SUMMARY
          echo "- **Multi-layer caching** implemented for Go modules and build cache" >> $GITHUB_STEP_SUMMARY
          echo "- **Intelligent cache keys** based on dependencies and build mode" >> $GITHUB_STEP_SUMMARY
          echo "- **Cross-job cache sharing** enabled for maximum efficiency" >> $GITHUB_STEP_SUMMARY
          
          echo "✅ Pipeline execution completed - All stages analyzed and reported"