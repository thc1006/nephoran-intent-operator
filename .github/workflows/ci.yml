name: CI

on:
  workflow_dispatch: {}
  push:
    branches: [ main, integrate/mvp, "feat/**", "chore/**" ]
  pull_request:
    branches: [ main, integrate/mvp ]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: nephoran-intent-operator

jobs:
  # =============================================================================
  # Repository Hygiene Check Job
  # =============================================================================
  hygiene:
    name: Repository Hygiene
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          lfs: true

      - name: Check for large files not in LFS
        id: large-files
        shell: bash
        run: |
          set -euo pipefail
          echo "## üßπ Repository Hygiene Check" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Find files larger than 10MB not tracked by LFS
          large_files=""
          file_count=0
          
          echo "| File | Size | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------|------|--------|" >> $GITHUB_STEP_SUMMARY
          
          while IFS= read -r file; do
            if [ -f "$file" ]; then
              size=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo 0)
              size_mb=$((size / 1048576))
              
              # Check if file is tracked by LFS
              if git check-attr filter "$file" | grep -q "filter: lfs"; then
                echo "| $file | ${size_mb}MB | ‚úÖ LFS tracked |" >> $GITHUB_STEP_SUMMARY
              else
                if [ $size -gt 10485760 ]; then  # 10MB = 10 * 1024 * 1024
                  echo "‚ùå Large file not in LFS: $file (${size_mb}MB)"
                  echo "| $file | ${size_mb}MB | ‚ùå Not in LFS |" >> $GITHUB_STEP_SUMMARY
                  large_files="${large_files}${file} (${size_mb}MB)\n"
                  ((file_count++))
                fi
              fi
            fi
          done < <(find . -type f -size +1M -not -path "./.git/*" -not -path "./vendor/*" -not -path "./node_modules/*" 2>/dev/null || true)
          
          if [ $file_count -gt 0 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚ùå Failed: Found $file_count large files (>10MB) not tracked by Git LFS" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Action Required:** Add these files to Git LFS or remove them:" >> $GITHUB_STEP_SUMMARY
            echo '```bash' >> $GITHUB_STEP_SUMMARY
            echo "git lfs track \"path/to/file\"" >> $GITHUB_STEP_SUMMARY
            echo "git add .gitattributes" >> $GITHUB_STEP_SUMMARY
            echo "git add path/to/file" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            exit 1
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚úÖ Passed: No large files found outside Git LFS" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Check for common unwanted files
        shell: bash
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìã Additional Checks" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          unwanted_patterns=(
            "*.log"
            "*.tmp"
            "*.bak"
            "*.swp"
            ".DS_Store"
            "Thumbs.db"
            "*.orig"
          )
          
          found_unwanted=false
          echo "| Pattern | Files Found |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|------------|" >> $GITHUB_STEP_SUMMARY
          
          for pattern in "${unwanted_patterns[@]}"; do
            count=$(find . -name "$pattern" -not -path "./.git/*" 2>/dev/null | wc -l)
            if [ $count -gt 0 ]; then
              echo "| $pattern | $count file(s) |" >> $GITHUB_STEP_SUMMARY
              found_unwanted=true
            fi
          done
          
          if [ "$found_unwanted" = false ]; then
            echo "| - | None found ‚úÖ |" >> $GITHUB_STEP_SUMMARY
          fi

  # =============================================================================
  # Change Detection Job (Path Filters)
  # =============================================================================
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      api: ${{ steps.filter.outputs.api }}
      controllers: ${{ steps.filter.outputs.controllers }}
      pkg-nephio: ${{ steps.filter.outputs.pkg-nephio }}
      pkg-oran: ${{ steps.filter.outputs.pkg-oran }}
      pkg-llm: ${{ steps.filter.outputs.pkg-llm }}
      pkg-rag: ${{ steps.filter.outputs.pkg-rag }}
      pkg-core: ${{ steps.filter.outputs.pkg-core }}
      cmd: ${{ steps.filter.outputs.cmd }}
      tools: ${{ steps.filter.outputs.tools }}
      internal: ${{ steps.filter.outputs.internal }}
      planner: ${{ steps.filter.outputs.planner }}
      docs: ${{ steps.filter.outputs.docs }}
      ci: ${{ steps.filter.outputs.ci }}
      scripts: ${{ steps.filter.outputs.scripts }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            api:
              - 'api/**'
              - 'config/crd/**'
            controllers:
              - 'controllers/**'
            pkg-nephio:
              - 'pkg/nephio/**'
              - 'pkg/packagerevision/**'
            pkg-oran:
              - 'pkg/oran/**'
              - 'pkg/telecom/**'
            pkg-llm:
              - 'pkg/llm/**'
              - 'pkg/ml/**'
            pkg-rag:
              - 'pkg/rag/**'
              - 'pkg/knowledge/**'
            pkg-core:
              - 'pkg/auth/**'
              - 'pkg/config/**'
              - 'pkg/errors/**'
              - 'pkg/logging/**'
              - 'pkg/monitoring/**'
              - 'pkg/security/**'
              - 'pkg/validation/**'
            cmd:
              - 'cmd/**'
            tools:
              - 'tools/**'
            internal:
              - 'internal/**'
            planner:
              - 'planner/**'
            docs:
              - 'docs/**'
              - '*.md'
            ci:
              - '.github/workflows/**'
              - 'Makefile'
              - 'go.mod'
              - 'go.sum'
            scripts:
              - 'scripts/**'

  # =============================================================================
  # Setup and CRD Generation Job
  # =============================================================================
  generate:
    name: Generate CRDs
    runs-on: ubuntu-latest
    needs: [hygiene, changes]
    if: |
      always() && 
      needs.hygiene.result == 'success' &&
      (needs.changes.outputs.api == 'true' || 
       needs.changes.outputs.controllers == 'true' || 
       needs.changes.outputs.cmd == 'true' ||
       needs.changes.outputs.planner == 'true' ||
       needs.changes.outputs.ci == 'true')
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          check-latest: true
          cache: false

      - name: Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - name: Download and verify dependencies
        run: |
          go mod download
          go mod verify
        env:
          GOPROXY: https://proxy.golang.org,direct
          GOSUMDB: sum.golang.org

      - name: Install controller-gen
        run: |
          go install sigs.k8s.io/controller-tools/cmd/controller-gen@v0.18.0

      - name: Generate CRDs and code
        run: |
          set -e
          make gen || true
          # Create directory if it doesn't exist for MVP stability
          mkdir -p deployments/crds
          ls -lah deployments/crds || true

      - name: Upload CRD artifacts
        uses: actions/upload-artifact@v4
        with:
          name: generated-crds
          path: deployments/crds/
          if-no-files-found: ignore
          retention-days: 1

  # =============================================================================
  # Build Job
  # =============================================================================
  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [hygiene, generate, changes]
    if: |
      always() && 
      needs.hygiene.result == 'success' &&
      needs.generate.result != 'failure' &&
      (needs.changes.outputs.cmd == 'true' || 
       needs.changes.outputs.planner == 'true' ||
       needs.changes.outputs.controllers == 'true' ||
       needs.changes.outputs.api == 'true' ||
       needs.changes.outputs.ci == 'true')
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          check-latest: true
          cache: false

      - name: Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - name: Download and verify dependencies
        run: |
          go mod download
          go mod verify
        env:
          GOPROXY: https://proxy.golang.org,direct
          GOSUMDB: sum.golang.org

      - name: Download CRD artifacts
        uses: actions/download-artifact@v4
        with:
          name: generated-crds
          path: deployments/crds/
        continue-on-error: true

      - name: Build binaries (cmd/*)
        id: build
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p bin .excellence-reports
          built=0

          if [[ -f cmd/intent-ingest/main.go ]]; then
            echo ">> building cmd/intent-ingest"
            ( go build -v -o bin/intent-ingest ./cmd/intent-ingest ) 2>&1 | tee .excellence-reports/build_intent-ingest.log
            built=1
          fi

          if [[ -f cmd/porch-publisher/main.go ]]; then
            echo ">> building cmd/porch-publisher"
            ( go build -v -o bin/porch-publisher ./cmd/porch-publisher ) 2>&1 | tee .excellence-reports/build_porch-publisher.log
            built=1
          fi

          if [[ -f cmd/porch-direct/main.go ]]; then
            echo ">> building cmd/porch-direct"
            ( go build -v -o bin/porch-direct ./cmd/porch-direct ) 2>&1 | tee .excellence-reports/build_porch-direct.log
            built=1
          fi

          if [[ -f planner/cmd/planner/main.go ]]; then
            echo ">> building planner/cmd/planner"
            ( go build -v -o bin/planner ./planner/cmd/planner ) 2>&1 | tee .excellence-reports/build_planner.log
            built=1
          fi

          if [[ "${built}" -eq 0 ]]; then
            echo "No command directories found under cmd/ or planner/, skipping build."
          fi
          ls -lah bin || true

      - name: Upload build artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            bin/
            .excellence-reports/build_*.log
          if-no-files-found: warn
          retention-days: 7

  # =============================================================================
  # Test Job (includes unit tests and envtest)
  # =============================================================================
  test:
    name: Test
    runs-on: ubuntu-latest
    needs: [hygiene, generate, changes]
    if: |
      always() && 
      needs.hygiene.result == 'success' &&
      needs.generate.result != 'failure' &&
      (needs.changes.outputs.cmd == 'true' || 
       needs.changes.outputs.controllers == 'true' || 
       needs.changes.outputs.planner == 'true' ||
       needs.changes.outputs.api == 'true' ||
       needs.changes.outputs.ci == 'true')
    timeout-minutes: 45

    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          check-latest: true
          cache: false

      - name: Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - name: Download and verify dependencies
        run: |
          go mod download
          go mod verify
        env:
          GOPROXY: https://proxy.golang.org,direct
          GOSUMDB: sum.golang.org

      - name: Download CRD artifacts
        uses: actions/download-artifact@v4
        with:
          name: generated-crds
          path: deployments/crds/
        continue-on-error: true

      - name: Install envtest
        run: |
          go install sigs.k8s.io/controller-runtime/tools/setup-envtest@latest

      - name: Setup envtest environment
        run: |
          setup-envtest use 1.29.0 --bin-dir ~/.local/bin
          echo "KUBEBUILDER_ASSETS=$(setup-envtest use 1.29.0 --bin-dir ~/.local/bin -p path)" >> $GITHUB_ENV

      - name: Run tests with coverage
        shell: bash
        env:
          USE_EXISTING_CLUSTER: false
          ENVTEST_K8S_VERSION: 1.29.0
          REDIS_URL: redis://localhost:6379
          GOMAXPROCS: 2
          CGO_ENABLED: 0
          GOOS: ${{ runner.os == 'Windows' && 'windows' || 'linux' }}
          GOARCH: amd64
          GOTRACEBACK: all
        run: |
          set -euo pipefail
          mkdir -p .excellence-reports
          if find . -type f -name "*_test.go" -not -path "./vendor/*" | head -n1 | grep -q .; then
            # Add retry logic for flaky tests
            for attempt in 1 2 3; do
              echo "Test attempt $attempt of 3..."
              if go test -v ./... -count=1 -timeout=40m -race -coverprofile=.excellence-reports/coverage.out -covermode=atomic 2>&1 | tee .excellence-reports/test-attempt-$attempt.log; then
                echo "Tests passed on attempt $attempt"
                cp .excellence-reports/test-attempt-$attempt.log .excellence-reports/test.log
                break
              elif [ $attempt -eq 3 ]; then
                echo "Tests failed after 3 attempts"
                cat .excellence-reports/test-attempt-*.log > .excellence-reports/test.log
                exit 1
              else
                echo "Test attempt $attempt failed, retrying..."
                sleep 10
              fi
            done
            go tool cover -html=.excellence-reports/coverage.out -o .excellence-reports/coverage.html || true
          else
            echo "No *_test.go found. Skipping tests."
            touch .excellence-reports/test.log
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_id }}
          path: |
            .excellence-reports/test.log
            .excellence-reports/test-attempt-*.log
            .excellence-reports/coverage.out
            .excellence-reports/coverage.html
          if-no-files-found: ignore
          retention-days: 7

  # =============================================================================
  # Linting Job (using golangci-lint-action for better performance)
  # =============================================================================
  lint:
    name: Lint
    runs-on: ubuntu-latest
    needs: [hygiene, generate]
    timeout-minutes: 15
    continue-on-error: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          check-latest: true
          cache: false

      - name: Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - name: Download and verify dependencies
        run: |
          go mod download
          go mod verify
        env:
          GOPROXY: https://proxy.golang.org,direct
          GOSUMDB: sum.golang.org

      - name: Download CRD artifacts
        uses: actions/download-artifact@v4
        with:
          name: generated-crds
          path: deployments/crds/
        continue-on-error: true

      - name: Install golangci-lint (pinned)
        run: go install github.com/golangci/golangci-lint/cmd/golangci-lint@v1.61.0

      - name: Run golangci-lint (non-blocking)
        shell: bash
        run: |
          mkdir -p .excellence-reports
          golangci-lint version || true
          # Avoid config schema errors in MVP stage
          golangci-lint run --timeout=5m --out-format=github-actions || true

      - name: Upload lint report (best-effort)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lint-report
          path: .excellence-reports/
          if-no-files-found: ignore
          retention-days: 7

  # =============================================================================
  # Security/Vulnerability Scanning Job
  # =============================================================================
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: [hygiene, generate]
    timeout-minutes: 15
    continue-on-error: true

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          check-latest: true
          cache: false

      - name: Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - name: Cache govulncheck database
        uses: actions/cache@v4
        with:
          path: ~/.cache/go-security-db
          key: ${{ runner.os }}-govulncheck-db-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-govulncheck-db-

      - name: Download and verify dependencies
        run: |
          go mod download
          go mod verify
        env:
          GOPROXY: https://proxy.golang.org,direct
          GOSUMDB: sum.golang.org

      - name: Download CRD artifacts
        uses: actions/download-artifact@v4
        with:
          name: generated-crds
          path: deployments/crds/
        continue-on-error: true

      - name: Install govulncheck
        run: |
          go install golang.org/x/vuln/cmd/govulncheck@v1.1.4

      - name: Run govulncheck (non-blocking)
        shell: bash
        env:
          GOVULNCHECK_DB: ~/.cache/go-security-db
        run: |
          mkdir -p .excellence-reports
          govulncheck -json ./... > .excellence-reports/govulncheck.json || true
          echo "Report at .excellence-reports/govulncheck.json"

      - name: Upload security scan results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-results
          path: .excellence-reports/govulncheck.json
          if-no-files-found: ignore
          retention-days: 7

  # =============================================================================
  # Tools Test Job - Test the tools directory when changed
  # =============================================================================
  tools-test:
    name: Tools Test
    runs-on: ubuntu-latest
    needs: [hygiene, changes]
    if: needs.changes.outputs.tools == 'true'
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod
          check-latest: true
          cache: false

      - name: Cache Go build/mod
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-

      - name: Download deps
        run: |
          go mod download
          go mod verify

      - name: Run tools tests
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p .excellence-reports
          echo "Testing tools directory..."
          
          # Test kmpgen
          if [ -d "tools/kmpgen" ]; then
            echo "Testing kmpgen..."
            go test -v ./tools/kmpgen/cmd/kmpgen -count=1 2>&1 | tee -a .excellence-reports/tools-test.log
          fi
          
          # Test vessend
          if [ -d "tools/vessend" ]; then
            echo "Testing vessend..."
            go test -v ./tools/vessend/cmd/vessend -count=1 2>&1 | tee -a .excellence-reports/tools-test.log
          fi
          
          # Test any other specific tool packages (not the root tools package)
          for tooldir in tools/*/; do
            if [ -d "$tooldir" ] && [ "$tooldir" != "tools/kmpgen/" ] && [ "$tooldir" != "tools/vessend/" ]; then
              # Find packages with test files in this tool directory
              tool_name=$(basename "$tooldir")
              if find "$tooldir" -name "*_test.go" | grep -q .; then
                echo "Testing $tool_name..."
                go test -v "./tools/$tool_name/..." -count=1 2>&1 | tee -a .excellence-reports/tools-test.log
              fi
            fi
          done
          
          echo "Tools testing completed."

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tools-test-results
          path: |
            .excellence-reports/tools-test.log
          if-no-files-found: ignore
          retention-days: 7

  # =============================================================================
  # Final CI Status Check (single required gate)
  # =============================================================================
  ci-status:
    name: CI Status Check
    runs-on: ubuntu-latest
    needs: [hygiene, generate, build, test, tools-test]
    if: always()
    timeout-minutes: 5

    steps:
      - name: Gate on upstream job results
        shell: bash
        run: |
          echo "=== CI Pipeline Status ==="
          echo "Hygiene:    ${{ needs.hygiene.result }}"
          echo "Generate:   ${{ needs.generate.result }}"
          echo "Build:      ${{ needs.build.result }}"
          echo "Test:       ${{ needs.test.result }}"
          echo "Tools-Test: ${{ needs.tools-test.result }}"
          echo ""

          # Check for any failures (skipped is OK, failure is not)
          failed=false
          
          # Hygiene must always succeed (never skipped)
          if [[ "${{ needs.hygiene.result }}" != "success" ]]; then
            echo "‚ùå Hygiene job failed or was cancelled"
            failed=true
          fi
          
          # Other jobs can be skipped or successful, but not failed
          if [[ "${{ needs.generate.result }}" != "success" && "${{ needs.generate.result }}" != "skipped" ]]; then
            echo "‚ùå Generate job failed"
            failed=true
          fi
          
          if [[ "${{ needs.build.result }}" != "success" && "${{ needs.build.result }}" != "skipped" ]]; then
            echo "‚ùå Build job failed"
            failed=true
          fi
          
          if [[ "${{ needs.test.result }}" != "success" && "${{ needs.test.result }}" != "skipped" ]]; then
            echo "‚ùå Test job failed"
            failed=true
          fi
          
          if [[ "${{ needs.tools-test.result }}" != "success" && "${{ needs.tools-test.result }}" != "skipped" ]]; then
            echo "‚ùå Tools-Test job failed"
            failed=true
          fi
          
          if [[ "$failed" == "true" ]]; then
            echo "‚ùå CI Pipeline Failed"
            exit 1
          else
            echo "‚úÖ CI Pipeline Succeeded (some jobs may have been skipped based on path filters)"
          fi

      - name: Generate CI summary
        if: always()
        shell: bash
        run: |
          echo "## üîÑ CI Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status | Description |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|-------------|" >> $GITHUB_STEP_SUMMARY
          echo "| üßπ Hygiene    | ${{ needs.hygiene.result }}    | Repository cleanliness checks |" >> $GITHUB_STEP_SUMMARY
          echo "| ‚öôÔ∏è Generate   | ${{ needs.generate.result }}   | CRD and code generation |" >> $GITHUB_STEP_SUMMARY
          echo "| üî® Build      | ${{ needs.build.result }}      | Binary compilation |" >> $GITHUB_STEP_SUMMARY
          echo "| üß™ Test       | ${{ needs.test.result }}       | Unit and integration tests |" >> $GITHUB_STEP_SUMMARY
          echo "| üîß Tools-Test | ${{ needs.tools-test.result }} | Test harness tools tests |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add timing information
          echo "### ‚è±Ô∏è Timing Information" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Workflow Started | ${{ github.event.head_commit.timestamp }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Runner OS | ${{ runner.os }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Ref | ${{ github.ref }} |" >> $GITHUB_STEP_SUMMARY
          echo "| SHA | ${{ github.sha }} |" >> $GITHUB_STEP_SUMMARY

  # =============================================================================
  # Container Build Job (runs after successful CI)
  # =============================================================================
  container:
    name: Container Build
    runs-on: ubuntu-latest
    needs: [build, test]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    timeout-minutes: 20

    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts
          path: bin/

      - name: Build and push container image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: Dockerfile.production
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            VERSION=${{ github.sha }}
            BUILD_DATE=${{ github.run_timestamp }}
            VCS_REF=${{ github.sha }}

  # =============================================================================
  # Enhanced Windows Compatibility Test Job
  # =============================================================================
  windows-test:
    name: Windows Compatibility
    runs-on: windows-latest
    needs: [hygiene, changes]
    if: |
      always() && 
      needs.hygiene.result == 'success' &&
      (needs.changes.outputs.cmd == 'true' || 
       needs.changes.outputs.controllers == 'true' || 
       needs.changes.outputs.api == 'true' ||
       needs.changes.outputs.ci == 'true')
    timeout-minutes: 35  # Increased timeout for Windows reliability
    continue-on-error: true  # Don't block main pipeline if Windows tests fail

    env:
      # Windows-specific optimizations
      CGO_ENABLED: 0
      GOMAXPROCS: 4
      GOTRACEBACK: all
      GO_TEST_TIMEOUT_SCALE: 2
      # Enhanced temp directory management
      WINDOWS_TEMP_BASE: ${{ runner.temp }}\nephoran-ci-${{ github.run_id }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod
          check-latest: true
          cache: false

      - name: Setup Windows temp directories
        shell: pwsh
        run: |
          # Create isolated temp directories for this CI run
          $tempBase = $env:WINDOWS_TEMP_BASE
          $tempGo = Join-Path $tempBase "go"
          $tempTest = Join-Path $tempBase "test"
          $tempCache = Join-Path $tempBase "cache"
          
          # Create directories
          @($tempBase, $tempGo, $tempTest, $tempCache) | ForEach-Object {
            New-Item -ItemType Directory -Force -Path $_ | Out-Null
            Write-Output "Created: $_"
          }
          
          # Set environment variables for this job
          "TMPDIR=$tempGo" >> $env:GITHUB_ENV
          "GOCACHE=$tempCache" >> $env:GITHUB_ENV
          "GOTMPDIR=$tempGo" >> $env:GITHUB_ENV
          "TEST_TEMP_DIR=$tempTest" >> $env:GITHUB_ENV
          
          Write-Output "Windows temp directories configured:"
          Write-Output "Base: $tempBase"
          Write-Output "Go: $tempGo" 
          Write-Output "Test: $tempTest"
          Write-Output "Cache: $tempCache"

      - name: Enhanced cache with Windows paths
        uses: actions/cache@v4
        with:
          path: |
            ~\AppData\Local\go-build
            ~\go\pkg\mod
            ${{ env.WINDOWS_TEMP_BASE }}\cache
          key: windows-enhanced-go-${{ hashFiles('**/go.sum') }}-${{ github.run_id }}
          restore-keys: |
            windows-enhanced-go-${{ hashFiles('**/go.sum') }}-
            windows-enhanced-go-
            ${{ runner.os }}-go-

      - name: Download and verify dependencies
        shell: pwsh
        run: |
          go mod download
          go mod verify

      - name: Install controller-gen
        shell: pwsh
        run: go install sigs.k8s.io/controller-tools/cmd/controller-gen@latest

      - name: Generate deepcopy methods
        shell: pwsh
        run: |
          $deepcopyFile = "api\v1\zz_generated.deepcopy.go"
          if (-not (Test-Path $deepcopyFile)) {
            Write-Output "Generating deepcopy methods for api/v1..."
            controller-gen object:headerFile="hack/boilerplate.go.txt" paths="./api/v1"
          }

      - name: Build Windows executables
        shell: pwsh  
        run: |
          Write-Output "Building Windows executables..."
          go build -v -o conductor-watch.exe ./cmd/conductor-watch
          go build -v -o intent-ingest.exe ./cmd/intent-ingest
          
          # Verify executables exist
          Get-ChildItem -Path . -Filter "*.exe" | Format-Table Name, Length

      - name: Run Windows-compatible tests with retry logic
        shell: pwsh
        run: |
          Write-Output "Running Windows-compatible tests with enhanced reliability..."
          
          # Test packages with retry logic
          $testPackages = @(
            @{name="api-intent"; path="./api/intent/v1alpha1"; timeout="5m"},
            @{name="internal-watch"; path="./internal/watch"; timeout="8m"},
            @{name="pkg-config"; path="./pkg/config"; timeout="5m"},
            @{name="conductor-watch"; path="./cmd/conductor-watch"; timeout="10m"}
          )
          
          $allPassed = $true
          
          foreach ($pkg in $testPackages) {
            Write-Output "=== Testing $($pkg.name) ==="
            $maxRetries = 3
            $attempt = 1
            $success = $false
            
            while ($attempt -le $maxRetries -and -not $success) {
              Write-Output "Attempt $attempt of $maxRetries for $($pkg.name)..."
              
              try {
                # Create isolated test directory
                $testDir = Join-Path $env:TEST_TEMP_DIR $pkg.name
                New-Item -ItemType Directory -Force -Path $testDir | Out-Null
                
                # Run test with enhanced environment
                $env:TMPDIR = $testDir
                $coverageFile = "coverage-windows-$($pkg.name).out"
                
                go test -v -count=1 -timeout=$($pkg.timeout) -coverprofile=$coverageFile $($pkg.path) 2>&1 | Tee-Object -FilePath "test-$($pkg.name)-$attempt.log"
                
                if ($LASTEXITCODE -eq 0) {
                  Write-Output "‚úÖ $($pkg.name) tests passed on attempt $attempt"
                  $success = $true
                  
                  # Generate coverage report
                  if (Test-Path $coverageFile) {
                    go tool cover -func=$coverageFile | Select-String "total:" | Write-Output
                  }
                } else {
                  throw "Test failed with exit code $LASTEXITCODE"
                }
              } catch {
                Write-Output "‚ùå $($pkg.name) test attempt $attempt failed: $_"
                if ($attempt -eq $maxRetries) {
                  Write-Output "‚ùå All attempts failed for $($pkg.name)"
                  $allPassed = $false
                } else {
                  Write-Output "Retrying in 5 seconds..."
                  Start-Sleep -Seconds 5
                }
              }
              $attempt++
            }
          }
          
          if (-not $allPassed) {
            Write-Output "‚ö†Ô∏è Some Windows tests failed, but continuing due to continue-on-error"
          } else {
            Write-Output "‚úÖ All Windows tests passed!"
          }
        continue-on-error: true

      - name: Validate Windows-specific features
        shell: pwsh
        run: |
          Write-Output "Validating Windows batch scripts..."
          if (Test-Path "mock-porch.bat") {
            Write-Output "‚úÖ mock-porch.bat exists"
            Get-Content "mock-porch.bat" -Head 3
          } else {
            Write-Output "‚ùå mock-porch.bat missing"
          }
          
          if (Test-Path "testdata\mock-executables\mock-porch-success.bat") {
            Write-Output "‚úÖ Mock executables exist"
            try {
              & ".\testdata\mock-executables\mock-porch-success.bat" --help
              Write-Output "‚úÖ Batch script execution successful"
            } catch {
              Write-Output "‚ö†Ô∏è Batch script execution failed: $($_.Exception.Message)"
            }
          } else {
            Write-Output "‚ùå Mock executables missing"
          }

      - name: Upload Windows test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: windows-test-results-${{ github.run_id }}
          path: |
            test-*.log
            coverage-windows-*.out
            *.exe
            ${{ env.TEST_TEMP_DIR }}\**\*.log
          retention-days: 7

      - name: Enhanced Windows test summary
        shell: pwsh
        run: |
          Write-Output "=== Enhanced Windows Compatibility Test Summary ==="
          Write-Output ""
          Write-Output "### Environment Information"
          Write-Output "- PowerShell Version: $($PSVersionTable.PSVersion)"
          Write-Output "- Go Version: $(go version)"
          Write-Output "- OS: ${{ runner.os }}"
          Write-Output "- CPU Cores: $([System.Environment]::ProcessorCount)"
          Write-Output "- Available RAM: $([math]::Round((Get-CimInstance -ClassName Win32_ComputerSystem).TotalPhysicalMemory / 1GB, 2)) GB"
          Write-Output "- Temp Base: $env:WINDOWS_TEMP_BASE"
          Write-Output ""
          
          Write-Output "### Build Artifacts"
          Get-ChildItem "*.exe" -ErrorAction SilentlyContinue | ForEach-Object {
            $size = [math]::Round($_.Length / 1MB, 2)
            Write-Output "- $($_.Name): $size MB"
          }
          Write-Output ""
          
          Write-Output "### Test Results"
          Get-ChildItem "test-*.log" -ErrorAction SilentlyContinue | ForEach-Object {
            $lines = (Get-Content $_.FullName | Measure-Object -Line).Lines
            Write-Output "- $($_.Name): $lines lines"
          }
          Write-Output ""
          
          Write-Output "### Coverage Files"
          Get-ChildItem "coverage-windows-*.out" -ErrorAction SilentlyContinue | ForEach-Object {
            if (Test-Path $_.FullName) {
              $coverage = go tool cover -func=$_.FullName | Select-String "total:" | ForEach-Object { $_.ToString().Split()[-1] }
              Write-Output "- $($_.BaseName): $coverage"
            }
          }
          Write-Output ""
          
          Write-Output "### Key Files Validation"
          $files = @("api\v1\zz_generated.deepcopy.go", "mock-porch.bat", "go.mod", "go.sum")
          foreach ($file in $files) {
            if (Test-Path $file) {
              Write-Output "‚úÖ $file exists"
            } else {
              Write-Output "‚ùå $file missing"
            }
          }
          Write-Output ""
          
          Write-Output "### Temp Directory Contents"
          if (Test-Path $env:TEST_TEMP_DIR) {
            Get-ChildItem $env:TEST_TEMP_DIR -Recurse -ErrorAction SilentlyContinue | 
              Select-Object -First 10 | ForEach-Object {
                Write-Output "- $($_.FullName)"
              }
          }
          
          Write-Output ""
          Write-Output "‚úÖ Windows compatibility test completed successfully"
        if: always()

      - name: Cleanup Windows temp directories  
        if: always()
        shell: pwsh
        run: |
          # Clean up temporary directories
          if (Test-Path $env:WINDOWS_TEMP_BASE) {
            try {
              Remove-Item -Path $env:WINDOWS_TEMP_BASE -Recurse -Force -ErrorAction SilentlyContinue
              Write-Output "‚úÖ Cleaned up temp directory: $env:WINDOWS_TEMP_BASE"
            } catch {
              Write-Output "‚ö†Ô∏è Could not clean up temp directory: $_"
            }
          }
          
          # Clean up any leftover processes
          Get-Process | Where-Object { $_.Name -match "conductor|intent" } | ForEach-Object {
            try {
              Stop-Process -Id $_.Id -Force -ErrorAction SilentlyContinue
              Write-Output "Stopped process: $($_.Name) ($($_.Id))"
            } catch {
              # Ignore cleanup errors
            }
          }