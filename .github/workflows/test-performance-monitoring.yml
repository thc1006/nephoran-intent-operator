name: Test Performance Monitoring

on:
  push:
    branches: [main, develop, "fix/*", "feat/*"]
  pull_request:
    types: [opened, synchronize, reopened]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test execution mode'
        required: true
        default: 'quick'
        type: choice
        options:
          - quick
          - full
          - race
          - benchmark

env:
  GO_VERSION: '1.24.x'
  RESULTS_RETENTION_DAYS: 30

jobs:
  test-performance:
    name: Test Performance Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: false  # Temporarily disabled - performance analysis needs test files
    
    strategy:
      fail-fast: false
      matrix:
        test-suite:
          - name: "Quick Validation"
            cmd: "go test -short -json ./..."
            timeout: 5
            parallel: 8
          - name: "Unit Tests"
            cmd: "go test -run '^Test[^I][^n][^t]' -json ./..."
            timeout: 10
            parallel: 4
          - name: "Integration Tests"
            cmd: "go test -run 'Integration' -json ./..."
            timeout: 15
            parallel: 2
            
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # For accurate git history
      
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
          
      - name: Setup test environment
        run: |
          echo "GOMAXPROCS=${{ matrix.test-suite.parallel }}" >> $GITHUB_ENV
          echo "GOGC=100" >> $GITHUB_ENV
          echo "GOMEMLIMIT=2GiB" >> $GITHUB_ENV
          
          # Create results directory
          mkdir -p test-results
          
      - name: Run ${{ matrix.test-suite.name }}
        id: test-execution
        timeout-minutes: ${{ matrix.test-suite.timeout }}
        run: |
          START_TIME=$(date +%s)
          
          # Run tests with JSON output for parsing
          ${{ matrix.test-suite.cmd }} \
            -parallel=${{ matrix.test-suite.parallel }} \
            -timeout=${{ matrix.test-suite.timeout }}m \
            2>&1 | tee test-results/${{ matrix.test-suite.name }}.json
          
          EXIT_CODE=${PIPESTATUS[0]}
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          
          # Parse test results
          if [ -f test-results/${{ matrix.test-suite.name }}.json ]; then
            PASS_COUNT=$(grep -c '"Action":"pass"' test-results/${{ matrix.test-suite.name }}.json || echo 0)
            FAIL_COUNT=$(grep -c '"Action":"fail"' test-results/${{ matrix.test-suite.name }}.json || echo 0)
            SKIP_COUNT=$(grep -c '"Action":"skip"' test-results/${{ matrix.test-suite.name }}.json || echo 0)
            
            echo "pass_count=$PASS_COUNT" >> $GITHUB_OUTPUT
            echo "fail_count=$FAIL_COUNT" >> $GITHUB_OUTPUT
            echo "skip_count=$SKIP_COUNT" >> $GITHUB_OUTPUT
          fi
          
          exit $EXIT_CODE
          
      - name: Generate performance report
        if: always()
        run: |
          cat > test-results/performance-report.md << EOF
          ## Test Performance Report: ${{ matrix.test-suite.name }}
          
          ### Execution Metrics
          - **Duration**: ${{ steps.test-execution.outputs.duration }}s
          - **Exit Code**: ${{ steps.test-execution.outputs.exit_code }}
          - **Parallel Workers**: ${{ matrix.test-suite.parallel }}
          
          ### Test Results
          - ✅ Passed: ${{ steps.test-execution.outputs.pass_count }}
          - ❌ Failed: ${{ steps.test-execution.outputs.fail_count }}
          - ⏭️ Skipped: ${{ steps.test-execution.outputs.skip_count }}
          
          ### Resource Configuration
          - GOMAXPROCS: ${{ matrix.test-suite.parallel }}
          - GOGC: 100
          - GOMEMLIMIT: 2GiB
          EOF
          
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.test-suite.name }}
          path: test-results/
          retention-days: ${{ env.RESULTS_RETENTION_DAYS }}
          
      - name: Comment PR with results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('test-results/performance-report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

  race-detection:
    name: Race Condition Detection
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
          
      - name: Run race detection
        run: |
          go test -race -timeout=15m -json ./... 2>&1 | tee race-results.json
          
      - name: Parse race conditions
        if: failure()
        run: |
          echo "### Race Conditions Detected" >> $GITHUB_STEP_SUMMARY
          grep "WARNING: DATA RACE" race-results.json >> $GITHUB_STEP_SUMMARY || true
          
      - name: Upload race detection results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: race-detection-results
          path: race-results.json
          retention-days: ${{ env.RESULTS_RETENTION_DAYS }}

  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: write
      pull-requests: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
          
      - name: Run benchmarks
        run: |
          # Run benchmarks only (no tests) with -run=^$ pattern
          go test -run=^$ -bench=. -benchmem -benchtime=10s -json ./... 2>&1 | tee benchmark-results.json
          
      - name: Parse benchmark results
        run: |
          echo "### Benchmark Results" >> $GITHUB_STEP_SUMMARY
          
          # Extract benchmark metrics
          grep '"Benchmark"' benchmark-results.json | while read -r line; do
            if echo "$line" | grep -q "NsPerOp"; then
              echo "$line" | jq -r '"\(.Benchmark): \(.NsPerOp) ns/op, \(.AllocsPerOp) allocs/op, \(.BytesPerOp) B/op"' >> $GITHUB_STEP_SUMMARY
            fi
          done
          
      - name: Store benchmark results
        # Only push results on push events to main or integrate/mvp branches
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/integrate/mvp')
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'go'
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: true
          fail-on-alert: false

  aggregate-results:
    name: Aggregate Performance Metrics
    runs-on: ubuntu-latest
    needs: [test-performance, race-detection, benchmark]
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-results/
          
      - name: Generate consolidated report
        run: |
          cat > performance-summary.md << EOF
          # Test Performance Summary
          
          ## Overall Status
          - Test Performance: ${{ needs.test-performance.result }}
          - Race Detection: ${{ needs.race-detection.result }}
          - Benchmarks: ${{ needs.benchmark.result }}
          
          ## Recommendations
          EOF
          
          if [ "${{ needs.test-performance.result }}" == "failure" ]; then
            echo "- ⚠️ Test failures detected. Review test logs for details." >> performance-summary.md
          fi
          
          if [ "${{ needs.race-detection.result }}" == "failure" ]; then
            echo "- 🔴 Race conditions detected. Must fix before merge." >> performance-summary.md
          fi
          
          if [ "${{ needs.benchmark.result }}" == "failure" ]; then
            echo "- 📉 Performance regression detected. Review benchmark results." >> performance-summary.md
          fi
          
          echo "" >> performance-summary.md
          echo "Generated at: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> performance-summary.md
          
      - name: Upload final summary
        uses: actions/upload-artifact@v4
        with:
          name: performance-summary
          path: performance-summary.md
          retention-days: ${{ env.RESULTS_RETENTION_DAYS }}
          
      - name: Add summary to PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('performance-summary.md', 'utf8');
            
            // Add as PR comment
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
            
            // Update PR status check
            const status = '${{ needs.test-performance.result }}' === 'success' &&
                          '${{ needs.race-detection.result }}' === 'success' ? 'success' : 'failure';
            
            github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: status,
              target_url: `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`,
              description: 'Test performance analysis complete',
              context: 'test-performance'
            });