# Comprehensive Code Quality Gate Workflow
# Enforces 90%+ test coverage and comprehensive quality standards
# Blocks PRs and releases that don't meet quality thresholds

name: 🔍 Code Quality Gate

permissions:
  contents: read
  pull-requests: write
  checks: write
  actions: read
  security-events: write

on:
  push:
    branches: [ main, develop, release/** ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.github/**'
      - '!.github/workflows/quality-gate.yml'
  pull_request:
    branches: [ main, develop, integrate/mvp ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  schedule:
    # Daily quality analysis at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      coverage_threshold:
        description: 'Minimum test coverage percentage'
        required: false
        default: '90'
        type: string
      quality_threshold:
        description: 'Minimum quality score (0-10)'
        required: false
        default: '8.0'
        type: string
      skip_tests:
        description: 'Skip test execution (use existing coverage)'
        required: false
        default: false
        type: boolean
      fail_fast:
        description: 'Fail fast on first quality gate failure'
        required: false
        default: true
        type: boolean

env:
  GO_VERSION: '1.24.1'
  COVERAGE_THRESHOLD: ${{ github.event.inputs.coverage_threshold || '90' }}
  QUALITY_THRESHOLD: ${{ github.event.inputs.quality_threshold || '8.0' }}
  REPORTS_DIR: '.quality-reports'

jobs:
  # ================================================================
  # Quality Gate Pre-checks
  # ================================================================
  pre-checks:
    name: 🔧 Pre-checks and Setup
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      should-run-full-analysis: ${{ steps.check.outputs.should-run-full-analysis }}
      go-cache-key: ${{ steps.cache-keys.outputs.go-cache-key }}
      golangci-cache-key: ${{ steps.cache-keys.outputs.golangci-cache-key }}
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: 🔍 Check if Full Analysis Needed
        id: check
        run: |
          # Check if this is a scheduled run, manual dispatch, or significant changes
          if [[ "${{ github.event_name }}" == "schedule" ]] || \
             [[ "${{ github.event_name }}" == "workflow_dispatch" ]] || \
             [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "should-run-full-analysis=true" >> $GITHUB_OUTPUT
            echo "🔍 Full quality analysis will be performed"
          else
            # Check if Go files have changed
            if git diff --name-only HEAD~1 HEAD | grep -E '\.(go|mod|sum)$' > /dev/null; then
              echo "should-run-full-analysis=true" >> $GITHUB_OUTPUT
              echo "🔍 Go files changed - full analysis will be performed"
            else
              echo "should-run-full-analysis=false" >> $GITHUB_OUTPUT
              echo "⏭️ No Go files changed - skipping quality analysis"
            fi
          fi
      
      - name: 🔑 Generate Cache Keys
        id: cache-keys
        run: |
          echo "go-cache-key=go-${{ env.GO_VERSION }}-${{ hashFiles('go.mod', 'go.sum') }}" >> $GITHUB_OUTPUT
          echo "golangci-cache-key=golangci-${{ env.GO_VERSION }}-${{ hashFiles('.golangci.yml', 'go.mod', 'go.sum') }}" >> $GITHUB_OUTPUT

  # ================================================================
  # Test Coverage Analysis
  # ================================================================
  coverage-analysis:
    name: 📊 Test Coverage Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: pre-checks
    if: needs.pre-checks.outputs.should-run-full-analysis == 'true'
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: 🐹 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
      
      - name: 📋 Cache Go Modules
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ needs.pre-checks.outputs.go-cache-key }}
          restore-keys: |
            go-${{ env.GO_VERSION }}-
          save-always: true
      
      - name: 🔧 Install Dependencies
        run: |
          go mod download
          go mod verify
      
      - name: 🧪 Run Tests with Coverage
        run: |
          mkdir -p ${{ env.REPORTS_DIR }}/coverage
          echo "🧪 Running comprehensive test suite with coverage analysis..."
          
          # Run tests with race detection and coverage
          go test -v -race -coverprofile=${{ env.REPORTS_DIR }}/coverage/coverage.out \
                  -covermode=atomic -timeout=25m ./... \
                  2>&1 | tee ${{ env.REPORTS_DIR }}/coverage/test-output.log
          
          # Generate coverage report
          go tool cover -html=${{ env.REPORTS_DIR }}/coverage/coverage.out \
                        -o ${{ env.REPORTS_DIR }}/coverage/coverage.html
          
          # Calculate coverage percentage
          COVERAGE=$(go tool cover -func=${{ env.REPORTS_DIR }}/coverage/coverage.out | \
                    tail -1 | awk '{print $3}' | sed 's/%//')
          
          echo "COVERAGE_PERCENT=$COVERAGE" >> $GITHUB_ENV
          echo "📊 Test Coverage: $COVERAGE%"
          
          # Generate coverage JSON for dashboard
          cat > ${{ env.REPORTS_DIR }}/coverage/coverage.json << EOF
          {
            "timestamp": "$(date -u '+%Y-%m-%dT%H:%M:%SZ')",
            "coverage_percent": $COVERAGE,
            "threshold": ${{ env.COVERAGE_THRESHOLD }},
            "status": "$([ "${COVERAGE%.*}" -ge "${{ env.COVERAGE_THRESHOLD }}" ] && echo "PASSED" || echo "FAILED")"
          }
          EOF
      
      - name: ✅ Validate Coverage Threshold
        run: |
          echo "🔍 Validating coverage threshold..."
          echo "Coverage: ${COVERAGE_PERCENT}%"
          echo "Threshold: ${{ env.COVERAGE_THRESHOLD }}%"
          
          if [ "${COVERAGE_PERCENT%.*}" -ge "${{ env.COVERAGE_THRESHOLD }}" ]; then
            echo "✅ Coverage check PASSED: ${COVERAGE_PERCENT}% >= ${{ env.COVERAGE_THRESHOLD }}%"
            echo "COVERAGE_STATUS=✅ PASSED" >> $GITHUB_ENV
          else
            echo "❌ Coverage check FAILED: ${COVERAGE_PERCENT}% < ${{ env.COVERAGE_THRESHOLD }}%"
            echo "COVERAGE_STATUS=❌ FAILED" >> $GITHUB_ENV
            
            if [[ "${{ github.event.inputs.fail_fast }}" == "true" ]]; then
              echo "💥 Failing fast due to coverage threshold violation"
              exit 1
            fi
          fi
      
      - name: 📄 Generate Coverage Summary
        run: |
          echo "# 📊 Test Coverage Report" > coverage-summary.md
          echo "" >> coverage-summary.md
          echo "| Metric | Value | Status |" >> coverage-summary.md
          echo "|--------|-------|--------|" >> coverage-summary.md
          echo "| **Coverage** | ${COVERAGE_PERCENT}% | $COVERAGE_STATUS |" >> coverage-summary.md
          echo "| **Threshold** | ${{ env.COVERAGE_THRESHOLD }}% | - |" >> coverage-summary.md
          echo "| **Generated** | $(date -u '+%Y-%m-%d %H:%M:%S UTC') | - |" >> coverage-summary.md
          echo "" >> coverage-summary.md
          
          # Add per-package coverage
          echo "## 📦 Coverage by Package" >> coverage-summary.md
          echo "" >> coverage-summary.md
          echo "| Package | Coverage |" >> coverage-summary.md
          echo "|---------|----------|" >> coverage-summary.md
          go tool cover -func=${{ env.REPORTS_DIR }}/coverage/coverage.out | head -n -1 | \
            awk '{printf "| %s | %s |\n", $1, $3}' >> coverage-summary.md
          
          cat coverage-summary.md >> $GITHUB_STEP_SUMMARY
      
      - name: 💾 Upload Coverage Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: ${{ env.REPORTS_DIR }}/coverage/
          retention-days: 30
      
      - name: 📤 Upload Coverage to Codecov
        if: github.event_name != 'pull_request' || github.event.pull_request.head.repo.full_name == github.repository
        uses: codecov/codecov-action@v4
        with:
          files: ${{ env.REPORTS_DIR }}/coverage/coverage.out
          flags: unittests
          name: nephoran-intent-operator
          fail_ci_if_error: false
          verbose: true

  # ================================================================
  # Code Quality Linting
  # ================================================================
  lint-analysis:
    name: 🔍 Code Quality Linting
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: pre-checks
    if: needs.pre-checks.outputs.should-run-full-analysis == 'true'
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: 🐹 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
      
      - name: 🔍 Cache golangci-lint
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/golangci-lint
            ~/.cache/go-build
          key: ${{ needs.pre-checks.outputs.golangci-cache-key }}
          restore-keys: |
            golangci-${{ env.GO_VERSION }}-
      
      - name: 🔧 Install golangci-lint
        uses: golangci/golangci-lint-action@v4
        with:
          version: latest
          install-mode: "goinstall"
          only-new-issues: false
      
      - name: 🔍 Run Comprehensive Linting
        run: |
          mkdir -p ${{ env.REPORTS_DIR }}/lint
          echo "🔍 Running comprehensive code quality analysis..."
          
          # Run golangci-lint with JSON output
          golangci-lint run --out-format=json --issues-exit-code=0 \
                           > ${{ env.REPORTS_DIR }}/lint/golangci-lint-report.json 2>&1 || true
          
          # Count issues
          LINT_ISSUES=$(jq '.Issues | length' ${{ env.REPORTS_DIR }}/lint/golangci-lint-report.json 2>/dev/null || echo "0")
          echo "LINT_ISSUES=$LINT_ISSUES" >> $GITHUB_ENV
          
          echo "🔍 Found $LINT_ISSUES code quality issues"
          
          # Generate human-readable report
          golangci-lint run --out-format=colored-line-number \
                           > ${{ env.REPORTS_DIR }}/lint/golangci-lint-report.txt 2>&1 || true
      
      - name: 📄 Generate Lint Summary
        run: |
          echo "# 🔍 Code Quality Lint Analysis" > lint-summary.md
          echo "" >> lint-summary.md
          echo "| Metric | Value | Status |" >> lint-summary.md
          echo "|--------|-------|--------|" >> lint-summary.md
          
          if [ "$LINT_ISSUES" -eq 0 ]; then
            LINT_STATUS="✅ CLEAN"
          else
            LINT_STATUS="⚠️ ISSUES FOUND"
          fi
          
          echo "| **Issues Found** | $LINT_ISSUES | $LINT_STATUS |" >> lint-summary.md
          echo "| **Configuration** | .golangci.yml | Active |" >> lint-summary.md
          echo "| **Generated** | $(date -u '+%Y-%m-%d %H:%M:%S UTC') | - |" >> lint-summary.md
          echo "" >> lint-summary.md
          
          if [ "$LINT_ISSUES" -gt 0 ]; then
            echo "## 🐛 Issues by Category" >> lint-summary.md
            echo "" >> lint-summary.md
            echo "| Linter | Count |" >> lint-summary.md
            echo "|--------|-------|" >> lint-summary.md
            jq -r '.Issues | group_by(.FromLinter) | .[] | "| " + .[0].FromLinter + " | " + (length | tostring) + " |"' \
              ${{ env.REPORTS_DIR }}/lint/golangci-lint-report.json >> lint-summary.md 2>/dev/null || true
            echo "" >> lint-summary.md
            
            echo "<details><summary>📋 Detailed Issues</summary>" >> lint-summary.md
            echo "" >> lint-summary.md
            echo '```' >> lint-summary.md
            head -50 ${{ env.REPORTS_DIR }}/lint/golangci-lint-report.txt >> lint-summary.md || true
            echo '```' >> lint-summary.md
            echo "</details>" >> lint-summary.md
          fi
          
          cat lint-summary.md >> $GITHUB_STEP_SUMMARY
      
      - name: 💾 Upload Lint Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: lint-reports
          path: ${{ env.REPORTS_DIR }}/lint/
          retention-days: 30

  # ================================================================
  # Security Analysis
  # ================================================================
  security-analysis:
    name: 🔐 Security Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: pre-checks
    if: needs.pre-checks.outputs.should-run-full-analysis == 'true'
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: 🐹 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
      
      - name: 🔒 Install Security Tools
        run: |
          # Install govulncheck
          go install golang.org/x/vuln/cmd/govulncheck@latest
          
          # Install gosec
          go install github.com/securego/gosec/v2/cmd/gosec@latest
      
      - name: 🔍 Vulnerability Scanning
        run: |
          mkdir -p ${{ env.REPORTS_DIR }}/security
          echo "🔍 Running vulnerability scan..."
          
          # Run govulncheck
          if govulncheck -json ./... > ${{ env.REPORTS_DIR }}/security/vulnerabilities.json 2>&1; then
            VULN_COUNT=$(jq '[.Vulns[]? // empty] | length' ${{ env.REPORTS_DIR }}/security/vulnerabilities.json 2>/dev/null || echo "0")
            echo "VULNERABILITIES=$VULN_COUNT" >> $GITHUB_ENV
            echo "🔒 Found $VULN_COUNT vulnerabilities"
          else
            echo "VULNERABILITIES=0" >> $GITHUB_ENV
            echo "🔒 No vulnerabilities detected"
          fi
      
      - name: 🔒 Static Security Analysis
        run: |
          echo "🔒 Running static security analysis..."
          
          # Run gosec
          gosec -fmt=json -out=${{ env.REPORTS_DIR }}/security/gosec-report.json ./... 2>/dev/null || true
          
          SECURITY_ISSUES=$(jq '.Issues | length' ${{ env.REPORTS_DIR }}/security/gosec-report.json 2>/dev/null || echo "0")
          echo "SECURITY_ISSUES=$SECURITY_ISSUES" >> $GITHUB_ENV
          
          echo "🔒 Found $SECURITY_ISSUES security issues"
      
      - name: 📄 Generate Security Summary
        run: |
          echo "# 🔐 Security Analysis Report" > security-summary.md
          echo "" >> security-summary.md
          echo "| Metric | Value | Status |" >> security-summary.md
          echo "|--------|-------|--------|" >> security-summary.md
          
          VULN_STATUS=$([ "$VULNERABILITIES" -eq 0 ] && echo "✅ CLEAN" || echo "⚠️ ISSUES")
          SECURITY_STATUS=$([ "$SECURITY_ISSUES" -eq 0 ] && echo "✅ CLEAN" || echo "⚠️ ISSUES")
          
          echo "| **Vulnerabilities** | $VULNERABILITIES | $VULN_STATUS |" >> security-summary.md
          echo "| **Security Issues** | $SECURITY_ISSUES | $SECURITY_STATUS |" >> security-summary.md
          echo "| **Generated** | $(date -u '+%Y-%m-%d %H:%M:%S UTC') | - |" >> security-summary.md
          
          if [ "$VULNERABILITIES" -gt 0 ]; then
            echo "" >> security-summary.md
            echo "## 🚨 Vulnerabilities Found" >> security-summary.md
            echo "" >> security-summary.md
            jq -r '.Vulns[]? | "- **" + .Symbol + "** (" + .ID + "): " + .Description' \
              ${{ env.REPORTS_DIR }}/security/vulnerabilities.json >> security-summary.md 2>/dev/null || true
          fi
          
          cat security-summary.md >> $GITHUB_STEP_SUMMARY
      
      - name: 💾 Upload Security Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: ${{ env.REPORTS_DIR }}/security/
          retention-days: 30

  # ================================================================
  # Quality Metrics Calculation
  # ================================================================
  quality-metrics:
    name: 📏 Quality Metrics Calculation
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [pre-checks, coverage-analysis, lint-analysis, security-analysis]
    if: always() && needs.pre-checks.outputs.should-run-full-analysis == 'true'
    
    steps:
      - name: 📥 Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: 🐹 Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true
      
      - name: 📥 Download Artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: "*-reports"
          path: ${{ env.REPORTS_DIR }}/
          merge-multiple: true
      
      - name: 📊 Calculate Quality Metrics
        run: |
          mkdir -p ${{ env.REPORTS_DIR }}/metrics
          echo "📊 Calculating comprehensive quality metrics..."
          
          # Run custom quality metrics calculator
          go run scripts/quality-metrics.go . ${{ env.REPORTS_DIR }}/metrics/quality-metrics.json
          
          # Extract key metrics
          if [ -f "${{ env.REPORTS_DIR }}/metrics/quality-metrics.json" ]; then
            QUALITY_SCORE=$(jq -r '.quality_score' ${{ env.REPORTS_DIR }}/metrics/quality-metrics.json)
            QUALITY_GRADE=$(jq -r '.quality_grade' ${{ env.REPORTS_DIR }}/metrics/quality-metrics.json)
            
            echo "QUALITY_SCORE=$QUALITY_SCORE" >> $GITHUB_ENV
            echo "QUALITY_GRADE=$QUALITY_GRADE" >> $GITHUB_ENV
            
            echo "📏 Quality Score: $QUALITY_SCORE/10.0 (Grade: $QUALITY_GRADE)"
          else
            echo "QUALITY_SCORE=0" >> $GITHUB_ENV
            echo "QUALITY_GRADE=F" >> $GITHUB_ENV
            echo "⚠️ Failed to calculate quality metrics"
          fi
      
      - name: 📊 Generate Quality Dashboard
        run: |
          echo "📊 Generating comprehensive quality dashboard..."
          
          # Run quality dashboard generator (from quality-gate.sh)
          if [[ -f "scripts/quality-gate.sh" ]]; then
            chmod +x scripts/quality-gate.sh
            ./scripts/quality-gate.sh --skip-tests --skip-lint --skip-security --reports-dir="${{ env.REPORTS_DIR }}"
          fi
      
      - name: 📄 Generate Metrics Summary
        run: |
          echo "# 📏 Code Quality Metrics" > metrics-summary.md
          echo "" >> metrics-summary.md
          echo "| Metric | Value | Threshold | Status |" >> metrics-summary.md
          echo "|--------|-------|-----------|--------|" >> metrics-summary.md
          
          QUALITY_STATUS=$(awk "BEGIN {print ($QUALITY_SCORE >= ${{ env.QUALITY_THRESHOLD }}) ? \"✅ PASSED\" : \"❌ FAILED\"}")
          
          echo "| **Overall Score** | $QUALITY_SCORE/10.0 | ${{ env.QUALITY_THRESHOLD }}/10.0 | $QUALITY_STATUS |" >> metrics-summary.md
          echo "| **Grade** | $QUALITY_GRADE | B+ | - |" >> metrics-summary.md
          
          if [ -f "${{ env.REPORTS_DIR }}/coverage/coverage.json" ]; then
            COVERAGE=$(jq -r '.coverage_percent' ${{ env.REPORTS_DIR }}/coverage/coverage.json)
            COVERAGE_STATUS=$(jq -r '.status' ${{ env.REPORTS_DIR }}/coverage/coverage.json)
            echo "| **Test Coverage** | ${COVERAGE}% | ${{ env.COVERAGE_THRESHOLD }}% | $COVERAGE_STATUS |" >> metrics-summary.md
          fi
          
          echo "| **Generated** | $(date -u '+%Y-%m-%d %H:%M:%S UTC') | - | - |" >> metrics-summary.md
          
          cat metrics-summary.md >> $GITHUB_STEP_SUMMARY
      
      - name: 💾 Upload Quality Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: quality-dashboard
          path: ${{ env.REPORTS_DIR }}/
          retention-days: 30

  # ================================================================
  # Quality Gate Enforcement
  # ================================================================
  quality-gate:
    name: 🚪 Quality Gate Enforcement
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [coverage-analysis, lint-analysis, security-analysis, quality-metrics]
    if: always() && needs.pre-checks.outputs.should-run-full-analysis == 'true'
    
    steps:
      - name: 📥 Download Quality Reports
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: quality-dashboard
          path: ${{ env.REPORTS_DIR }}/
      
      - name: 🔍 Evaluate Quality Gate
        id: quality-gate
        run: |
          echo "🔍 Evaluating quality gate criteria..."
          
          GATE_PASSED=true
          FAILURES=()
          
          # Check coverage
          if [ -f "${{ env.REPORTS_DIR }}/coverage/coverage.json" ]; then
            COVERAGE_STATUS=$(jq -r '.status' ${{ env.REPORTS_DIR }}/coverage/coverage.json)
            if [ "$COVERAGE_STATUS" != "PASSED" ]; then
              GATE_PASSED=false
              FAILURES+=("Test coverage below threshold")
            fi
          fi
          
          # Check quality score
          if [ -f "${{ env.REPORTS_DIR }}/metrics/quality-metrics.json" ]; then
            QUALITY_SCORE=$(jq -r '.quality_score' ${{ env.REPORTS_DIR }}/metrics/quality-metrics.json)
            if awk "BEGIN {exit !($QUALITY_SCORE < ${{ env.QUALITY_THRESHOLD }})}"; then
              GATE_PASSED=false
              FAILURES+=("Quality score below threshold")
            fi
          fi
          
          # Check for critical security issues
          if [ "${{ env.VULNERABILITIES || 0 }}" -gt 0 ]; then
            GATE_PASSED=false
            FAILURES+=("Security vulnerabilities found")
          fi
          
          echo "gate-passed=$GATE_PASSED" >> $GITHUB_OUTPUT
          
          if [ "$GATE_PASSED" = true ]; then
            echo "✅ Quality gate PASSED - All criteria met"
            echo "gate-status=✅ PASSED" >> $GITHUB_OUTPUT
          else
            echo "❌ Quality gate FAILED - Criteria not met:"
            printf '%s\n' "${FAILURES[@]}"
            echo "gate-status=❌ FAILED" >> $GITHUB_OUTPUT
          fi
      
      - name: 📊 Create Quality Gate Summary
        run: |
          echo "# 🚪 Quality Gate Results" > gate-summary.md
          echo "" >> gate-summary.md
          echo "## Overall Status: ${{ steps.quality-gate.outputs.gate-status }}" >> gate-summary.md
          echo "" >> gate-summary.md
          
          echo "| Component | Status | Details |" >> gate-summary.md
          echo "|-----------|--------|---------|" >> gate-summary.md
          
          # Coverage status
          if [ -f "${{ env.REPORTS_DIR }}/coverage/coverage.json" ]; then
            COVERAGE=$(jq -r '.coverage_percent' ${{ env.REPORTS_DIR }}/coverage/coverage.json)
            COVERAGE_STATUS=$(jq -r '.status' ${{ env.REPORTS_DIR }}/coverage/coverage.json)
            echo "| Test Coverage | $COVERAGE_STATUS | ${COVERAGE}% (threshold: ${{ env.COVERAGE_THRESHOLD }}%) |" >> gate-summary.md
          fi
          
          # Quality score status
          if [ -f "${{ env.REPORTS_DIR }}/metrics/quality-metrics.json" ]; then
            QUALITY_SCORE=$(jq -r '.quality_score' ${{ env.REPORTS_DIR }}/metrics/quality-metrics.json)
            QUALITY_GRADE=$(jq -r '.quality_grade' ${{ env.REPORTS_DIR }}/metrics/quality-metrics.json)
            QUALITY_STATUS=$(awk "BEGIN {print ($QUALITY_SCORE >= ${{ env.QUALITY_THRESHOLD }}) ? \"✅ PASSED\" : \"❌ FAILED\"}")
            echo "| Quality Score | $QUALITY_STATUS | $QUALITY_SCORE/10.0 ($QUALITY_GRADE) |" >> gate-summary.md
          fi
          
          # Security status
          VULN_STATUS=$([ "${{ env.VULNERABILITIES || 0 }}" -eq 0 ] && echo "✅ CLEAN" || echo "⚠️ ISSUES")
          echo "| Security | $VULN_STATUS | ${{ env.VULNERABILITIES || 0 }} vulnerabilities |" >> gate-summary.md
          
          # Lint status
          LINT_STATUS=$([ "${{ env.LINT_ISSUES || 0 }}" -eq 0 ] && echo "✅ CLEAN" || echo "⚠️ ISSUES")
          echo "| Code Quality | $LINT_STATUS | ${{ env.LINT_ISSUES || 0 }} issues |" >> gate-summary.md
          
          echo "" >> gate-summary.md
          echo "**Generated**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> gate-summary.md
          
          if [ -f "${{ env.REPORTS_DIR }}/quality-dashboard.html" ]; then
            echo "" >> gate-summary.md
            echo "📊 [View Detailed Quality Dashboard](../quality-dashboard.html)" >> gate-summary.md
          fi
          
          cat gate-summary.md >> $GITHUB_STEP_SUMMARY
      
      - name: ❌ Fail on Quality Gate Failure
        if: steps.quality-gate.outputs.gate-passed != 'true'
        run: |
          echo "💥 Quality gate failed - build will be marked as failed"
          echo ""
          echo "To resolve:"
          echo "1. 📊 Review the quality dashboard for detailed metrics"
          echo "2. 🧪 Increase test coverage to meet the ${{ env.COVERAGE_THRESHOLD }}% threshold"
          echo "3. 🔍 Address code quality issues identified by linting"
          echo "4. 🔐 Fix any security vulnerabilities"
          echo "5. 📏 Improve overall code quality score to ${{ env.QUALITY_THRESHOLD }}/10.0"
          echo ""
          echo "Quality gates are in place to maintain code quality standards."
          exit 1

  # ================================================================
  # Quality Report Publishing
  # ================================================================
  publish-reports:
    name: 📤 Publish Quality Reports
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [quality-gate]
    if: always() && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
    permissions:
      contents: read
      pages: write
      id-token: write
    
    steps:
      - name: 📥 Download Quality Dashboard
        uses: actions/download-artifact@v4
        with:
          name: quality-dashboard
          path: quality-reports/
      
      - name: 📊 Setup Pages
        if: github.ref == 'refs/heads/main'
        uses: actions/configure-pages@v4
      
      - name: 📤 Upload Pages Artifact
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-pages-artifact@v4
        with:
          path: quality-reports/
      
      - name: 🚀 Deploy to GitHub Pages
        if: github.ref == 'refs/heads/main'
        uses: actions/deploy-pages@v4
        id: deployment

  # ================================================================
  # Notification and Alerts
  # ================================================================
  notify:
    name: 📢 Quality Gate Notifications
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [quality-gate]
    if: always() && (failure() || github.event_name == 'schedule')
    
    steps:
      - name: 📢 Post Quality Gate Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const gateStatus = "${{ needs.quality-gate.outputs.gate-status }}";
            const coverage = process.env.COVERAGE_PERCENT || 'N/A';
            const qualityScore = process.env.QUALITY_SCORE || 'N/A';
            const vulns = process.env.VULNERABILITIES || '0';
            const lintIssues = process.env.LINT_ISSUES || '0';
            
            const body = `## 🚪 Code Quality Gate Results
            
            **Overall Status**: ${gateStatus}
            
            ### 📊 Quality Metrics
            - **Test Coverage**: ${coverage}% (threshold: ${{ env.COVERAGE_THRESHOLD }}%)
            - **Quality Score**: ${qualityScore}/10.0 (threshold: ${{ env.QUALITY_THRESHOLD }}/10.0)
            - **Security Issues**: ${vulns} vulnerabilities
            - **Lint Issues**: ${lintIssues} code quality issues
            
            ${gateStatus.includes('FAILED') ? 
              '❌ **Quality gate failed** - Please address the issues above before merging.' :
              '✅ **Quality gate passed** - All quality criteria met!'
            }
            
            📊 Detailed reports are available in the workflow artifacts.`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
      
      - name: 📧 Send Quality Alert
        if: failure() && github.event_name == 'schedule'
        run: |
          echo "📧 Quality gate failure detected in scheduled run"
          echo "This would typically trigger alerts to the development team"
          echo "Configure your notification system (Slack, email, etc.) here"