name: CI Performance Monitor

on:
  workflow_run:
    workflows: ["CI Optimized", "Docker Build Optimized"]
    types: [completed]
  schedule:
    # Weekly performance report
    - cron: '0 0 * * 0'
  workflow_dispatch:
    inputs:
      days:
        description: 'Number of days to analyze'
        required: false
        default: '7'

permissions:
  contents: read
  actions: read
  issues: write

jobs:
  collect-metrics:
    name: Collect Performance Metrics
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Collect workflow metrics
        id: metrics
        uses: actions/github-script@v7
        with:
          script: |
            const days = parseInt(context.payload.inputs?.days || '7');
            const since = new Date(Date.now() - days * 24 * 60 * 60 * 1000).toISOString();
            
            // Collect workflow runs
            const workflows = ['ci-optimized.yml', 'docker-build-optimized.yml', 'ci.yml', 'docker-build.yml'];
            const metrics = {};
            
            for (const workflow of workflows) {
              try {
                const runs = await github.rest.actions.listWorkflowRuns({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: workflow,
                  created: `>=${since}`,
                  per_page: 100
                });
                
                if (runs.data.workflow_runs.length === 0) continue;
                
                // Calculate metrics
                const durations = runs.data.workflow_runs
                  .filter(run => run.conclusion === 'success')
                  .map(run => {
                    const start = new Date(run.created_at);
                    const end = new Date(run.updated_at);
                    return (end - start) / 1000 / 60; // minutes
                  });
                
                if (durations.length > 0) {
                  metrics[workflow] = {
                    avg: (durations.reduce((a, b) => a + b, 0) / durations.length).toFixed(2),
                    min: Math.min(...durations).toFixed(2),
                    max: Math.max(...durations).toFixed(2),
                    p50: durations.sort((a, b) => a - b)[Math.floor(durations.length / 2)].toFixed(2),
                    p95: durations.sort((a, b) => a - b)[Math.floor(durations.length * 0.95)].toFixed(2),
                    count: durations.length,
                    success_rate: ((runs.data.workflow_runs.filter(r => r.conclusion === 'success').length / runs.data.workflow_runs.length) * 100).toFixed(1)
                  };
                }
              } catch (error) {
                console.log(`Workflow ${workflow} not found or no data`);
              }
            }
            
            return metrics;
      
      - name: Generate performance report
        uses: actions/github-script@v7
        with:
          script: |
            const metrics = ${{ steps.metrics.outputs.result }};
            
            let report = `# CI/CD Performance Report\n\n`;
            report += `**Period**: Last ${{ github.event.inputs.days || '7' }} days\n`;
            report += `**Generated**: ${new Date().toISOString()}\n\n`;
            
            report += `## Workflow Performance Metrics\n\n`;
            report += `| Workflow | Avg (min) | P50 (min) | P95 (min) | Success Rate | Runs |\n`;
            report += `|----------|-----------|-----------|-----------|--------------|------|\n`;
            
            for (const [workflow, data] of Object.entries(metrics)) {
              const name = workflow.replace('.yml', '').replace(/-/g, ' ');
              report += `| ${name} | ${data.avg} | ${data.p50} | ${data.p95} | ${data.success_rate}% | ${data.count} |\n`;
            }
            
            report += `\n## Performance Comparison\n\n`;
            
            // Compare optimized vs original
            const ciOrig = metrics['ci.yml'];
            const ciOpt = metrics['ci-optimized.yml'];
            const dockerOrig = metrics['docker-build.yml'];
            const dockerOpt = metrics['docker-build-optimized.yml'];
            
            if (ciOrig && ciOpt) {
              const improvement = ((1 - ciOpt.avg / ciOrig.avg) * 100).toFixed(1);
              report += `- **CI Workflow**: ${improvement}% improvement (${ciOrig.avg} → ${ciOpt.avg} min)\n`;
            }
            
            if (dockerOrig && dockerOpt) {
              const improvement = ((1 - dockerOpt.avg / dockerOrig.avg) * 100).toFixed(1);
              report += `- **Docker Build**: ${improvement}% improvement (${dockerOrig.avg} → ${dockerOpt.avg} min)\n`;
            }
            
            report += `\n## Recommendations\n\n`;
            
            // Generate recommendations based on metrics
            const recommendations = [];
            
            for (const [workflow, data] of Object.entries(metrics)) {
              if (data.p95 > data.avg * 1.5) {
                recommendations.push(`- **${workflow}**: High variance detected (P95 is ${((data.p95/data.avg - 1) * 100).toFixed(0)}% above average)`);
              }
              if (data.success_rate < 90) {
                recommendations.push(`- **${workflow}**: Low success rate (${data.success_rate}%) - investigate failures`);
              }
              if (data.avg > 15) {
                recommendations.push(`- **${workflow}**: Consider further optimization (avg ${data.avg} min)`);
              }
            }
            
            if (recommendations.length > 0) {
              report += recommendations.join('\n');
            } else {
              report += `✅ All workflows performing within acceptable parameters`;
            }
            
            // Save report
            require('fs').writeFileSync('performance-report.md', report);
            
            // Also output to summary
            core.summary.addRaw(report).write();
      
      - name: Upload performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: performance-report.md
          retention-days: 30
      
      - name: Create issue if performance degraded
        uses: actions/github-script@v7
        with:
          script: |
            const metrics = ${{ steps.metrics.outputs.result }};
            
            // Check for performance degradation
            let hasIssue = false;
            let issueBody = '## ⚠️ CI/CD Performance Degradation Detected\n\n';
            
            for (const [workflow, data] of Object.entries(metrics)) {
              if (data.avg > 20) {  // Alert if average > 20 minutes
                hasIssue = true;
                issueBody += `- **${workflow}**: Average runtime ${data.avg} minutes (threshold: 20 min)\n`;
              }
              if (data.success_rate < 80) {  // Alert if success rate < 80%
                hasIssue = true;
                issueBody += `- **${workflow}**: Success rate ${data.success_rate}% (threshold: 80%)\n`;
              }
            }
            
            if (hasIssue) {
              // Check if issue already exists
              const issues = await github.rest.issues.listForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo,
                labels: 'ci-performance',
                state: 'open'
              });
              
              if (issues.data.length === 0) {
                // Create new issue
                await github.rest.issues.create({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  title: 'CI/CD Performance Degradation Alert',
                  body: issueBody + '\n\nView the full [performance report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})',
                  labels: ['ci-performance', 'automation']
                });
              }
            }