// Main test execution script for comprehensive validation suite.

package main

import (
	"context"
	"encoding/json"
	"flag"
	"fmt"
	"html/template"
	"log"
	"os"
	"path/filepath"
	"time"

	test_validation "github.com/thc1006/nephoran-intent-operator/tests/validation"
)

func main() {
	var (
		testScope = flag.String("scope", "all", "Test scope to run (all, functional, performance, security, production)")

		targetScore = flag.Int("target-score", 90, "Target score to achieve (0-100)")

		timeout = flag.Duration("timeout", 30*time.Minute, "Maximum test execution time")

		concurrency = flag.Int("concurrency", 50, "Maximum concurrent operations")

		enableLoadTest = flag.Bool("enable-load-test", true, "Enable load testing")

		enableChaosTest = flag.Bool("enable-chaos-test", false, "Enable chaos testing")

		outputDir = flag.String("output-dir", "test-results", "Output directory for test results")

		reportFormat = flag.String("report-format", "json", "Report format (json, html, both)")

		verbose = flag.Bool("verbose", false, "Enable verbose logging")
	)

	flag.Parse()

	if *verbose {

		log.SetFlags(log.LstdFlags | log.Lshortfile)

		log.Println("Starting Nephoran Intent Operator Comprehensive Validation")

	}

	// Create output directory.

	if err := os.MkdirAll(*outputDir, 0o755); err != nil {
		log.Fatalf("Failed to create output directory: %v", err)
	}

	// Create validation configuration.

	config := &test_validation.ValidationConfig{
		FunctionalTarget: 45,

		PerformanceTarget: 23,

		SecurityTarget: 14,

		ProductionTarget: 8,

		TotalTarget: *targetScore,

		TimeoutDuration: *timeout,

		ConcurrencyLevel: *concurrency,

		LoadTestDuration: 5 * time.Minute,

		LatencyThreshold: 2 * time.Second,

		ThroughputThreshold: 45.0,

		AvailabilityTarget: 99.95,

		CoverageThreshold: 90.0,

		EnableE2ETesting: true,

		EnableLoadTesting: *enableLoadTest,

		EnableChaosTesting: *enableChaosTest,

		EnableSecurityTesting: true,
	}

	// Adjust configuration based on test scope.

	switch *testScope {

	case "functional":

		config.EnableLoadTesting = false

		config.EnableChaosTesting = false

		config.TotalTarget = config.FunctionalTarget

	case "performance":

		config.EnableLoadTesting = true

		config.TotalTarget = config.PerformanceTarget

	case "security":

		config.EnableLoadTesting = false

		config.EnableChaosTesting = false

		config.TotalTarget = config.SecurityTarget

	case "production":

		config.EnableLoadTesting = true

		config.EnableChaosTesting = *enableChaosTest

		config.TotalTarget = config.ProductionTarget

	case "all":

		// Use default configuration.

	default:

		log.Fatalf("Invalid test scope: %s", *testScope)

	}

	if *verbose {
		log.Printf("Configuration: Target=%d, Scope=%s, Concurrency=%d, LoadTest=%t, ChaosTest=%t",

			config.TotalTarget, *testScope, config.ConcurrencyLevel, config.EnableLoadTesting, config.EnableChaosTesting)
	}

	// Create validation suite.

	suite := test_validation.NewValidationSuite(config)

	// Create execution context with timeout.

	ctx, cancel := context.WithTimeout(context.Background(), *timeout)

	defer cancel()

	// Setup test suite.

	if *verbose {
		log.Println("Setting up test environment...")
	}

	suite.SetupSuite()

	defer suite.TearDownSuite()

	// Execute validation based on scope.

	var results *test_validation.ValidationResults

	var err error

	switch *testScope {

	case "functional":

		results, err = runFunctionalValidation(ctx, suite)

	case "performance":

		results, err = runPerformanceValidation(ctx, suite)

	case "security":

		results, err = runSecurityValidation(ctx, suite)

	case "production":

		results, err = runProductionValidation(ctx, suite)

	case "all":

		results, err = suite.ExecuteComprehensiveValidation(ctx)

	default:

		log.Fatalf("Invalid test scope: %s", *testScope)

	}

	// Handle execution results.

	if err != nil {

		log.Printf("Validation execution failed: %v", err)

		if results != nil {
			generateReports(results, *outputDir, *reportFormat, *verbose)
		}

		log.Fatal(1)

	}

	if *verbose {
		log.Printf("Validation completed successfully: %d/%d points",

			results.TotalScore, results.MaxPossibleScore)
	}

	// Generate reports.

	generateReports(results, *outputDir, *reportFormat, *verbose)

	// Check if target score was achieved.

	if results.TotalScore < config.TotalTarget {

		log.Printf("‚ùå Validation FAILED: Achieved %d points, target %d points",

			results.TotalScore, config.TotalTarget)

		log.Fatal(1)

	}

	log.Printf("‚úÖ Validation PASSED: Achieved %d points, target %d points",

		results.TotalScore, config.TotalTarget)
}

// runFunctionalValidation executes only functional tests.

func runFunctionalValidation(ctx context.Context, suite *test_validation.ValidationSuite) (*test_validation.ValidationResults, error) {
	log.Println("Running Functional Completeness Validation...")

	// Execute functional tests only.

	funcScore, err := suite.GetFunctionalValidator().ExecuteFunctionalTests(ctx)
	if err != nil {
		return nil, fmt.Errorf("functional tests failed: %w", err)
	}

	// Create results structure.

	results := &test_validation.ValidationResults{
		TotalScore: funcScore,

		MaxPossibleScore: 50,

		FunctionalScore: funcScore,

		ExecutionTime: time.Minute, // Placeholder

		TestsExecuted: 15, // Placeholder

		TestsPassed: funcScore * 15 / 50, // Approximate

		TestsFailed: 15 - (funcScore * 15 / 50),
	}

	return results, nil
}

// runPerformanceValidation executes only performance tests.

func runPerformanceValidation(ctx context.Context, suite *test_validation.ValidationSuite) (*test_validation.ValidationResults, error) {
	log.Println("Running Performance Benchmarking...")

	// Execute performance tests only.

	perfScore, err := suite.GetPerformanceBenchmarker().ExecutePerformanceTests(ctx)
	if err != nil {
		return nil, fmt.Errorf("performance tests failed: %w", err)
	}

	results := &test_validation.ValidationResults{
		TotalScore: perfScore,

		MaxPossibleScore: 25,

		PerformanceScore: perfScore,

		ExecutionTime: 5 * time.Minute, // Placeholder

		TestsExecuted: 8, // Placeholder

		TestsPassed: perfScore * 8 / 25, // Approximate

		TestsFailed: 8 - (perfScore * 8 / 25),
	}

	return results, nil
}

// runSecurityValidation executes only security tests.

func runSecurityValidation(ctx context.Context, suite *test_validation.ValidationSuite) (*test_validation.ValidationResults, error) {
	log.Println("Running Security Compliance Validation...")

	// Execute security tests only.

	secScore, err := suite.GetSecurityValidator().ExecuteSecurityTests(ctx)
	if err != nil {
		return nil, fmt.Errorf("security tests failed: %w", err)
	}

	results := &test_validation.ValidationResults{
		TotalScore: secScore,

		MaxPossibleScore: 15,

		SecurityScore: secScore,

		ExecutionTime: 3 * time.Minute, // Placeholder

		TestsExecuted: 12, // Placeholder

		TestsPassed: secScore * 12 / 15, // Approximate

		TestsFailed: 12 - (secScore * 12 / 15),
	}

	return results, nil
}

// runProductionValidation executes only production readiness tests.

func runProductionValidation(ctx context.Context, suite *test_validation.ValidationSuite) (*test_validation.ValidationResults, error) {
	log.Println("Running Production Readiness Validation...")

	// Execute production tests only.

	prodScore, err := suite.GetReliabilityValidator().ExecuteProductionTests(ctx)
	if err != nil {
		return nil, fmt.Errorf("production tests failed: %w", err)
	}

	results := &test_validation.ValidationResults{
		TotalScore: prodScore,

		MaxPossibleScore: 10,

		ProductionScore: prodScore,

		ExecutionTime: 10 * time.Minute, // Placeholder

		TestsExecuted: 6, // Placeholder

		TestsPassed: prodScore * 6 / 10, // Approximate

		TestsFailed: 6 - (prodScore * 6 / 10),

		AvailabilityAchieved: 99.95, // Placeholder

	}

	return results, nil
}

// generateReports creates validation reports in requested formats.

func generateReports(results *test_validation.ValidationResults, outputDir, format string, verbose bool) {
	if verbose {
		log.Println("Generating validation reports...")
	}

	switch format {

	case "json":

		generateJSONReport(results, outputDir, verbose)

	case "html":

		generateHTMLReport(results, outputDir, verbose)

	case "both":

		generateJSONReport(results, outputDir, verbose)

		generateHTMLReport(results, outputDir, verbose)

	default:

		log.Printf("Unknown report format: %s, generating JSON", format)

		generateJSONReport(results, outputDir, verbose)

	}
}

// generateJSONReport creates a JSON validation report.

func generateJSONReport(results *test_validation.ValidationResults, outputDir string, verbose bool) {
	filename := filepath.Join(outputDir, "validation-report.json")

	file, err := os.Create(filename)
	if err != nil {

		log.Printf("Failed to create JSON report: %v", err)

		return

	}

	defer file.Close() // #nosec G307 - Error handled in defer

	encoder := json.NewEncoder(file)

	encoder.SetIndent("", "  ")

	if err := encoder.Encode(results); err != nil {

		log.Printf("Failed to write JSON report: %v", err)

		return

	}

	if verbose {
		log.Printf("JSON report written to: %s", filename)
	}
}

// generateHTMLReport creates an HTML validation report.

func generateHTMLReport(results *test_validation.ValidationResults, outputDir string, verbose bool) {
	const htmlTemplate = `

<!DOCTYPE html>

<html>

<head>

    <title>Nephoran Intent Operator Validation Report</title>

    <style>

        body { font-family: Arial, sans-serif; margin: 20px; }

        .header { background: #f0f8ff; padding: 20px; border-radius: 5px; }

        .score { font-size: 24px; font-weight: bold; }

        .passed { color: #008000; }

        .failed { color: #ff0000; }

        .category { margin: 10px 0; padding: 10px; border: 1px solid #ddd; border-radius: 3px; }

        .metrics { display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px; margin: 20px 0; }

        .metric { background: #f9f9f9; padding: 10px; border-radius: 3px; }

        table { width: 100%; border-collapse: collapse; margin: 20px 0; }

        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }

        th { background-color: #f2f2f2; }

    </style>

</head>

<body>

    <div class="header">

        <h1>Nephoran Intent Operator - Comprehensive Validation Report</h1>

        <div class="score {{if ge .TotalScore .MaxPossibleScore}}passed{{else}}failed{{end}}">

            Final Score: {{.TotalScore}}/{{.MaxPossibleScore}} points

        </div>

        <p>Generated: {{.ExecutionTime}}</p>

    </div>



    <h2>Category Breakdown</h2>

    <div class="category">

        <h3>üéØ Functional Completeness: {{.FunctionalScore}}/50 points</h3>

    </div>

    <div class="category">

        <h3>‚ö° Performance Benchmarks: {{.PerformanceScore}}/25 points</h3>

    </div>

    <div class="category">

        <h3>üîí Security Compliance: {{.SecurityScore}}/15 points</h3>

    </div>

    <div class="category">

        <h3>üè≠ Production Readiness: {{.ProductionScore}}/10 points</h3>

    </div>



    <h2>Performance Metrics</h2>

    <div class="metrics">

        <div class="metric">

            <strong>Average Latency:</strong> {{.AverageLatency}}

        </div>

        <div class="metric">

            <strong>P95 Latency:</strong> {{.P95Latency}}

        </div>

        <div class="metric">

            <strong>Throughput:</strong> {{.ThroughputAchieved}} intents/min

        </div>

        <div class="metric">

            <strong>Availability:</strong> {{.AvailabilityAchieved}}%

        </div>

    </div>



    <h2>Execution Summary</h2>

    <table>

        <tr><th>Metric</th><th>Value</th></tr>

        <tr><td>Tests Executed</td><td>{{.TestsExecuted}}</td></tr>

        <tr><td>Tests Passed</td><td>{{.TestsPassed}}</td></tr>

        <tr><td>Tests Failed</td><td>{{.TestsFailed}}</td></tr>

        <tr><td>Execution Time</td><td>{{.ExecutionTime}}</td></tr>

        <tr><td>Code Coverage</td><td>{{.CodeCoverage}}%</td></tr>

    </table>

</body>

</html>

`

	filename := filepath.Join(outputDir, "validation-report.html")

	file, err := os.Create(filename)
	if err != nil {

		log.Printf("Failed to create HTML report: %v", err)

		return

	}

	defer file.Close() // #nosec G307 - Error handled in defer

	tmpl, err := template.New("report").Parse(htmlTemplate)
	if err != nil {

		log.Printf("Failed to parse HTML template: %v", err)

		return

	}

	if err := tmpl.Execute(file, results); err != nil {

		log.Printf("Failed to generate HTML report: %v", err)

		return

	}

	if verbose {
		log.Printf("HTML report written to: %s", filename)
	}
}
